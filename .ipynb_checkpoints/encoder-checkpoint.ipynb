{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_label = 'screw'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘sample/hazelnut/encdec’: File exists\r\n"
     ]
    }
   ],
   "source": [
    "!mkdir sample/hazelnut/encdec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘checkpoint/hazelnut/encdec’: File exists\r\n"
     ]
    }
   ],
   "source": [
    "!mkdir checkpoint/hazelnut/encdec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#coding: future_fstrings     # should work even without -*-\n",
    "#location = fromstr(f'POINT({longitude} {latitude})', srid=4326)\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "import sys\n",
    "sys.argv = [sys.argv[0], '--mixing', '--sched', 'mvtec_single_out/' +data_label]# '--loss', 'r1'\n",
    "\n",
    "import argparse\n",
    "import random\n",
    "import math\n",
    "\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torch.autograd import Variable, grad\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, utils\n",
    "\n",
    "from dataset import MultiResolutionDataset2\n",
    "from model import StyledGenerator, Discriminator, Encoder, ShortDiscriminator, StyledGenerator2\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.datasets import load_digits\n",
    "from scipy.spatial.distance import pdist\n",
    "from sklearn.manifold.t_sne import _joint_probabilities\n",
    "from scipy import linalg\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from scipy.spatial.distance import squareform\n",
    "from sklearn.manifold import TSNE\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import imgaug as ia\n",
    "import imgaug.augmenters as iaa\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 \n",
    "from scipy.spatial import distance\n",
    "\n",
    "def requires_grad(model, flag=True):\n",
    "    for p in model.parameters():\n",
    "        p.requires_grad = flag\n",
    "\n",
    "\n",
    "def accumulate(model1, model2, decay=0.999):\n",
    "    par1 = dict(model1.named_parameters())\n",
    "    par2 = dict(model2.named_parameters())\n",
    "\n",
    "    for k in par1.keys():\n",
    "        par1[k].data.mul_(decay).add_(1 - decay, par2[k].data)\n",
    "\n",
    "\n",
    "def sample_data(dataset, batch_size, image_size=4):\n",
    "    dataset.resolution = image_size\n",
    "    loader = DataLoader(dataset, shuffle=True, batch_size=batch_size, num_workers=1, drop_last=True)\n",
    "\n",
    "    return loader\n",
    "\n",
    "\n",
    "def adjust_lr(optimizer, lr):\n",
    "    for group in optimizer.param_groups:\n",
    "        mult = group.get('mult', 1)\n",
    "        group['lr'] = lr * mult\n",
    "        \n",
    "from PIL import Image\n",
    "# Open the image form working directory\n",
    "#image = Image.open('crack/004.png')\n",
    "image = Image.open('1.png')\n",
    "#image = #Image.open('crack/004.png')\n",
    "image = Image.open('test/capsule/test/squeeze/001.png')\n",
    "\n",
    "resize_image = image.resize((512, 512))\n",
    "AAA = None\n",
    "BBB = None\n",
    "    \n",
    "    \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial import distance\n",
    "\n",
    "\n",
    "def sortpts_clockwise(A):\n",
    "    sortedAc2 = A[np.argsort(A[:,1]),:]\n",
    "    top2 = sortedAc2[0:2,:]\n",
    "    bottom2 = sortedAc2[2:,:]\n",
    "    sortedtop2c1 = top2[np.argsort(top2[:,0]),:]\n",
    "    top_left = sortedtop2c1[0,:]\n",
    "    sqdists = distance.cdist(top_left[None], bottom2, 'sqeuclidean')\n",
    "    rest2 = bottom2[np.argsort(np.max(sqdists,0))[::-1],:]\n",
    "    return np.concatenate((sortedtop2c1,rest2),axis =0)\n",
    "\n",
    "\n",
    "#plt.imshow( \n",
    "#(\n",
    "#            (toImage(real_image[0, :, :, :]) - toImage(torch.tensor(mask)) \n",
    "#             * toImage(torch.tensor( ((np.array(real_image[0, :, :, :]))) )) )\n",
    "#             \n",
    "#             + (toImage(torch.tensor(mask)) \n",
    "#            * toImage(torch.tensor(aug.augment_image(np.array( (real_image[0, :, :, :]*255).permute(1, 2, 0)).astype(np.uint8) ).copy() / 255.0)).permute(2, 0, 1))\n",
    "#)\n",
    "#            .permute(1, 2, 0)\n",
    "#            )\n",
    "        \n",
    "    \n",
    "class ImgAugTransform:\n",
    "    def __init__(self):\n",
    "        #self.aug = iaa.Sequential([\n",
    "             #iaa.CoarseDropout(0.1, size_percent=0.5),\n",
    "             #iaa.CoarseDropout((0.02, 0.1), size_percent=(0.02, 0.05), per_channel=False),\n",
    "             #iaa.Salt(0.05, size_percent=(0.01, 0.1)) #AndPepper CoarseSalt\n",
    "            #iaa.BlendAlphaSimplexNoise(iaa.EdgeDetect(1.0))\n",
    "            #iaa.Cutout(fill_mode=\"gaussian\", fill_per_channel=True)\n",
    "            #iaa.Salt(0.05)\n",
    "        #])\n",
    "        self.aug = iaa.Sequential([\n",
    "            #iaa.CoarseDropout(0.1, size_percent=0.5),\n",
    "            #iaa.CoarseDropout((0.02, 0.1), size_percent=(0.02, 0.05), per_channel=False),\n",
    "            #iaa.Salt(0.05)#(0.05, size_percent=(0.01, 0.1)) #AndPepper CoarseSalt\n",
    "            iaa.ChangeColorTemperature((1100, 10000)),\n",
    "            iaa.KeepSizeByResize( iaa.Crop(percent=(0.0, 0.5), keep_size=False) ),\n",
    "            iaa.Flipud(0.5),\n",
    "            iaa.Fliplr(0.5),\n",
    "            #iaa.SaltAndPepper(0.01),\n",
    "            \n",
    "            #iaa.ScaleX((0.5, 1.5)),\n",
    "            #iaa.ScaleY((0.5, 1.5)),\n",
    "            #iaa.TranslateX(px=(-256, 256)),\n",
    "            #iaa.TranslateX(px=(-256, 256)),\n",
    "            \n",
    "            \n",
    "            #iaa.BlendAlphaSimplexNoise(iaa.EdgeDetect(1.0))\n",
    "            #iaa.Cutout(fill_mode=\"gaussian\", fill_per_channel=True)\n",
    "            #iaa.Salt(0.05)\n",
    "        ])\n",
    "        #self.masks = [\n",
    "        #    np.zeros((4, 4, 1), dtype=np.int8),\n",
    "        #    np.zeros((8, 8, 1), dtype=np.int8),\n",
    "        #    np.zeros((16, 16, 1), dtype=np.int8),\n",
    "        #    np.zeros((32, 32, 1), dtype=np.int8),\n",
    "        #    np.zeros((64, 64, 1), dtype=np.int8),\n",
    "        #    np.zeros((128, 128, 1), dtype=np.int8),\n",
    "        #    np.zeros((256, 256, 1), dtype=np.int8),\n",
    "        #    np.zeros((512, 512, 1), dtype=np.int8),\n",
    "        #             ]\n",
    "        self.mask = np.zeros((512, 512, 1), dtype=np.int8)\n",
    "    \n",
    "    def distortion(self, img):\n",
    "        A = img.shape[0] / 3.0\n",
    "        w = 2.0 / img.shape[1]\n",
    "\n",
    "        shift = lambda x: A * np.sin(2.0*np.pi*x * w)\n",
    "\n",
    "        #for i in range(img.shape[0]):\n",
    "        #ret = np.roll(np.array(img[:,:,:]), int(shift(i)))\n",
    "        \n",
    "        if (np.random.randint(2) == 0):\n",
    "            for i in range(img.shape[0]):\n",
    "                img[i,:,0] = torch.tensor( np.roll(img[i,:,0], int(shift(i))) )\n",
    "                img[i,:,1] = torch.tensor( np.roll(img[i,:,1], int(shift(i))) )\n",
    "                img[i,:,2] = torch.tensor( np.roll(img[i,:,2], int(shift(i))) )\n",
    "        else:\n",
    "            for i in range(img.shape[1]):\n",
    "                img[:,i,0] = torch.tensor( np.roll(img[:,i,0], int(shift(i))) )\n",
    "                img[:,i,1] = torch.tensor( np.roll(img[:,i,1], int(shift(i))) )\n",
    "                img[:,i,2] = torch.tensor( np.roll(img[:,i,2], int(shift(i))) )\n",
    "            \n",
    "        return img\n",
    "\n",
    "    def __call__(self, img):\n",
    "        img = np.array(img)\n",
    "        tile_size = img.shape[0]\n",
    "        step = int(np.log2(tile_size / 4.0))\n",
    "        \n",
    "        #self.mask = self.masks[step][:, :, :]\n",
    "        n = int(np.random.rand(1) * 7 + 3)\n",
    "        xy = np.random.uniform(low=0.2, high=0.8, size=(2))\n",
    "        #wh = (np.random.normal(0.2, 0.1, size=(2)))\n",
    "        wh = np.random.uniform(low=0.2, high=0.8, size=(2))\n",
    "        \n",
    "#        for i in range(n):\n",
    "#            polys = np.random.rand(5*2).reshape(5, 2)\n",
    "#            polys[:, 0] = polys[:, 0] * tile_size * wh[0] + xy[0] * tile_size\n",
    "#            polys[:, 1] = polys[:, 1] * tile_size * wh[1] + xy[1] * tile_size\n",
    "#        for i in sortpts_clockwise(polys).reshape(1, 5, 2).astype(np.int32).tolist():\n",
    "#            cv2.fillConvexPoly(self.mask, np.array(i), 1)\n",
    "        \n",
    "        self.mask[:] = 0\n",
    "        polys = np.random.rand(10*4).reshape(10, 4)\n",
    "        wh = np.random.uniform(low=0.2, high=0.8, size=(2))\n",
    "        n = 5\n",
    "        tile_size = 512\n",
    "        max_n = np.random.randint(10)\n",
    "        #num = np.random.randint(5)\n",
    "        for i in range(max_n+1):\n",
    "            cv2.line(self.mask,(int(polys[i, 0]*tile_size), int(polys[i, 1]*tile_size)),\n",
    "                        (int(polys[i, 2]*tile_size), int(polys[i, 3]*tile_size)),(1),1*1)\n",
    "        polys = np.random.rand(10*4).reshape(10, 4)\n",
    "        wh = np.random.uniform(low=0.2, high=0.8, size=(2))\n",
    "        for i in range(max_n+1):\n",
    "            cv2.line(self.mask,(int(polys[i, 0]*tile_size), int(polys[i, 1]*tile_size)),\n",
    "                        (int(polys[i, 2]*tile_size), int(polys[i, 3]*tile_size)),(1),2*2)\n",
    "        polys = np.random.rand(10*4).reshape(10, 4)\n",
    "        wh = np.random.uniform(low=0.2, high=0.8, size=(2))\n",
    "        for i in range(max_n+1):\n",
    "            cv2.line(self.mask,(int(polys[i, 0]*tile_size), int(polys[i, 1]*tile_size)),\n",
    "                        (int(polys[i, 2]*tile_size), int(polys[i, 3]*tile_size)),(1),3*3)\n",
    "        \n",
    "        #self.mask = 1-self.mask\n",
    "        \n",
    "        ret_mask = cv2.resize(self.mask.astype(np.uint8), dsize=(img.shape[0], img.shape[1]), interpolation=cv2.INTER_CUBIC)\n",
    "        ret_mask = ret_mask[:, :, None]\n",
    "        img_anom = img\n",
    "        #if (np.random.randint(2) == 0):\n",
    "        #    img_anom = (self.distortion( np.array(img_anom).astype(np.uint8) ).copy()).astype(np.float32)\n",
    "        #else:\n",
    "        #    pass\n",
    "        img_anom = (self.aug.augment_image( np.array(img_anom).astype(np.uint8) ).copy()).astype(np.float32)\n",
    "        #self.mask[:] = 1\n",
    "        ret = (img - ret_mask*img) + (ret_mask * img_anom)#img_anom#(img - self.mask*img) + (self.mask * img_anom)\n",
    "        \n",
    "        return np.concatenate((ret, ret_mask), axis=2)\n",
    "\n",
    "ia_transform = ImgAugTransform()\n",
    "\n",
    "code_size = 512\n",
    "base_batch_size = 2 #16\n",
    "n_critic = 1\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Progressive Growing of GANs')\n",
    "\n",
    "parser.add_argument('path', type=str, help='path of specified dataset')\n",
    "parser.add_argument(\n",
    "    '--phase',\n",
    "    type=int,\n",
    "    default=20_000, #600_000\n",
    "    help='number of samples used for each training phases',\n",
    ")\n",
    "parser.add_argument('--lr', default=0.001, type=float, help='learning rate')\n",
    "parser.add_argument('--sched', action='store_true', help='use lr scheduling')\n",
    "parser.add_argument('--init_size', default=512, type=int, help='initial image size') #2^9\n",
    "parser.add_argument('--max_size', default=512, type=int, help='max image size')\n",
    "parser.add_argument(\n",
    "    '--ckpt', default='checkpoint/'+data_label+'/train_step-7.model', type=str, help='load from previous checkpoints'\n",
    ")\n",
    "parser.add_argument(\n",
    "    '--no_from_rgb_activate',\n",
    "    action='store_true',\n",
    "    help='use activate in from_rgb (original implementation)',\n",
    ")\n",
    "parser.add_argument(\n",
    "    '--mixing', action='store_true', help='use mixing regularization'\n",
    ")\n",
    "parser.add_argument(\n",
    "    '--loss',\n",
    "    type=str,\n",
    "    default='wgan-gp',\n",
    "    choices=['wgan-gp', 'r1'],\n",
    "    help='class of gan loss',\n",
    ")\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "#encoder = nn.DataParallel(\n",
    "#    Encoder(from_rgb_activate=not args.no_from_rgb_activate)\n",
    "#).cuda()\n",
    "#generator = nn.DataParallel(StyledGenerator(code_size)).cuda()\n",
    "\n",
    "g2_running = StyledGenerator2(code_size).cuda()\n",
    "\n",
    "g_running = StyledGenerator(code_size).cuda()\n",
    "#g_running.train(False)\n",
    "\n",
    "e_running = Encoder(from_rgb_activate=not args.no_from_rgb_activate).cuda()\n",
    "#e_running.train(False)\n",
    "\n",
    "g2_optimizer = optim.Adam(\n",
    "    g2_running.generator.parameters(), lr=args.lr, betas=(0.0, 0.99)\n",
    ")\n",
    "g2_optimizer.add_param_group(\n",
    "    {\n",
    "        'params': g2_running.style.parameters(),\n",
    "        'lr': args.lr * 0.01,\n",
    "        'mult': 0.01,\n",
    "    }\n",
    ")\n",
    "\n",
    "g_optimizer = optim.Adam(\n",
    "    g_running.generator.parameters(), lr=args.lr, betas=(0.0, 0.99)\n",
    ")\n",
    "g_optimizer.add_param_group(\n",
    "    {\n",
    "        'params': g_running.style.parameters(),\n",
    "        'lr': args.lr * 0.01,\n",
    "        'mult': 0.01,\n",
    "    }\n",
    ")\n",
    "\n",
    "e_optimizer = optim.Adam(e_running.parameters(), lr=args.lr, betas=(0.0, 0.99))\n",
    "\n",
    "#accumulate(g_running, generator.module, 0)\n",
    "#accumulate(e_running, encoder.module, 0)\n",
    "\n",
    "assert args.ckpt is not None\n",
    "ckpt = torch.load(args.ckpt)\n",
    "\n",
    "#generator.module.load_state_dict(ckpt['generator'])\n",
    "#g_running.load_state_dict(ckpt['g_running'])\n",
    "#g_optimizer.load_state_dict(ckpt['g_optimizer'])\n",
    "\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        #transforms.RandomHorizontalFlip(),\n",
    "        ia_transform,\n",
    "        #transforms.ToTensor(),\n",
    "        #transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5), inplace=True),\n",
    "    ]\n",
    ")\n",
    "\n",
    "transform2 = transforms.Compose(\n",
    "    [\n",
    "        #transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5), inplace=True),\n",
    "    ]\n",
    ")\n",
    "\n",
    "dataset = MultiResolutionDataset2(args.path, transform, transform2)\n",
    "\n",
    "if args.sched:\n",
    "    args.lr = {128: 0.0015, 256: 0.002, 512: 0.003, 1024: 0.003}\n",
    "    args.batch = {4: 128, 8: 64, 16: 32, 32: 16, 64: 8, 128: 8, 256: 2, 512: 2} #8\n",
    "\n",
    "else:\n",
    "    args.lr = {}\n",
    "    args.batch = {}\n",
    "\n",
    "args.gen_sample = {512: (8, 4), 1024: (4, 2)}\n",
    "\n",
    "args.batch_default = base_batch_size * 2\n",
    "\n",
    "\n",
    "def toImage(tensor):\n",
    "    A = tensor.clone()\n",
    "    A -= A.min()\n",
    "    A /= A.max()\n",
    "    \n",
    "    return A\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt = torch.load('checkpoint/'+data_label+'/train_step-7.model')\n",
    "#e_running.load_state_dict(ckpt['e_running'])\n",
    "g_running.load_state_dict(ckpt['g_running'])\n",
    "#g_running.load_state_dict(ckpt['g_running'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28 39 76 33 23  4 54 27 22 53]\n",
      "[28 39 76 33 23  4 54 27 22 53]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# randomly initialize the RNG from some platform-dependent source of entropy\n",
    "np.random.seed(None)\n",
    "\n",
    "# get the initial state of the RNG\n",
    "st0 = np.random.get_state()\n",
    "\n",
    "# draw some random numbers\n",
    "print(np.random.randint(0, 100, 10))\n",
    "# [ 8 76 76 33 77 26  3  1 68 21]\n",
    "\n",
    "# set the state back to what it was originally\n",
    "np.random.set_state(st0)\n",
    "\n",
    "# draw again\n",
    "print(np.random.randint(0, 100, 10))\n",
    "# [ 8 76 76 33 77 26  3  1 68 21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def get_holes(image, thresh):\n",
    "    gray = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "    im_bw = cv.threshold(gray, thresh, 255, cv.THRESH_BINARY)[1]\n",
    "    im_bw_inv = cv.bitwise_not(im_bw)\n",
    "\n",
    "    contour, _ = cv.findContours(im_bw_inv, cv.RETR_CCOMP, cv.CHAIN_APPROX_SIMPLE)\n",
    "    for cnt in contour:\n",
    "        cv.drawContours(im_bw_inv, [cnt], 0, 255, -1)\n",
    "\n",
    "    nt = cv.bitwise_not(im_bw)\n",
    "    im_bw_inv = cv.bitwise_or(im_bw_inv, nt)\n",
    "    return im_bw_inv\n",
    "\n",
    "\n",
    "def remove_background(image, thresh, scale_factor=.25, kernel_range=range(1, 15), border=None):\n",
    "    border = border or kernel_range[-1]\n",
    "\n",
    "    holes = get_holes(image, thresh)\n",
    "    small = cv.resize(holes, None, fx=scale_factor, fy=scale_factor)\n",
    "    bordered = cv.copyMakeBorder(small, border, border, border, border, cv.BORDER_CONSTANT)\n",
    "\n",
    "    for i in kernel_range:\n",
    "        kernel = cv.getStructuringElement(cv.MORPH_ELLIPSE, (2*i+1, 2*i+1))\n",
    "        bordered = cv.morphologyEx(bordered, cv.MORPH_CLOSE, kernel)\n",
    "\n",
    "    unbordered = bordered[border: -border, border: -border]\n",
    "    mask = cv.resize(unbordered, (image.shape[1], image.shape[0]))\n",
    "    fg = cv.bitwise_and(image, image, mask=mask)\n",
    "    return fg, mask\n",
    "\n",
    "def get_score(generator2, encoder, generator):\n",
    "    num_file = 0\n",
    "    r_list = []\n",
    "    for root, dirs, files in os.walk(\"./test/\"+data_label+\"/test/\"):\n",
    "        path = root.split(os.sep)\n",
    "        #print((len(path) - 1) * '---', os.path.basename(root))\n",
    "        if path[-1] == 'good' or path[-1] == '.ipynb_checkpoints':\n",
    "            continue\n",
    "        r_list_sub = []\n",
    "        for file in (sorted(files[:])):\n",
    "            if '.png' == file[-4:] and path[-1] != '':\n",
    "                #print()\n",
    "                # Open the image form working directory\n",
    "                anomaly = Image.open('./test/'+data_label+'/test/' + str(path[-1]) + '/' + file).convert('RGB')\n",
    "                gt = Image.open('./test/'+data_label+'/gt/' + str(path[-1]) + '/' + file[:-4] + '_mask.png')\n",
    "                gt = gt.resize((512, 512))\n",
    "                anomaly = anomaly.resize((512, 512))\n",
    "\n",
    "                gen_in1, gen_in2 = torch.randn(2, 1, code_size, device='cuda').chunk(\n",
    "                        2, 0\n",
    "                    )\n",
    "                gen_in1 = gen_in1.squeeze(0)\n",
    "\n",
    "                ground_truth = 1 - (torch.from_numpy(np.array(gt)[:, :]).permute(0, 1) / 255.0)\n",
    "                anomaly_image = torch.from_numpy(np.array(anomaly)[None, :, :, :]).permute(0, 3, 1, 2) / 255.0\n",
    "                anomaly_image = anomaly_image.cuda()\n",
    "\n",
    "                anomaly_image = anomaly_image\n",
    "                anomaly_image = anomaly_image * 2\n",
    "                anomaly_image = anomaly_image - 1.0\n",
    "\n",
    "                #out = encoder(anomaly_image, step=step, alpha=alpha)\n",
    "                (out, skiplist) = encoder(anomaly_image, step=step, alpha=alpha)\n",
    "                skiplist = skiplist[1:]\n",
    "                skiplist.insert(0, None)\n",
    "\n",
    "                out_orin, fake_image     = generator([gen_in1], styles=[out[:, :512]], step=step, alpha=alpha)\n",
    "                out_orin, (fake_image2, mask)     = generator2(skiplist, fake_image, anomaly_image, [gen_in1], styles=[out[:, 512:]], step=step, alpha=alpha)\n",
    "\n",
    "                gt_image = torch.from_numpy(np.array(gt)[None, :, :]) / 255.0\n",
    "                gt_image_im =torch.from_numpy(np.array(( toImage(torch.sum( gt_image.data[:, :, :], axis = 0) ) ) ))\n",
    "\n",
    "\n",
    "                fake_image_norm = (1 - mask) * fake_image + mask * anomaly_image\n",
    "\n",
    "\n",
    "                anomaly_image_norm = anomaly_image\n",
    "                anomaly_image_norm = (anomaly_image_norm - torch.min(anomaly_image_norm))\n",
    "                anomaly_image_norm = anomaly_image_norm / (torch.max(anomaly_image_norm) + 1e-6)\n",
    "\n",
    "                img_diff = mask\n",
    "                img_diff = torch.sum( torch.abs(img_diff), axis = 0)\n",
    "                img_diff = torch.from_numpy(np.array(( toImage(torch.sum( img_diff.data.cpu()[:, :, :], axis = 0) ) ) )).permute(0, 1)\n",
    "\n",
    "                fg = torch.from_numpy(np.array(( toImage( anomaly_image.data.cpu()[0, :, :, :] ) ) )).permute(1, 2, 0)\n",
    "                img = np.array(fg*255).astype(np.uint8)\n",
    "                nb_img, mask_fg = remove_background(img, 120)\n",
    "\n",
    "                kernel = np.ones((9,9),np.uint8)\n",
    "                img_diff = cv2.dilate(np.array(img_diff),kernel,iterations = 1)\n",
    "                ret = ((torch.tensor(img_diff) > 0.2) & (mask_fg > 0) )\n",
    "                gt = (gt_image_im > 0)\n",
    "\n",
    "                score = float(torch.sum ( ret & gt ).item()) / torch.sum ( ret | gt ).item()\n",
    "                \n",
    "                r_list_sub.append(score)\n",
    "            \n",
    "        r_list.append(r_list_sub)\n",
    "        \n",
    "    length = 0\n",
    "    sum_score = 0\n",
    "    for s_list in r_list:\n",
    "        length += len(s_list)\n",
    "        sum_score += sum(s_list)\n",
    "    \n",
    "    return sum_score / length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Size: 512; E: 0.097; G: 0.000;  Grad: 0.000; Alpha: 1.00000:   0%|          | 999/3000000 [03:06<199:00:16,  4.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07681572528798353\n",
      "001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Size: 512; E: 0.088; G: 0.000;  Grad: 0.000; Alpha: 1.00000:   0%|          | 1999/3000000 [07:54<245:56:26,  3.39it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15823801174198843\n",
      "002000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Size: 512; E: 0.070; G: 0.000;  Grad: 0.000; Alpha: 1.00000:   0%|          | 3999/3000000 [18:05<253:11:35,  3.29it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1649379840151192\n",
      "004000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Size: 512; E: 0.039; G: 0.000;  Grad: 0.000; Alpha: 1.00000:   0%|          | 4999/3000000 [23:09<220:24:29,  3.77it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24000147749409725\n",
      "005000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Size: 512; E: 0.028; G: 0.000;  Grad: 0.000; Alpha: 1.00000:   0%|          | 5999/3000000 [28:30<284:30:27,  2.92it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2674371448776942\n",
      "006000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Size: 512; E: 0.053; G: 0.000;  Grad: 0.000; Alpha: 1.00000:   0%|          | 7999/3000000 [38:53<258:31:58,  3.21it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3026808756594139\n",
      "008000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Size: 512; E: 0.049; G: 0.000;  Grad: 0.000; Alpha: 1.00000:   0%|          | 11999/3000000 [59:43<235:48:50,  3.52it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.31294718106836894\n",
      "012000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Size: 512; E: 0.030; G: 0.000;  Grad: 0.000; Alpha: 1.00000:   0%|          | 12999/3000000 [1:04:54<254:18:10,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3727348359223772\n",
      "013000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Size: 512; E: 0.032; G: 0.000;  Grad: 0.000; Alpha: 1.00000:   0%|          | 14999/3000000 [1:15:23<243:24:51,  3.41it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3805039425279266\n",
      "015000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Size: 512; E: 0.027; G: 0.000;  Grad: 0.000; Alpha: 1.00000:   1%|          | 15999/3000000 [1:20:48<328:15:11,  2.53it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4316559131551962\n",
      "016000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Size: 512; E: 0.037; G: 0.000;  Grad: 0.000; Alpha: 1.00000:   1%|          | 17999/3000000 [1:31:10<245:01:28,  3.38it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4398161569591399\n",
      "018000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Size: 512; E: 0.019; G: 0.000;  Grad: 0.000; Alpha: 1.00000:   1%|          | 32999/3000000 [2:49:47<286:52:24,  2.87it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.441476272858257\n",
      "033000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Size: 512; E: 0.020; G: 0.000;  Grad: 0.000; Alpha: 1.00000:   2%|▏         | 46999/3000000 [4:03:01<246:05:09,  3.33it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45065039424939174\n",
      "047000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Size: 512; E: 0.015; G: 0.000;  Grad: 0.000; Alpha: 1.00000:   2%|▏         | 48999/3000000 [4:13:29<236:37:29,  3.46it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4579884315365957\n",
      "049000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Size: 512; E: 0.016; G: 0.000;  Grad: 0.000; Alpha: 1.00000:   2%|▏         | 59999/3000000 [5:11:31<294:14:43,  2.78it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4586253110108075\n",
      "060000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Size: 512; E: 0.013; G: 0.000;  Grad: 0.000; Alpha: 1.00000:   2%|▏         | 67999/3000000 [5:53:42<251:08:53,  3.24it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4600679025170507\n",
      "068000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Size: 512; E: 0.019; G: 0.000;  Grad: 0.000; Alpha: 1.00000:   2%|▏         | 69999/3000000 [6:04:03<255:57:33,  3.18it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48550607831836395\n",
      "070000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Size: 512; E: 0.007; G: 0.000;  Grad: 0.000; Alpha: 1.00000:   7%|▋         | 222755/3000000 [19:24:23<241:57:20,  3.19it/s] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-9db551efb99d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;31m#fake_image_ori = generator(gen_in1, None, step=step, alpha=alpha) #skiplist, None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0mout_orin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfake_image\u001b[0m     \u001b[0;34m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgen_in1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstyles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#styles=[out],\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m     \u001b[0mout_orin2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfake_image2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mskiplist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfake_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manomaly_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgen_in1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstyles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m     \u001b[0;31m#out_orin2, (fake_image2, mask)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;31m#print(fake_image)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/notebooks/style-based-gan-pytorch/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, skiplist, fake_normal_image, anomaly_image, input, styles, noise, step, alpha, mean_style, style_weight, mixing_range)\u001b[0m\n\u001b[1;32m    757\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0mstyles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstyles_norm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mstyles_ori\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mskiplist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfake_normal_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manomaly_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstyles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmixing_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmixing_range\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/notebooks/style-based-gan-pytorch/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, skiplist, fake_normal_image, anomaly_image, style, noise, step, alpha, mixing_range)\u001b[0m\n\u001b[1;32m    673\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mskiplist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskiplist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstyle_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/notebooks/style-based-gan-pytorch/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, style, noise)\u001b[0m\n\u001b[1;32m    366\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnoise2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlrelu2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 368\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madain2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstyle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/notebooks/style-based-gan-pytorch/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, style)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstyle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m         \u001b[0mstyle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstyle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstyle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m         \u001b[0mgamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstyle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/notebooks/style-based-gan-pytorch/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1608\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1609\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1610\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1611\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1612\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "generator2 = g2_running\n",
    "encoder = e_running\n",
    "generator = g_running\n",
    "\n",
    "losses = []\n",
    "scores = []\n",
    "scores.append(0)\n",
    "step = int(math.log2(args.init_size)) - 2\n",
    "resolution = 4 * 2 ** step\n",
    "\n",
    "#anomaly_image = torch.from_numpy(np.array(resize_image)[None, :, :, :]).permute(0, 3, 1, 2) / 255.0\n",
    "#anomaly_image = anomaly_image.cuda()\n",
    "\n",
    "resize_image = image.resize((512, 512))\n",
    "anomaly_image = torch.from_numpy(np.array(resize_image)[None, :, :, :]).permute(0, 3, 1, 2) / 255.0\n",
    "anomaly_image = anomaly_image.cuda()\n",
    "anomaly_image = anomaly_image\n",
    "anomaly_image = anomaly_image * 2\n",
    "anomaly_image = anomaly_image - 1.0\n",
    "\n",
    "loader = sample_data(\n",
    "    dataset, args.batch.get(resolution, args.batch_default), resolution\n",
    ")\n",
    "data_loader = iter(loader)\n",
    "\n",
    "adjust_lr(g_optimizer, args.lr.get(resolution, 0.001))\n",
    "\n",
    "pbar = tqdm(range(3_000_000)) #3_000_000\n",
    "\n",
    "requires_grad(generator, False)\n",
    "\n",
    "gen_loss_val = 0\n",
    "grad_loss_val = 0\n",
    "\n",
    "alpha = 1\n",
    "used_sample = 0\n",
    "\n",
    "max_step = int(math.log2(args.max_size)) - 2\n",
    "final_progress = False\n",
    "\n",
    "\n",
    "for i in pbar:\n",
    "    if used_sample > args.phase * 2:\n",
    "        used_sample = 0\n",
    "        step += 1\n",
    "\n",
    "        if step > max_step:\n",
    "            step = max_step\n",
    "            final_progress = True\n",
    "            ckpt_step = step + 1\n",
    "\n",
    "        else:\n",
    "            ckpt_step = step\n",
    "\n",
    "        resolution = 4 * 2 ** step\n",
    "\n",
    "        loader = sample_data(\n",
    "            dataset, args.batch.get(resolution, args.batch_default), resolution\n",
    "        )\n",
    "        data_loader = iter(loader)\n",
    "\n",
    "        torch.save(\n",
    "            {\n",
    "                'g_optimizer': g_optimizer.state_dict(),\n",
    "                'g_running': g_running.state_dict(),\n",
    "                'e_running': e_running.state_dict(),\n",
    "            },\n",
    "            ('checkpoint/'+data_label+'/encdec/train_step-' + str(ckpt_step) + '.model'),\n",
    "        )\n",
    "\n",
    "        adjust_lr(g_optimizer, args.lr.get(resolution, 0.001))\n",
    "        #gc.collect()\n",
    "    try:\n",
    "        real_image, anomaly_img, mask_gt = next(data_loader)\n",
    "\n",
    "    except (OSError, StopIteration):\n",
    "        data_loader = iter(loader)\n",
    "        real_image, anomaly_img, mask_gt = next(data_loader)\n",
    "\n",
    "    used_sample += real_image.shape[0]\n",
    "\n",
    "    b_size = real_image.size(0)\n",
    "    real_image = real_image.cuda()\n",
    "    anomaly_img = anomaly_img.cuda()\n",
    "    mask_gt = mask_gt.unsqueeze(1)\n",
    "    mask_gt = mask_gt.cuda()\n",
    "    \n",
    "   \n",
    "\n",
    "    # Encoder \n",
    "    encoder.zero_grad()\n",
    "\n",
    "    requires_grad(encoder, True)\n",
    "    requires_grad(generator2, True)\n",
    "    requires_grad(generator, False)\n",
    "\n",
    "    gen_in1, gen_in2 = torch.randn(2, b_size, code_size, device='cuda').chunk(\n",
    "            2, 0\n",
    "        )\n",
    "    gen_in1 = gen_in1.squeeze(0)\n",
    "    \n",
    "    #print(gen_in1.shape)\n",
    "    \n",
    "    anomaly_img = anomaly_img\n",
    "    anomaly_img = anomaly_img / 255.0\n",
    "    anomaly_img = anomaly_img - 1.0\n",
    "    #anomaly_img = (anomaly_img - torch.min(anomaly_img))\n",
    "    #anomaly_img = anomaly_img / torch.max(anomaly_img)\n",
    "\n",
    "    #skiplist = encoder(real_image, step=step, alpha=alpha)\n",
    "    (out, skiplist) = encoder(anomaly_img, step=step, alpha=alpha)\n",
    "    skiplist = skiplist[1:]\n",
    "    skiplist.insert(0, None)\n",
    "    \n",
    "    #print(out)\n",
    "\n",
    "    #print(len(out))\n",
    "    #print(out[0].shape)\n",
    "    #out_list = []\n",
    "    #for it in range(out.shape[0]):\n",
    "    #    out_list.append(out[it:it+1])\n",
    "    #print(out_list[0].shape)\n",
    "    #for iii in skiplist:\n",
    "    #    if iii is None:\n",
    "    #        print(iii)\n",
    "    #    else:\n",
    "    #        print(iii.shape)\n",
    "    #print(\"\")\n",
    "    #print(\"Hey\")\n",
    "    #print(gen_in1.shape)\n",
    "    #print(out_zero.shape)\n",
    "    #print(out.shape)\n",
    "    #fake_image_ori = generator(gen_in1, None, step=step, alpha=alpha) #skiplist, None\n",
    "    out_orin, fake_image     = generator([gen_in1], styles=[out[:, :512]], step=step, alpha=alpha) #styles=[out],\n",
    "    out_orin2, (fake_image2, mask) = generator2(skiplist, fake_image, anomaly_img, [gen_in1], styles=[out[:, 512:]], step=step, alpha=alpha)\n",
    "    #out_orin2, (fake_image2, mask) \n",
    "    #print(fake_image)\n",
    "    #styles=[out[0], out[1]],\n",
    "    #print(real_image.shape)\n",
    "    #print(fake_image)\n",
    "    #print(len(fake_image))\n",
    "    #print(fake_image[0].shape)\n",
    "    #print(fake_image[0].shape)\n",
    "    #print(out.shape)\n",
    "\n",
    "    #skiplist = encoder(fake_image, step=step, alpha=alpha)\n",
    "\n",
    "    fake_image_norm = fake_image2\n",
    "    #fake_image_norm = (fake_image_norm - torch.min(fake_image_norm))\n",
    "    #fake_image_norm = fake_image_norm / torch.max(fake_image_norm)\n",
    "\n",
    "    anomaly_image_norm = real_image\n",
    "    #anomaly_image_norm = #(anomaly_image_norm - torch.min(anomaly_image_norm))\n",
    "    #anomaly_image_norm = #anomaly_image_norm / torch.max(anomaly_image_norm)\n",
    "\n",
    "    loss = nn.MSELoss(reduction = 'mean')\n",
    "    diff_norm = loss(fake_image_norm, anomaly_image_norm)\n",
    "    diff_norm2 = loss(fake_image, anomaly_image_norm)\n",
    "    diff_norm3 = loss(mask, mask_gt)\n",
    "    diff_norm4 = loss(fake_image, fake_image_norm)\n",
    "    #diff_norm = fake_image_norm - anomaly_image_norm\n",
    "    #diff_norm = torch.sum( torch.abs(diff_norm), axis = 0)\n",
    "    \n",
    "   \n",
    "    #recon_loss_pixel = torch.sum(torch.sum(torch.abs(diff_norm), -1)) # 코드가  비슷해짐, 근데 검어짐\n",
    "    recon_loss_pixel = torch.mean(diff_norm) + torch.mean(diff_norm2) + torch.mean(diff_norm3)+ torch.mean(diff_norm4)#loss(fake_image_norm, anomaly_image_norm) # 코드가  비슷해짐, 근데 검어짐\n",
    "    \n",
    "    #if i < 1000:\n",
    "    corr = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "    #recon_loss_info = (1-torch.mean(corr(out,out_orin[0])))\n",
    "    #else:\n",
    "    #    recon_loss_info = 0\n",
    "    loss_norm = torch.norm(mask)\n",
    "    \n",
    "    recon_loss = recon_loss_pixel #+ 0.1 * (loss_norm)#recon_loss_info + recon_loss_pixel # + recon_loss_mag #recon_loss_pixel#recon_loss_info#recon_loss_pixel + recon_loss_info# + recon_loss_feature\n",
    "    \n",
    "\n",
    "    if i%10 == 0:\n",
    "        encoder_loss_val = recon_loss.item()\n",
    "        losses.append(encoder_loss_val)\n",
    "    \n",
    "    recon_loss.backward()\n",
    "    #recon_loss_mag.backward()\n",
    "    #recon_loss_pixel.backward()\n",
    "    #recon_loss_info.backward()\n",
    "    #loss_norm.backward()\n",
    "    e_optimizer.step()\n",
    "    #accumulate(e_running, encoder.module)\n",
    "    requires_grad(generator2, False)\n",
    "    requires_grad(encoder, False)\n",
    "    requires_grad(generator, False)\n",
    "    \n",
    "    # Encoder End\n",
    "\n",
    "    if (i + 1) % 1000 == 0:\n",
    "        images = []\n",
    "\n",
    "        gen_i, gen_j = args.gen_sample.get(resolution, (10, 5))\n",
    "        \n",
    "        \n",
    "        #if step == 7:\n",
    "        #    anom = torch.cat((anomaly_image , anomaly_img[:1, :, :, :] ), 0)\n",
    "        #else:\n",
    "        anom = anomaly_img #torch.cat((anomaly_img[:, :, :, :] , anomaly_img[:1, :, :, :] ), 0)\n",
    "        (out_tmp, list_tmp) = encoder(anom, step=step, alpha=alpha)\n",
    "\n",
    "        images.append(anomaly_img.data.detach().cpu())\n",
    "        images.append((anom*2-1).data[:1].detach().cpu())\n",
    "        \n",
    "        list_tmp = list_tmp[1:]\n",
    "        list_tmp.insert(0, None)\n",
    "\n",
    "        fk2 = g2_running(\n",
    "            list_tmp, fake_image[:], anom, [gen_in1], styles=[out[:, 512:]], step=step, alpha=alpha\n",
    "        )\n",
    "        fk2_mask = torch.cat( [fk2[1][1].data[:1].detach().cpu(), fk2[1][1].data[:1].detach().cpu(),\n",
    "                               fk2[1][1].data[:1].detach().cpu()], axis=1)\n",
    "\n",
    "        fk3_mask = torch.cat( [fk2[1][1].data[1:].detach().cpu(), fk2[1][1].data[1:].detach().cpu(),\n",
    "                               fk2[1][1].data[1:].detach().cpu()], axis=1)      \n",
    "\n",
    "        with torch.no_grad():\n",
    "            for _ in range(1):#(gen_i):\n",
    "                #images.append(\n",
    "                #    g_running(\n",
    "                #        torch.randn(gen_j, code_size).cuda(), skiplist, step=step, alpha=alpha\n",
    "                #    ).data.detach().cpu()\n",
    "                #)\n",
    "                images.append(\n",
    "                    g_running(\n",
    "                        [out[:, :512]], styles=[out[:, :512]], step=step, alpha=alpha\n",
    "                    )[1].data.detach().cpu() \n",
    "                )\n",
    "                images.append(\n",
    "                    g_running(\n",
    "                        [out_tmp[:, :512]], styles=[out_tmp[:, :512]], step=step, alpha=alpha\n",
    "                    )[1].data[:1].detach().cpu() \n",
    "                )\n",
    "                images.append(\n",
    "                    fk2[1][0].data[:1].detach().cpu()\n",
    "                )\n",
    "                images.append(\n",
    "                    fk2_mask\n",
    "                )\n",
    "                \n",
    "                images.append(\n",
    "                    fk2[1][0].data[1:].detach().cpu()\n",
    "                )\n",
    "                images.append(\n",
    "                    fk3_mask\n",
    "                )\n",
    "                \n",
    "                #generator2(fake_image, real_image, [gen_in1], styles=[out], step=step, alpha=alpha)\n",
    "\n",
    "        utils.save_image(\n",
    "            torch.cat(images, 0),\n",
    "            'sample/'+data_label+'/encdec/'+str(i + 1).zfill(6)+ '.png',\n",
    "            nrow=gen_i,\n",
    "            normalize=True,\n",
    "            range=(-1, 1),\n",
    "        )\n",
    "        \n",
    "        latest_score = get_score(generator2, encoder, generator)\n",
    "        \n",
    "        if latest_score > max(scores):\n",
    "            print(latest_score)\n",
    "            print(str(i + 1).zfill(6))\n",
    "            torch.save(\n",
    "                g2_running.state_dict(), 'checkpoint/'+data_label+'/encdec/bestg2.model'\n",
    "            )\n",
    "            torch.save(\n",
    "                e_running.state_dict(), 'checkpoint/'+data_label+'/encdec/beste.model'\n",
    "            )\n",
    "        scores.append(latest_score)\n",
    "\n",
    "    if (i + 1) % 20000 == 0:\n",
    "        #torch.save(\n",
    "        #    g_running.state_dict(), 'checkpoint/'+data_label+'/encdec/prog'+str(i + 1).zfill(6)+'.model'\n",
    "        #)\n",
    "        torch.save(\n",
    "            g2_running.state_dict(), 'checkpoint/'+data_label+'/encdec/prog'+str(i + 1).zfill(6)+'g2.model'\n",
    "        )\n",
    "        torch.save(\n",
    "            e_running.state_dict(), 'checkpoint/'+data_label+'/encdec/prog'+str(i + 1).zfill(6)+'e.model'\n",
    "        )\n",
    "        \n",
    "    state_msg = (\n",
    "        f'Size: {4 * 2 ** step}; E: {encoder_loss_val:.3f}; G: {gen_loss_val:.3f}; '\n",
    "        f' Grad: {grad_loss_val:.3f}; Alpha: {alpha:.5f}'\n",
    "    )\n",
    "\n",
    "    pbar.set_description(state_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('MT19937',\n",
       " array([2147483648, 1973952246, 2700483622, 3062020305, 2909344801,\n",
       "        1116939581, 1008371610, 1249036225,  861768517, 2505248493,\n",
       "        3593500672,  227497116, 2298433495, 3516138394, 1044592035,\n",
       "        2361457843, 1291448833, 3685614512,  953746249, 3087288407,\n",
       "        3122638999,  786488974, 4197158251, 3744250015, 3836680439,\n",
       "        3384097227, 1656112966, 1328243768, 3803903442, 1794590777,\n",
       "        3145332185, 1201569261,  535702486, 3007142371, 1021677493,\n",
       "        4052770243, 3079164736, 2840641662, 3374635812, 4017673419,\n",
       "        2440034551, 1342282559, 2906900979,  780450199, 1347469560,\n",
       "        3690854515, 2138950941, 2727648487, 2107678168, 2212443201,\n",
       "        3491437067, 3083886467,  198888914, 3706326276, 1036374021,\n",
       "         558837500, 1342537693, 4139764033, 2584649342, 2992058692,\n",
       "         840155387, 2488245761, 1946839338, 2429375166, 2799784793,\n",
       "        4165585943, 2609904223, 2235539820,   78207713, 2314463581,\n",
       "         512636430, 2253907428, 2314024181, 3105193387, 2081201980,\n",
       "        1059868735, 2566816982, 3191313721, 2618899705, 4185702159,\n",
       "        4156691514,  439974695,  970727756, 3641007958, 1909829213,\n",
       "        1639680213,  924128085,  541040012, 2071509536, 4264109911,\n",
       "        3473305078, 2013017839, 3669509840, 3213132874, 1461875842,\n",
       "        3719908810, 2660804512, 2500447959, 2902883670, 3049650070,\n",
       "        2280062510, 3119422400, 3291235116, 2067131014, 3175961557,\n",
       "        4251093340, 2929952531, 1465678415,  827880688, 1570070811,\n",
       "        2555797302, 1571899842, 3638844828, 3312987622, 1243768114,\n",
       "        3926496346, 2315002612, 4270781536, 3033667090,  671206834,\n",
       "        1914074830, 2314281231, 3835370987, 2952378090, 2636323531,\n",
       "         800230652, 1667205503, 1280988201, 3903230494,  578160424,\n",
       "         242022588,  543463991, 3398326726, 2657224652, 3848927465,\n",
       "        2760842556, 2336807248, 1783203831,  731382696, 3783648406,\n",
       "        3481939618, 1906685355, 3189677054, 2300122474, 1323095588,\n",
       "        2164953876, 3457954700, 3660564092,  843216586, 1798359390,\n",
       "        3881090580, 4028195754, 2635893572, 2736021866, 3472349447,\n",
       "        2600357357, 3949033993, 2518155990, 2323997221, 3422301583,\n",
       "         422295315,  748128329, 3333825510, 3431666904, 1219090017,\n",
       "        3787487982, 2415393783, 3050164862, 3899292658, 2874521195,\n",
       "        3099942517, 3848414833,  909126808, 3153047137,  974517877,\n",
       "        2481977756, 3148087772, 2117111726,  523539236, 2548794296,\n",
       "        1893429459, 4233134014, 2321010071, 3788298879, 2289164713,\n",
       "        1314611109, 3988200391, 3866413415,  517050937, 1779625564,\n",
       "        1042419970, 1723599055, 4270989610,  950851314, 4227031075,\n",
       "        3106597241, 1173913008, 2525539366,  522526117, 4275761513,\n",
       "        2256400741,  752499300, 2703621141, 2456062327,  281151210,\n",
       "        2830069153, 1443325159, 3162197512, 3486388790, 2584346900,\n",
       "        3408730557, 2500274004, 4285581048, 4142642565, 3485708675,\n",
       "        3025231330, 2527948277, 3239471720, 1720646270, 4274492372,\n",
       "        4201274370, 1509035068, 1086389600,  128990147, 2616985796,\n",
       "        2258398018,  316414092, 4019749323, 2347423778, 2704760089,\n",
       "         422363180, 2498898241,  225355254,  825351951,  284592966,\n",
       "        2596815835,  602045514, 1594001804, 3258721116, 3358328927,\n",
       "        4169500669, 3359584929, 3883402856, 3858452392, 1363063862,\n",
       "        4171889735,  498887036, 1429587078, 3977040852, 3772989981,\n",
       "         523887689, 4030543150, 2743771746, 2510407919, 3804194463,\n",
       "         216058003, 1620554799, 1169552107,  564992381, 3760653940,\n",
       "        3478290970, 4125984323, 3742181517, 1919653848, 2666193650,\n",
       "         838751808, 2461468807,  878806386, 2166745613, 2228542170,\n",
       "         871429136,  566716852, 1933238722, 3475499833, 1709232752,\n",
       "         904101296, 1942781252, 3111470363, 2979005136, 1228797582,\n",
       "        4140512915, 1349250069,  621622525, 1524619724, 1279944482,\n",
       "        2584818911, 2462357604, 2643136504, 4048513399,  496577351,\n",
       "        1096441354, 2404453122, 1573332239,  433417467, 3204051193,\n",
       "        3777294999, 3226398166, 3443153412, 1624834153, 2633298919,\n",
       "        3038486963, 4080164028, 2723007533,  274662956, 1834633506,\n",
       "        4081512664,  279271093, 3705379976, 1274810868, 4153723514,\n",
       "         264250880,  560088785, 2870094026, 2961423229, 1969128750,\n",
       "        1469516932, 1144967894,  476178991, 3211490891, 3499051772,\n",
       "        3795958777,  718973572, 1774036077, 2425744582, 4072435956,\n",
       "        3769732127,  960847301, 1438805617, 4045856830,  979675866,\n",
       "        1019864057, 1306004171,  206257251, 1292892673, 1629236732,\n",
       "        3362084374,  573543895, 1687538059, 1508363639, 1726199984,\n",
       "        1313684933,  575985466, 3979185517, 3981965540, 1881171320,\n",
       "        4192427165, 1206831390, 2508229779, 4018982884,  459463852,\n",
       "        1281197053, 1487319253, 2591332172, 1607276563, 3840923839,\n",
       "        3686187493, 2587727861,  486683436, 3630197600, 3529653201,\n",
       "         670852452, 2021603393, 3306737832, 1394169354, 2138805971,\n",
       "        4096670880, 2435113540,  409891869,  898591991, 1708585288,\n",
       "        3786832550, 2710796224,  299613907, 3409149405,  357030791,\n",
       "        3886438933,  732087162, 2660887143, 4194963322,  425289802,\n",
       "         685880073,  306109808, 1429848857, 3449503208, 4102601264,\n",
       "        1637265608, 1093350395,  669726136, 1685799731,  303675319,\n",
       "        4156014135,  988359514, 2011185656, 2845577250, 1604995994,\n",
       "        2653012786, 2270159463, 2294470860,  173271987, 1004457901,\n",
       "        1889176674, 1583784056, 1147874811, 2151543918, 4033124588,\n",
       "        2924281891,   85950559, 4273575178,  803132806, 1049800940,\n",
       "        1288265529, 1828897297, 3613843982,  139471006, 1696383420,\n",
       "         303705193, 2998485121, 4039073889, 2084183402, 3715919151,\n",
       "         338089710, 1489895395,  459258719,  527835333, 1616152524,\n",
       "        3015006859, 3603760253, 3592277262, 1294164875, 2495690063,\n",
       "        3319680446,  523820363, 1650555929, 3037866124, 1488822445,\n",
       "        1702332708, 3984095600,   76344162,   43352405,  615790343,\n",
       "        2525113178,   46587704,  424405819, 3421621474,  425658807,\n",
       "         108533302, 3646567034,  909799497, 1822482200, 3165726447,\n",
       "        1191854298, 3400557283, 2560533718, 3459156096, 3731153124,\n",
       "        2002981072, 2549701857, 2620423822, 3647373398, 1035783855,\n",
       "        2491100755, 2802669059, 4236251744, 3102077590, 3955710527,\n",
       "        3821757653,  994145745, 4287395295, 3372348553, 4199331106,\n",
       "        3848494883, 1461655212, 1421732837, 3906510758, 2740857774,\n",
       "        2534494722, 4235347482, 3712826499, 1097083076, 1590545086,\n",
       "         222325368,  688451798,  543905339, 2500449114, 2284351456,\n",
       "         499480043, 4065257294, 3729837027, 2667705241, 1240921032,\n",
       "        3793253800, 2571905119, 1071701064,  266628458, 3211932178,\n",
       "        3878092629,  407821110, 1950733019,  982345629, 1408618918,\n",
       "        1963162635, 3005260750, 4055777662, 2835235149,  675424922,\n",
       "        3868338284,  126083315, 3783556247,  332707388, 3583327451,\n",
       "        2235413789, 2175671773, 2113619267, 2225006528, 2285317351,\n",
       "        3095660247, 4117857337, 2223831842, 1489271620,  859016832,\n",
       "        3342735142, 2824444903, 3900472908, 2798727106, 1082539950,\n",
       "          40257640, 3205483759, 3974122643, 2516664569, 1961321721,\n",
       "        2232657539, 3393710612,  647463967, 3251685822, 1489209219,\n",
       "        2337676517, 2613546911, 3837791422,  870792727, 1775252163,\n",
       "        1638256333, 2339484095,  400531839,   94957531, 1192700719,\n",
       "        1929662938, 3185649329, 3045812696, 1265055663, 2298783786,\n",
       "        2479483337, 2726021576,  245403448,  535002333, 1747592346,\n",
       "        3561231191, 2693433378,  736956515, 1731689815,  776749119,\n",
       "        3353886608, 1485829905,  554865410, 4279822155, 3337328867,\n",
       "        2645546049,  495798349,  409020370,  514554227, 2870385896,\n",
       "        3547741958,  196982958, 1867564472,  125470004, 2653690636,\n",
       "         794352939, 3619158543,  310853337,  684417307, 2560806129,\n",
       "        3912367993, 2679432986,  523210671, 1733424354, 2840681545,\n",
       "        4171473949, 1244889347, 1767175751, 1123284699, 2889174843,\n",
       "        2535366654, 2022346489, 3081940042, 3724428512, 1703896351,\n",
       "        2548310455,  749976379, 4256431325, 2928943828, 1546826113,\n",
       "        4184211518, 3069994882, 3140170203, 4176480739, 1446797908,\n",
       "        2936470728,  465604704, 2202354486, 1915101982, 3634121538,\n",
       "        4236133422,  175142947, 2886639046, 2129454274,  600165573,\n",
       "         586081117, 1058937222,  883701906, 2588052466, 2140742282,\n",
       "        1915654022, 3786257699,  843586856,  194498532], dtype=uint32),\n",
       " 624,\n",
       " 0,\n",
       " 0.0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0.07681572528798353,\n",
       " 0.15823801174198843,\n",
       " 0.14375657892854732,\n",
       " 0.1649379840151192,\n",
       " 0.24000147749409725,\n",
       " 0.2674371448776942,\n",
       " 0.25342091404310474,\n",
       " 0.3026808756594139,\n",
       " 0.29365830074689714,\n",
       " 0.19971747094819498,\n",
       " 0.19560848506239964,\n",
       " 0.31294718106836894,\n",
       " 0.3727348359223772,\n",
       " 0.363653746723367,\n",
       " 0.3805039425279266,\n",
       " 0.4316559131551962,\n",
       " 0.4271487367949082,\n",
       " 0.4398161569591399,\n",
       " 0.3041939228740437,\n",
       " 0.41823271521052596,\n",
       " 0.4057650560917065,\n",
       " 0.3963421301513099,\n",
       " 0.29153030103173155,\n",
       " 0.3837023667021972,\n",
       " 0.3695862069284389,\n",
       " 0.4240676969617158,\n",
       " 0.3718329493472246,\n",
       " 0.3989592922881014,\n",
       " 0.41507439142530356,\n",
       " 0.38584033947351576,\n",
       " 0.36049771749190007,\n",
       " 0.42236058212034566,\n",
       " 0.441476272858257,\n",
       " 0.421281103107415,\n",
       " 0.44011783343213096,\n",
       " 0.41338076156588804,\n",
       " 0.4175040939338306,\n",
       " 0.38260983803332516,\n",
       " 0.3586686352806997,\n",
       " 0.3692592179127893,\n",
       " 0.41976986628526897,\n",
       " 0.4051606680001207,\n",
       " 0.38355359515252024,\n",
       " 0.3810865750730608,\n",
       " 0.389684930817785,\n",
       " 0.37531505921337766,\n",
       " 0.45065039424939174,\n",
       " 0.40811487258902324,\n",
       " 0.4579884315365957,\n",
       " 0.4147875181714408,\n",
       " 0.42858560893697023,\n",
       " 0.4427553301026003,\n",
       " 0.4529016323777049,\n",
       " 0.4245998221607026,\n",
       " 0.44241894955888206,\n",
       " 0.4544915379390268,\n",
       " 0.43754239895509023,\n",
       " 0.4286016530885154,\n",
       " 0.3767288917070244,\n",
       " 0.4586253110108075,\n",
       " 0.43423801038339127,\n",
       " 0.41869249556401544,\n",
       " 0.23669716985900444,\n",
       " 0.40961198132287474,\n",
       " 0.449258937689855,\n",
       " 0.4068343041446937,\n",
       " 0.44796323641515845,\n",
       " 0.4600679025170507,\n",
       " 0.399352589834526,\n",
       " 0.48550607831836395,\n",
       " 0.4518948114022306,\n",
       " 0.4574753228919046,\n",
       " 0.4041501098085551,\n",
       " 0.40492220636019327,\n",
       " 0.4224224705655656,\n",
       " 0.3782679702004583,\n",
       " 0.40432077488969265,\n",
       " 0.35523697030606016,\n",
       " 0.3736840948118768,\n",
       " 0.28509107429641706,\n",
       " 0.35574813026170954,\n",
       " 0.35833869943470015,\n",
       " 0.3721940400324696,\n",
       " 0.4275985140778131,\n",
       " 0.340665824389153,\n",
       " 0.3651372633263423,\n",
       " 0.30574889533602806,\n",
       " 0.34613480214150305,\n",
       " 0.2899355645726618,\n",
       " 0.40857214044067947,\n",
       " 0.35930776602961845,\n",
       " 0.3370615381955867,\n",
       " 0.3085606438895227,\n",
       " 0.344974407300099,\n",
       " 0.3389078005873508,\n",
       " 0.28128550634388194,\n",
       " 0.37046946365987615,\n",
       " 0.3378945542366311,\n",
       " 0.3977687429452242,\n",
       " 0.37137564002643403,\n",
       " 0.330777583714492,\n",
       " 0.3816102870630257,\n",
       " 0.32066512780773265,\n",
       " 0.3602385801428366,\n",
       " 0.3118676677388486,\n",
       " 0.30560688305353534,\n",
       " 0.3552500219694367,\n",
       " 0.28707280329454904,\n",
       " 0.3486387548085662,\n",
       " 0.3378739013070319,\n",
       " 0.2711083601226377,\n",
       " 0.26914559428708973,\n",
       " 0.3751745158526099,\n",
       " 0.2887666509720487,\n",
       " 0.355347081185528,\n",
       " 0.3172209408342665,\n",
       " 0.32574715422390016,\n",
       " 0.28225704666812135,\n",
       " 0.3339192979569173,\n",
       " 0.32104722439447275,\n",
       " 0.30771022548806604,\n",
       " 0.33024033987342927,\n",
       " 0.35833858927819323,\n",
       " 0.31007658095391855,\n",
       " 0.25497582392462637,\n",
       " 0.28320819818260384,\n",
       " 0.30064597725772213,\n",
       " 0.28580832059538996,\n",
       " 0.3198647449197131,\n",
       " 0.2990285603177576,\n",
       " 0.2866686358212411,\n",
       " 0.3081435242223618,\n",
       " 0.27549583840679104,\n",
       " 0.27106540506953153,\n",
       " 0.27249975799462284,\n",
       " 0.3166637161643568,\n",
       " 0.3057309422199371,\n",
       " 0.31294328221735207,\n",
       " 0.2889199838406798,\n",
       " 0.2753650767855865,\n",
       " 0.310911025850086,\n",
       " 0.2521836696830595,\n",
       " 0.27878890128365946,\n",
       " 0.2799349620850023,\n",
       " 0.28576940755143626,\n",
       " 0.2882085081013494,\n",
       " 0.26728159868202,\n",
       " 0.29232521985480425,\n",
       " 0.25363606745506173,\n",
       " 0.2283868565573222,\n",
       " 0.267358125018951,\n",
       " 0.27084728374995465,\n",
       " 0.2677520237355525,\n",
       " 0.18876590767773024,\n",
       " 0.2619234915585226,\n",
       " 0.27389776476450123,\n",
       " 0.2785939550893903,\n",
       " 0.27576135864917617,\n",
       " 0.2729203643683115,\n",
       " 0.2657684385357863,\n",
       " 0.2505309621195639,\n",
       " 0.09252011625199243,\n",
       " 0.2618506631328013,\n",
       " 0.2409485981250953,\n",
       " 0.2583400165100121,\n",
       " 0.24052417344769894,\n",
       " 0.2705769623603195,\n",
       " 0.2419432370785478,\n",
       " 0.2782603985634764,\n",
       " 0.2574415692487548,\n",
       " 0.21202359394765416,\n",
       " 0.26145742767316,\n",
       " 0.28171104280397846,\n",
       " 0.21530966328513612,\n",
       " 0.2685076993000334,\n",
       " 0.23055041600839843,\n",
       " 0.2488533526460811,\n",
       " 0.23678016556637782,\n",
       " 0.23938560184881108,\n",
       " 0.21251234980102204,\n",
       " 0.24532196638196657,\n",
       " 0.259638694697279,\n",
       " 0.2415987992200738,\n",
       " 0.2630475926340076,\n",
       " 0.24884231926822512,\n",
       " 0.2362621807327384,\n",
       " 0.2318993328594262,\n",
       " 0.2171721050458754,\n",
       " 0.22738913946005418,\n",
       " 0.22508315819457084,\n",
       " 0.2471693398494668,\n",
       " 0.21605534296410167,\n",
       " 0.27915125089400405,\n",
       " 0.22108254063119953,\n",
       " 0.25445661616438775,\n",
       " 0.21474324620448434,\n",
       " 0.23301317263516616,\n",
       " 0.18230274003282557,\n",
       " 0.22284861921597104,\n",
       " 0.24262548138505236,\n",
       " 0.19420626401102659,\n",
       " 0.21405954737377972,\n",
       " 0.21387931684556974,\n",
       " 0.21897319146113772,\n",
       " 0.24716100988614775,\n",
       " 0.20197814626963478,\n",
       " 0.17324377144538436,\n",
       " 0.1719379216780688,\n",
       " 0.20103951646627252,\n",
       " 0.23274351256031603,\n",
       " 0.190245372677811,\n",
       " 0.20837463828611483,\n",
       " 0.19881562015854637,\n",
       " 0.18127410551480883,\n",
       " 0.18117615773490658,\n",
       " 0.202249088768102,\n",
       " 0.24067966435081475,\n",
       " 0.2081755895624925,\n",
       " 0.18722771333712415,\n",
       " 0.2517433931704957,\n",
       " 0.18377706296196458,\n",
       " 0.2221013712960664]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot((np.array(losses[1:]) - np.array(losses[:-1])))\n",
    "plt.ylabel('some numbers')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(np.log( (np.array(losses[1:])) ))\n",
    "plt.ylabel('some numbers')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir sample/tile/encdec/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skiplist[-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step = 8\n",
    "for i in range(step, -1, -1):\n",
    "    print(i)\n",
    "    print(\"0\" + str(step - i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.min(fake_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.min(anomaly_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly_img = anomaly_img\n",
    "anomaly_img = anomaly_img / 255.0\n",
    "anomaly_img = anomaly_img - 1.0\n",
    "\n",
    "torch.min(anomaly_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.min(anomaly_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.min(real_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        torch.save(\n",
    "            g_running.state_dict(), 'checkpoint/capsule/encdec/'+str(i + 1).zfill(6)+'.model'\n",
    "        )\n",
    "        torch.save(\n",
    "            g2_running.state_dict(), 'checkpoint/capsule/encdec/'+str(i + 1).zfill(6)+'g2.model'\n",
    "        )\n",
    "        torch.save(\n",
    "            e_running.state_dict(), 'checkpoint/capsule/encdec/'+str(i + 1).zfill(6)+'e.model'\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'checkpoint/capsule/encdec/'+str(i + 1).zfill(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.norm(mask) * 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(list_tmp)):\n",
    "    if (list_tmp[i] == None):\n",
    "        print(\"None\")\n",
    "    else:\n",
    "        print(list_tmp[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(skiplist)):\n",
    "    if (skiplist[i] == None):\n",
    "        print(\"None\")\n",
    "    else:\n",
    "        print(skiplist[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cat( [skiplist[0], skiplist[0]], axis=1 ).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.max(fake_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.max(anomaly_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cat( [fk2[1][1].data[:1].detach().cpu(), fk2[1][1].data[:1].detach().cpu(), fk2[1][1].data[:1].detach().cpu()], axis = 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g2_running(\n",
    "                        fake_image, anomaly_img, [gen_in1], styles=[out[:, 512:]], step=step, alpha=alpha\n",
    "                    )[1][1].data[:1].detach().cpu().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'checkpoint/capsule/encdec/'+str(i + 1).zfill(6)+'g2.model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(\n",
    "#    g2_running.state_dict(), 'checkpoint/capsule/encdec/'+str(i + 1).zfill(6)+'g2.model'\n",
    "#)\n",
    "#torch.save(\n",
    "#    e_running.state_dict(), 'checkpoint/capsule/encdec/'+str(i + 1).zfill(6)+'e.model'\n",
    "#)\n",
    "#torch.save(\n",
    "#    g_running.state_dict(), 'checkpoint/capsule/encdec/'+str(i + 1).zfill(6)+'g.model'\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = torch.load('checkpoint/capsule/encdec/prog070000e.model')\n",
    "e_running.load_state_dict(ckpt)\n",
    "ckpt = torch.load('checkpoint/capsule/encdec/prog070000.model')\n",
    "g_running.load_state_dict(ckpt)\n",
    "ckpt = torch.load('checkpoint/capsule/encdec/prog070000g2.model')\n",
    "g2_running.load_state_dict(ckpt)\n",
    "\n",
    "#ckpt = torch.load('checkpoint/capsule/encdec/020000e.model')\n",
    "#e_running.load_state_dict(ckpt)\n",
    "#ckpt = torch.load('checkpoint/capsule/encdec/020000.model')\n",
    "#g_running.load_state_dict(ckpt)\n",
    "#ckpt = torch.load('checkpoint/capsule/encdec/020000g2.model')\n",
    "#g2_running.load_state_dict(ckpt)\n",
    "\n",
    "generator2 = g2_running\n",
    "encoder = e_running\n",
    "generator = g_running\n",
    "\n",
    "\n",
    "resize_image = image.resize((256, 256))\n",
    "anomaly_image = torch.from_numpy(np.array(resize_image)[None, :, :, :]).permute(0, 3, 1, 2) / 255.0\n",
    "anomaly_image = anomaly_image.cuda()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "resolution = 512\n",
    "encoder = e_running\n",
    "generator = g_running\n",
    "step = 7\n",
    "alpha = 1\n",
    "\n",
    "gen_in1, gen_in2 = torch.randn(2, 1, code_size, device='cuda').chunk(\n",
    "                    2, 0\n",
    "                )\n",
    "gen_in1 = gen_in1.squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls ./test/capsule/test/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ckpt =  torch.load('checkpoint/capsule/090000.model')\n",
    "#g_running.load_state_dict(ckpt)\n",
    "#ckpt =  torch.load('checkpoint/capsule/090000enc.model')\n",
    "#e_running.load_state_dict(ckpt)\n",
    "\n",
    "#ckpt = torch.load('checkpoint/capsule/encdec/213464.model')\n",
    "#g_running.load_state_dict(ckpt)\n",
    "#ckpt = torch.load('checkpoint/capsule/encdec/encoder213464.model')\n",
    "#e_running.load_state_dict(ckpt)\n",
    "\n",
    "import cv2 as cv\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def get_holes(image, thresh):\n",
    "    gray = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "    im_bw = cv.threshold(gray, thresh, 255, cv.THRESH_BINARY)[1]\n",
    "    im_bw_inv = cv.bitwise_not(im_bw)\n",
    "\n",
    "    contour, _ = cv.findContours(im_bw_inv, cv.RETR_CCOMP, cv.CHAIN_APPROX_SIMPLE)\n",
    "    for cnt in contour:\n",
    "        cv.drawContours(im_bw_inv, [cnt], 0, 255, -1)\n",
    "\n",
    "    nt = cv.bitwise_not(im_bw)\n",
    "    im_bw_inv = cv.bitwise_or(im_bw_inv, nt)\n",
    "    return im_bw_inv\n",
    "\n",
    "\n",
    "def remove_background(image, thresh, scale_factor=.25, kernel_range=range(1, 15), border=None):\n",
    "    border = border or kernel_range[-1]\n",
    "\n",
    "    holes = get_holes(image, thresh)\n",
    "    small = cv.resize(holes, None, fx=scale_factor, fy=scale_factor)\n",
    "    bordered = cv.copyMakeBorder(small, border, border, border, border, cv.BORDER_CONSTANT)\n",
    "\n",
    "    for i in kernel_range:\n",
    "        kernel = cv.getStructuringElement(cv.MORPH_ELLIPSE, (2*i+1, 2*i+1))\n",
    "        bordered = cv.morphologyEx(bordered, cv.MORPH_CLOSE, kernel)\n",
    "\n",
    "    unbordered = bordered[border: -border, border: -border]\n",
    "    mask = cv.resize(unbordered, (image.shape[1], image.shape[0]))\n",
    "    fg = cv.bitwise_and(image, image, mask=mask)\n",
    "    return fg, mask\n",
    "\n",
    "num_file = 0\n",
    "r_list = []\n",
    "# traverse root directory, and list directories as dirs and files as files\n",
    "for root, dirs, files in os.walk(\"./test/tile/test/\"):\n",
    "    path = root.split(os.sep)\n",
    "    #print(path)\n",
    "    print((len(path) - 1) * '---', os.path.basename(root))\n",
    "    if path[-1] == 'good':\n",
    "        continue\n",
    "    r_list_sub = []\n",
    "    for file in tqdm(sorted(files[:])):\n",
    "        if '.png' == file[-4:] and path[-1] != '':\n",
    "            #print()\n",
    "            # Open the image form working directory\n",
    "            anomaly = Image.open('./test/tile/test/' + str(path[-1]) + '/' + file)\n",
    "            gt = Image.open('./test/tile/gt/' + str(path[-1]) + '/' + file[:-4] + '_mask.png')\n",
    "            gt = gt.resize((512, 512))\n",
    "            anomaly = anomaly.resize((512, 512))\n",
    "            #resize_image = image\n",
    "            #anomaly_image = torch.from_numpy(np.array(resize_image)[None, :, :, :]).permute(0, 3, 1, 2) / 255.0\n",
    "            #anomaly_image = anomaly_image.cuda()\n",
    "            #plt.imshow( gt )\n",
    "            \n",
    "            #plt.imshow( toImage(resize_image.data.detach().cpu()[0]).permute(1, 2, 0)  )\n",
    "            \n",
    "            gen_in1, gen_in2 = torch.randn(2, 1, code_size, device='cuda').chunk(\n",
    "                    2, 0\n",
    "                )\n",
    "            gen_in1 = gen_in1.squeeze(0)\n",
    "\n",
    "            ground_truth = 1 - (torch.from_numpy(np.array(gt)[:, :]).permute(0, 1) / 255.0)\n",
    "            anomaly_image = torch.from_numpy(np.array(anomaly)[None, :, :, :]).permute(0, 3, 1, 2) / 255.0\n",
    "            anomaly_image = anomaly_image.cuda()\n",
    "            \n",
    "            anomaly_image = anomaly_image\n",
    "            anomaly_image = anomaly_image * 2\n",
    "            anomaly_image = anomaly_image - 1.0\n",
    "\n",
    "            #out = encoder(anomaly_image, step=step, alpha=alpha)\n",
    "            (out, skiplist) = encoder(anomaly_image, step=step, alpha=alpha)\n",
    "            skiplist = skiplist[1:]\n",
    "            skiplist.insert(0, None)\n",
    "\n",
    "            out_orin, fake_image     = generator([gen_in1], styles=[out[:, :512]], step=step, alpha=alpha)\n",
    "            out_orin, (fake_image2, mask)     = generator2(skiplist, fake_image, anomaly_image, [gen_in1], styles=[out[:, 512:]], step=step, alpha=alpha)\n",
    "            \n",
    "            #fake_image = fake_image[0] / 255.0\n",
    "            \n",
    "            gt_image = torch.from_numpy(np.array(gt)[None, :, :]) / 255.0\n",
    "            #gt_image = gt_image.cuda()\n",
    "            gt_image_im =torch.from_numpy(np.array(( toImage(torch.sum( gt_image.data[:, :, :], axis = 0) ) ) ))\n",
    "            \n",
    "            \n",
    "            fake_image_norm = (1 - mask) * fake_image + mask * anomaly_image\n",
    "\n",
    "\n",
    "            anomaly_image_norm = anomaly_image\n",
    "            anomaly_image_norm = (anomaly_image_norm - torch.min(anomaly_image_norm))\n",
    "            anomaly_image_norm = anomaly_image_norm / (torch.max(anomaly_image_norm) + 1e-6)\n",
    "\n",
    "            \n",
    "            img_diff = mask\n",
    "            #img_diff = fake_image_norm - anomaly_image_norm#mask#\n",
    "            img_diff = torch.sum( torch.abs(img_diff), axis = 0)\n",
    "            img_diff = torch.from_numpy(np.array(( toImage(torch.sum( img_diff.data.cpu()[:, :, :], axis = 0) ) ) )).permute(0, 1)\n",
    "            #plt.imshow( img_diff  )\n",
    "            \n",
    "            #img_diff = mask\n",
    "            fg = torch.from_numpy(np.array(( toImage( anomaly_image.data.cpu()[0, :, :, :] ) ) )).permute(1, 2, 0)\n",
    "            img = np.array(fg*255).astype(np.uint8)\n",
    "            nb_img, mask_fg = remove_background(img, 120)\n",
    "            \n",
    "            #diff = diff * ground_truth.expand_as(diff)\n",
    "            kernel = np.ones((9,9),np.uint8)\n",
    "            img_diff = cv2.dilate(np.array(img_diff),kernel,iterations = 1)\n",
    "            ret = ((torch.tensor(img_diff) > 0.2) & (mask_fg > 0) )\n",
    "            gt = (gt_image_im > 0)\n",
    "            \n",
    "            score = float(torch.sum ( ret & gt ).item()) / torch.sum ( ret | gt ).item()\n",
    "            \n",
    "            #plt.imshow( diff )\n",
    "            r_list_sub.append(score)\n",
    "            \n",
    "    r_list.append(r_list_sub)\n",
    "            #r_list.append((torch.sum(diff) / torch.sum(ground_truth) ).item())\n",
    "            #num_file += 1\n",
    "            #plt.imsave('./test/'+'result/'+str(num_file)+'.png', diff)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = 0\n",
    "sum_score = 0\n",
    "for s_list in r_list:\n",
    "    length += len(s_list)\n",
    "    sum_score += sum(s_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_score / length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(r_list) / len(r_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(r_list) / len(r_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(r_list) / len(r_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(r_list) / len(r_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_score / length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_l = [\"crack\", \"squeeze\", \"faulty_imprint\", \"poke\", \"scratch\"]\n",
    "\n",
    "k = 0\n",
    "for i in range(len(r_list)):\n",
    "    if len(r_list[i]) > 0:\n",
    "        print(str_l[k])\n",
    "        print(sum(r_list[i]) / len(r_list[i]))\n",
    "        k += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(r_list) / len(r_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img =torch.from_numpy(np.array(( diff_norm.data.cpu()[0, :, :, :] ) )).permute(1, 2, 0)  #[:, :, :] #.permute(1, 2)\n",
    "img_diff_ =torch.from_numpy(np.array(( toImage( mask.data.cpu()[0, 0, :, :] ) ) ))#.permute(1, 2, 0)\n",
    "plt.imshow( img_diff_   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img =torch.from_numpy(np.array(( diff_norm.data.cpu()[0, :, :, :] ) )).permute(1, 2, 0)  #[:, :, :] #.permute(1, 2)\n",
    "img_diff__ =torch.from_numpy(np.array(( toImage( anomaly_image.data.cpu()[0, :, :, :] ) ) )).permute(1, 2, 0)\n",
    "plt.imshow( img_diff__  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.array(img_diff__*255).astype(np.uint8)\n",
    "nb_img, mask_fg = remove_background(img, 120)\n",
    "plt.imshow( mask_fg )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.array(img_diff__*255).astype(np.uint8)\n",
    "plt.imshow( img )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_diff__.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow( (img_diff_ > 0.2) & (mask_fg > 0)  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow( img_diff_ > 0.2  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = np.ones((5,5),np.uint8)\n",
    "rt = cv2.dilate(np.array(img_diff_),kernel,iterations = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow( rt > 0.2  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img =torch.from_numpy(np.array(( diff_norm.data.cpu()[0, :, :, :] ) )).permute(1, 2, 0)  #[:, :, :] #.permute(1, 2)\n",
    "img_diff_ =torch.from_numpy(np.array(( toImage( img_diff.data.cpu()[:, :] - torch.mean(img_diff) ) ) ))#.permute(1, 2, 0)\n",
    "plt.imshow( img_diff_  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img =torch.from_numpy(np.array(( diff_norm.data.cpu()[0, :, :, :] ) )).permute(1, 2, 0)  #[:, :, :] #.permute(1, 2)\n",
    "img_diff =torch.from_numpy(np.array(( toImage( gt_image_im.data.cpu() ) ) ))#.permute(1, 2, 0)\n",
    "plt.imshow( img_diff  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img =torch.from_numpy(np.array(( diff_norm.data.cpu()[0, :, :, :] ) )).permute(1, 2, 0)  #[:, :, :] #.permute(1, 2)\n",
    "img_diff =torch.from_numpy(np.array(( toImage( gt_image_im.data.cpu() ) ) ))#.permute(1, 2, 0)\n",
    "plt.imshow( img_diff  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img =torch.from_numpy(np.array(( diff_norm.data.cpu()[0, :, :, :] ) )).permute(1, 2, 0)  #[:, :, :] #.permute(1, 2)\n",
    "img_diff =torch.from_numpy(np.array(( toImage( anomaly_image.data.cpu()[0, :, :, :] ) ) )).permute(1, 2, 0)\n",
    "plt.imshow( img_diff  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(r_list) / len(r_list) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#squeeze\n",
    "gt_image = Image.open('test/capsule/gt/squeeze/001_mask.png')\n",
    "gt_resize_image = gt_image.resize((resolution, resolution))\n",
    "\n",
    "gt_image = torch.from_numpy(np.array(gt_resize_image)[None, :, :]) / 255.0\n",
    "gt_image = gt_image.cuda()\n",
    "\n",
    "#img =torch.from_numpy(np.array(( diff_norm.data.cpu()[0, :, :, :] ) )).permute(1, 2, 0)  #[:, :, :] #.permute(1, 2)\n",
    "gt_image_im =torch.from_numpy(np.array(( toImage(torch.sum( gt_image.data.cpu()[:, :, :], axis = 0) ) ) ))\n",
    "plt.imshow( gt_image_im  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loader = sample_data(\n",
    "            dataset, 1, resolution\n",
    "        )\n",
    "data_loader = iter(loader)\n",
    "real_image, anomaly_img, mask_gt = next(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open('test/capsule/test/squeeze/001.png')\n",
    "#image = Image.open('mvtec_single_dataset/capsule/000.png')\n",
    "resize_image_real = image.resize((resolution, resolution))\n",
    "resize_image_ano = transform(resize_image_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_image.requires_grad = True\n",
    "real_image = torch.from_numpy(np.array(resize_image_real)[None, :, :, :3]).permute(0, 3, 1, 2) / 255.0\n",
    "real_image = real_image.cuda()\n",
    "\n",
    "anomaly_image.requires_grad = True\n",
    "anomaly_image = torch.from_numpy(np.array(resize_image_ano)[None, :, :, :3]).permute(0, 3, 1, 2) / 255.0\n",
    "anomaly_image = anomaly_img.cuda()\n",
    "#anomaly_image.requires_grad = True\n",
    "#anomaly_image = anomaly_img.cuda()\n",
    "\n",
    "#anomaly_image = anomaly_img.cuda()\n",
    "#real_image = anomaly_image#real_image.cuda()\n",
    "#real_image = real_image.cuda()\n",
    "#var_xs_h = Variable((anomaly_image).data, requires_grad=True)\n",
    "(out, out_list) = e_running(real_image, step=step, alpha=1)\n",
    "#out = Variable(out.data, requires_grad=True)\n",
    "out_list = out_list[1:]\n",
    "out_list.insert(0, None)\n",
    "#out_orin, fake_image     = generator([gen_in1], step=step, alpha=1) # styles=[out],\n",
    "out_orin, fake_image     = g_running([gen_in1[:1, :]], styles=[out[:, :512]], step=step, alpha=1) # \n",
    "out_orin2, (fake_image2, mask)     = g2_running(out_list, real_image, fake_image, [gen_in1[:1, :]], styles=[out[:, 512:]], step=step, alpha=1) # \n",
    "#out_orin2, fake_image2     = g_running([gen_in1], step=step, alpha=1) # \n",
    "#inter = encoder.self.progression[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_image_norm = fake_image2\n",
    "#fake_image_norm = (fake_image_norm - torch.min(fake_image_norm))\n",
    "#fake_image_norm = fake_image_norm / torch.max(fake_image_norm)\n",
    "\n",
    "anomaly_image_norm = real_image\n",
    "anomaly_image_norm = (anomaly_image_norm - torch.min(anomaly_image_norm))\n",
    "anomaly_image_norm = anomaly_image_norm / torch.max(anomaly_image_norm)\n",
    "\n",
    "loss = nn.MSELoss(reduction = 'mean')\n",
    "diff_norm = loss(fake_image_norm, anomaly_image_norm)\n",
    "diff_norm2 = loss(fake_image, anomaly_image)\n",
    "#diff_norm = fake_image_norm - anomaly_image_norm\n",
    "#diff_norm = torch.sum( torch.abs(diff_norm), axis = 0)\n",
    "\n",
    "\n",
    "#recon_loss_pixel = torch.sum(torch.sum(torch.abs(diff_norm), -1)) # 코드가  비슷해짐, 근데 검어짐\n",
    "recon_loss_pixel = torch.mean(diff_norm) + torch.mean(diff_norm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fake_image_norm = fake_image2\n",
    "#fake_image_norm = (fake_image_norm - torch.min(fake_image_norm))\n",
    "#fake_image_norm = fake_image_norm / torch.max(fake_image_norm)\n",
    "\n",
    "fake_image_norm = (1 - mask) * fake_image + mask * anomaly_image\n",
    "\n",
    "real_image = (real_image - torch.min(real_image))\n",
    "real_image = real_image / (torch.max(real_image) + 1e-6)\n",
    "\n",
    "anomaly_image_norm = anomaly_image\n",
    "anomaly_image_norm = (anomaly_image_norm - torch.min(anomaly_image_norm))\n",
    "anomaly_image_norm = anomaly_image_norm / (torch.max(anomaly_image_norm) + 1e-6)\n",
    "\n",
    "diff_norm2 = fake_image - anomaly_image_norm\n",
    "diff_norm2 = torch.sum( torch.abs(diff_norm2), axis = 0)\n",
    "#diff_norm = (torch.mean( torch.abs(diff_norm), axis = 0))\n",
    "#diff_norm = (diff_norm - torch.min(diff_norm))\n",
    "#diff_norm = diff_norm / torch.max(diff_norm)\n",
    "\n",
    "\n",
    "diff_norm = fake_image_norm - real_image\n",
    "diff_norm = torch.sum( torch.abs(diff_norm), axis = 0)\n",
    "#diff_norm = torch.sum( torch.abs(diff_norm), axis = 0)\n",
    "\n",
    "\n",
    "#loss = nn.MSELoss()\n",
    "#recon_loss = loss(fake_image_norm, anomaly_image_norm)\n",
    "#\n",
    "#diff_norm = torch.clamp(diff_norm, min=0.3)\n",
    "#torch.abs\n",
    "recon_loss_pixel = torch.sum(torch.sum(torch.abs(diff_norm), -1)) # 코드가  비슷해짐, 근데 검어짐\n",
    "#recon_loss_pixel = torch.mean(diff_norm)#torch.mean(torch.mean(torch.abs(diff_norm), axis=0)) # 코드가  비슷해짐, 근데 검어짐\n",
    "\n",
    "#recon_loss_pixel = torch.clamp(recon_loss_pixel - 0.4, min=0)\n",
    "\n",
    "#corr = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "#recon_loss_info = 1-torch.mean(corr(out,out_orin[0]))\n",
    "\n",
    "#recon_loss_pixel.backward()\n",
    "#recon_loss = recon_loss_pixel#recon_loss_pixel# + recon_loss_mag #recon_loss_pixel#recon_loss_info#recon_loss_pixel + recon_loss_info# + recon_loss_feature\n",
    "#recon_loss = recon_loss_pixel\n",
    "#recon_loss_info.backward(retain_graph=True)\n",
    "#recon_loss_pixel.backward(retain_graph=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.min(real_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img =torch.from_numpy(np.array(( diff_norm.data.cpu()[0, :, :, :] ) )).permute(1, 2, 0)  #[:, :, :] #.permute(1, 2)\n",
    "img_diff =torch.from_numpy(np.array(( toImage( real_image.data.cpu()[0, :, :, :] ) ) )).permute(1, 2, 0)\n",
    "plt.imshow( img_diff  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img =torch.from_numpy(np.array(( diff_norm.data.cpu()[0, :, :, :] ) )).permute(1, 2, 0)  #[:, :, :] #.permute(1, 2)\n",
    "img_diff2 =torch.from_numpy(np.array(( toImage( fake_image.data.cpu()[0, :, :, :] ) ) )).permute(1, 2, 0)\n",
    "plt.imshow( img_diff2  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = (1 - mask) * real_image + (mask) * fake_image\n",
    "#e = (0.5) * fake_image2 + (0.5) * fake_image_norm\n",
    "#img =torch.from_numpy(np.array(( diff_norm.data.cpu()[0, :, :, :] ) )).permute(1, 2, 0)  #[:, :, :] #.permute(1, 2)\n",
    "img_diff0 =torch.from_numpy(np.array(( toImage( e.data.cpu()[0, :, :, :] ) ) )).permute(1, 2, 0)\n",
    "plt.imshow( img_diff0  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err0 = torch.abs(real_image[0, :, : ,:] - fake_image2[0, :, : ,:])\n",
    "err4 = torch.from_numpy(np.array(( toImage(torch.sum( err0.data.cpu()[:, :, :], axis = 0) ) ) ))\n",
    "plt.imshow( err4 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#err0 = torch.abs(real_image[0, :, : ,:] - fake_image2[0, :, : ,:])\n",
    "err0 = torch.from_numpy(np.array(( ( mask.data.cpu()[0, 0, :, :] ) ) ))\n",
    "plt.imshow( err0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img =torch.from_numpy(np.array(( diff_norm.data.cpu()[0, :, :, :] ) )).permute(1, 2, 0)  #[:, :, :] #.permute(1, 2)\n",
    "gt_image_im =torch.from_numpy(np.array(( toImage(torch.sum( gt_image.data.cpu()[:, :, :], axis = 0) ) ) ))\n",
    "plt.imshow( (gt_image_im > 0) & (err4 > 0.1)  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxi = 0\n",
    "maxv = -1\n",
    "for i in range(40):\n",
    "    thr = 0.1 + 0.01 * i\n",
    "    score = torch.sum((gt_image_im > 0) & (err4 > thr)) * 1.0 / (torch.sum((gt_image_im > 0) | (err4 > thr)) ) \n",
    "    \n",
    "    if score > maxv:\n",
    "        maxi = i\n",
    "        maxv = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.1 + 0.01 * 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow( (gt_image_im > 0)  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow( (gt_image_im > 0) | (err4 > thr) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err0\n",
    "\n",
    "plt.imshow( gt_image_im  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err1 = torch.abs(img_diff - img_diff2)\n",
    "err1 =torch.from_numpy(np.array(( (torch.sum( err1.data.cpu()[:, :, :], axis = 2) ) ) ))\n",
    "plt.imshow( err1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow( (err0 > 0.2) & (err1 > 0.2) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err2 = torch.abs(img_diff - img_diff0)\n",
    "err2 =torch.from_numpy(np.array(( (torch.sum( err2.data.cpu()[:, :, :], axis = 2) ) ) ))\n",
    "plt.imshow( err2  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow( (err0 > 0.2) & (err1 > 0.2) & (err2 > 0.2) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img =torch.from_numpy(np.array(( diff_norm.data.cpu()[0, :, :, :] ) )).permute(1, 2, 0)  #[:, :, :] #.permute(1, 2)\n",
    "img_diff =torch.from_numpy(np.array(( toImage( (mask).data.cpu()[0, 0, :, :] ) ) )).permute(0, 1)\n",
    "plt.imshow( 1-img_diff )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow( (1-img_diff) < 0.6 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow( img_diff * e1  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_mask = torch.from_numpy(np.array(( toImage( (mask*e1).data.cpu()[0, 0, :, :] ) ) )).permute(0, 1)\n",
    "plt.imshow( img_mask )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = #(1-img_diff[:, :, None]) * img_diff2 + (img_diff[:, :, None]) * img_diff0\n",
    "#img =torch.from_numpy(np.array(( diff_norm.data.cpu()[0, :, :, :] ) )).permute(1, 2, 0)  #[:, :, :] #.permute(1, 2)\n",
    "#img_diff0 =torch.from_numpy(np.array(( toImage( e.data.cpu()[0, :, :, :] ) ) )).permute(1, 2, 0)\n",
    "plt.imshow( e  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = (1-img_diff[:, :, None]) * img_diff2 + (img_diff[:, :, None]) * img_diff0\n",
    "#img =torch.from_numpy(np.array(( diff_norm.data.cpu()[0, :, :, :] ) )).permute(1, 2, 0)  #[:, :, :] #.permute(1, 2)\n",
    "#img_diff0 =torch.from_numpy(np.array(( toImage( e.data.cpu()[0, :, :, :] ) ) )).permute(1, 2, 0)\n",
    "plt.imshow( e  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_diff2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gen_in1, gen_in2 = torch.randn(2, b_size, code_size, device='cuda').chunk(\n",
    "#            2, 0\n",
    "#        )\n",
    "#gen_in1 = gen_in1.squeeze(0)\n",
    "\n",
    "#out_orin2, fake_image2     = g_running([gen_in1], step=step, alpha=1) # \n",
    "#img =torch.from_numpy(np.array(( diff_norm.data.cpu()[0, :, :, :] ) )).permute(1, 2, 0)  #[:, :, :] #.permute(1, 2)\n",
    "#img_diff =torch.from_numpy(np.array(( toImage( fake_image2.data.cpu()[0, :, :, :] ) ) )).permute(1, 2, 0)\n",
    "#plt.imshow( img_diff  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#diff_norm = (mask) * e + (1-mask) * real_image\n",
    "#diff_norm = torch.sum( torch.abs(diff_norm), axis = 0)\n",
    "\n",
    "#img =torch.from_numpy(np.array(( diff_norm.data.cpu()[0, :, :, :] ) )).permute(1, 2, 0)  #[:, :, :] #.permute(1, 2)\n",
    "#img_diff =torch.from_numpy(np.array(( toImage(torch.sum( diff_norm.data.cpu()[:, :, :], axis = 0) ) ) )).permute(0, 1)\n",
    "#plt.imshow( img_diff  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img =torch.from_numpy(np.array(( diff_norm.data.cpu()[0, :, :, :] ) )).permute(1, 2, 0)  #[:, :, :] #.permute(1, 2)\n",
    "img_diff =torch.from_numpy(np.array(( toImage(torch.sum( diff_norm.data.cpu()[:, :, :], axis = 0) ) ) )).permute(0, 1)\n",
    "img_mask =torch.from_numpy(np.array(( toImage( (mask).data.cpu()[0, 0, :, :] ) ) )).permute(0, 1)\n",
    "plt.imshow( (1-img_mask) * img_diff )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_norm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img =torch.from_numpy(np.array(( diff_norm.data.cpu()[0, :, :, :] ) )).permute(1, 2, 0)  #[:, :, :] #.permute(1, 2)\n",
    "img_diff =torch.from_numpy(np.array(( toImage(torch.sum( diff_norm.data.cpu()[:, :, :], axis = 0) ) ) )).permute(0, 1)\n",
    "plt.imshow( img_diff  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow( img_diff > 0.4 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img =torch.from_numpy(np.array(( toImage(torch.sum( anomaly_image.grad.cpu()[0, :, :, :], axis = 0) ) ) )).permute(0, 1)  #[:, :, :] #.permute(1, 2)\n",
    "plt.imshow( img )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "float(torch.sum ( (img_diff > 0.3) & (gt_image_im > 0)).item()) / torch.sum ( (img_diff > 0.3) | (gt_image_im > 0) ).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow( (img_diff > 0.3) | (gt_image_im > 0) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img =torch.from_numpy(np.array(( toImage(torch.sum( anomaly_image.grad.cpu()[0, :, :, :], axis = 0) ) ) )).permute(0, 1)  #[:, :, :] #.permute(1, 2)\n",
    "plt.imshow( img )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_cp = img_diff.clone()\n",
    "diff_cp[img > 0.5] = 0.5\n",
    "plt.imshow( diff_cp )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img =torch.from_numpy(np.array(( anomaly_image.data.cpu()[0, :, :, :] ) )).permute(1, 2, 0)  #[:, :, :] #.permute(1, 2)\n",
    "plt.imshow( img )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.max(anomaly_image.grad.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.max(toImage(anomaly_image.grad.cpu()[0, :, :, :]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_gr =torch.from_numpy(np.array(( toImage(fake_image2.data.cpu()[0, :, :, :]  ) ) )).permute(1, 2, 0)  #[:, :, :] #.permute(1, 2)\n",
    "plt.imshow( img_gr )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_gr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img =torch.from_numpy(np.array(toImage( anomaly_image.data.cpu()[0, :, :, :] ) )).permute(1, 2, 0)  #[:, :, :] #.permute(1, 2)\n",
    "plt.imshow( (img_gr[:, :, None])*img )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img =torch.from_numpy(np.array(toImage( anomaly_image.grad.cpu()[0, :, :, :] ) )).permute(1, 2, 0)  #[:, :, :] #.permute(1, 2)\n",
    "plt.imshow( img )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img =torch.from_numpy(np.array(toImage( anomaly_image.grad.cpu()[0, :, :, :] ) )).permute(1, 2, 0)  #[:, :, :] #.permute(1, 2)\n",
    "plt.imshow( img )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img =torch.from_numpy(np.array(toImage( anomaly_image.grad.cpu()[0, :, :, :] ) )).permute(1, 2, 0)  #[:, :, :] #.permute(1, 2)\n",
    "plt.imshow( img )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(((torch.abs(diff_norm.cpu().detach()[0]))  ) ).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_norm\n",
    "img =torch.from_numpy(np.array(((torch.abs(toImage(diff_norm.cpu().detach()[1]) ))  ) ) ).permute(1, 2, 0)  #[:, :, :]\n",
    "plt.imshow( img )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img =torch.from_numpy(np.array(toImage( (fake_image).cpu().detach()[0, :, :, :] ))).permute(1, 2, 0)  #[:, :, :]\n",
    "plt.imshow( img )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img =torch.from_numpy(np.array(toImage( (anomaly_image).cpu().detach()[0, :, :, :] ))).permute(1, 2, 0)  #[:, :, :]\n",
    "plt.imshow( img )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img =torch.from_numpy(np.array(toImage(fake_image.cpu().detach()[0, :, :, :]) - toImage(anomaly_image.cpu().detach()[0, :, :, :])) ).permute(1, 2, 0)  #[:, :, :]\n",
    "plt.imshow( img )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_image_norm - anomaly_image_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img =torch.from_numpy(np.array(toImage( (fake_image_norm - anomaly_image_norm).cpu().detach()[0, :, :, :] ))).permute(1, 2, 0)  #[:, :, :]\n",
    "plt.imshow( img )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = torch.from_numpy(np.array(toImage((fake_image).cpu().detach()[1, :, :, :]) )).permute(1, 2, 0)  #[:, :, :]\n",
    "plt.imshow( img )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = torch.from_numpy(np.array(toImage((fake_image).cpu().detach()[0, :, :, :]) )).permute(1, 2, 0)  #[:, :, :]\n",
    "plt.imshow( img )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_image - anomaly_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_image = real_image.cuda()\n",
    "recon_loss_pixel = torch.mean(torch.sum(torch.square(fake_image - real_image), -1)) # 코드가  비슷해짐, 근데 검어짐\n",
    "corr = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "recon_loss_info = 1-torch.mean(corr(out,out_orin[0]))\n",
    "\n",
    "recon_loss = recon_loss_pixel + recon_loss_info# + recon_loss_mag #recon_loss_pixel#recon_loss_info#recon_loss_pixel + recon_loss_info# + recon_loss_feature\n",
    "    \n",
    "    \n",
    " #loss_norm = torch.norm(recon_loss_info)\n",
    "\n",
    "if i%10 == 0:\n",
    "    encoder_loss_val = recon_loss.item()\n",
    "    losses.append(encoder_loss_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow( diff )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_list = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow( diff )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.max(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow( anomaly )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_normal = toImage((fake_image).data.detach().cpu()[0]).permute(1, 2, 0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow( fake_normal )\n",
    "plt.imshow( anomaly )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_normal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow( toImage((fake_image).data.detach().cpu()[0]).permute(1, 2, 0)   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "\n",
    "sample_size = 512\n",
    "\n",
    "loader = sample_data(\n",
    "    dataset, 1, sample_size\n",
    ")\n",
    "\n",
    "\n",
    "step = int(math.log2(sample_size)) - 2\n",
    "alpha = 1.0\n",
    "\n",
    "def evaluation(step, alpha, real_image):\n",
    "    real_feature     = e_running(real_image, step=step, alpha=alpha).cuda()\n",
    "    inv_real_image   = g_running(real_feature, step=step, alpha=alpha)#data.detach().cpu()\n",
    "    #fake_feature     = e_running(inv_real_image, step=step, alpha=alpha).cuda()\n",
    "    #fake_image       = g_running(fake_feature, step=step, alpha=alpha)#.data.detach().cpu()\n",
    "    \n",
    "    #real_image       = real_image.data.detach().cpu()\n",
    "    #inv_real_image   = inv_real_image.data.detach().cpu()\n",
    "    #fake_image       = fake_image.data.detach().cpu()\n",
    "    #diff             = (real_feature - fake_feature).data.detach().cpu()\n",
    "    return inv_real_image, real_feature#, fake_image, diff\n",
    "\n",
    "def sample(real_feature, step, alpha, real_image):\n",
    "    prev_0           = e_running(real_image, step=step, alpha=alpha)\n",
    "    #print(prev_0.shape)\n",
    "    inv_real_image   = g_running(real_feature, prev_0, step=step, alpha=alpha)\n",
    "    #print(inv_real_image.shape)\n",
    "    return inv_real_image, real_feature\n",
    "\n",
    "def toImage(tensor):\n",
    "    A = tensor.clone()\n",
    "    A -= A.min()\n",
    "    A /= A.max()\n",
    "    \n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_in1, gen_in2 = torch.randn(2, b_size, code_size, device='cuda').chunk(\n",
    "            2, 0\n",
    "        )\n",
    "gen_in1 = gen_in1.squeeze(0)\n",
    "out_orin, fake_image     = generator([gen_in1], step=step, alpha=alpha)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow( toImage(fake_image.data.detach().cpu()[0]).permute(1, 2, 0)  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gg = out_orin[0].clone()\n",
    "#gg = gen_in1.clone()\n",
    "gg[0, 472:512] = 0\n",
    "_, fake_image     = generator([gg], styles=[gg], step=step, alpha=alpha) #styles=[gg],\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow( toImage(fake_image.data.detach().cpu()[0]).permute(1, 2, 0)  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_in1, gen_in2 = torch.randn(2, b_size, code_size, device='cuda').chunk(\n",
    "            2, 0\n",
    "        )\n",
    "gen_in1 = gen_in1.squeeze(0)\n",
    "out_orin, fake_image     = generator([gen_in1], styles=[out], step=step, alpha=alpha)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow( toImage(fake_image.data.detach().cpu()[0]).permute(1, 2, 0)  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_feature = torch.normal(0, 1, size=(1, 512)).cuda()\n",
    "\n",
    "data_loader = iter(loader)\n",
    "real_image = next(data_loader)\n",
    "real_image = real_image.cuda()\n",
    "\n",
    "inv_real_image, real_feature = sample(real_feature, step, alpha, real_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow( toImage(inv_real_image.data.detach().cpu()[0]).permute(1, 2, 0)  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow( toImage(real_image.data.detach().cpu()[0]).permute(1, 2, 0)  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_feature = torch.normal(0, 1, size=(1, 512)).cuda()\n",
    "\n",
    "data_loader = iter(loader)\n",
    "real_image = next(data_loader)\n",
    "real_image = real_image.cuda()\n",
    "\n",
    "inv_real_image, real_feature = sample(real_feature, step, alpha, anomaly_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow( toImage(inv_real_image.data.detach().cpu()[0]).permute(1, 2, 0)  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow( toImage(inv_real_image.data.detach().cpu()[0]).permute(1, 2, 0)  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow( toImage(real_image.data.detach().cpu()[0]).permute(1, 2, 0)  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow( toImage(anomaly_image.data.detach().cpu()[0]).permute(1, 2, 0)  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow( toImage(inv_real_image.data.detach().cpu()[0]).permute(1, 2, 0)  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mask = np.zeros((512, 512), dtype=np.int8)\n",
    "from scipy.spatial import distance\n",
    "\n",
    "def sortpts_clockwise(A):\n",
    "    sortedAc2 = A[np.argsort(A[:,1]),:]\n",
    "    top2 = sortedAc2[0:2,:]\n",
    "    bottom2 = sortedAc2[2:,:]\n",
    "    sortedtop2c1 = top2[np.argsort(top2[:,0]),:]\n",
    "    top_left = sortedtop2c1[0,:]\n",
    "    sqdists = distance.cdist(top_left[None], bottom2, 'sqeuclidean')\n",
    "    rest2 = bottom2[np.argsort(np.max(sqdists,0))[::-1],:]\n",
    "    return np.concatenate((sortedtop2c1,rest2),axis =0)\n",
    "\n",
    "n = int(np.random.rand(1) * 7 + 3)\n",
    "polys = []\n",
    "\n",
    "xy = np.random.uniform(low=0.1, high=0.9, size=(2))\n",
    "wh = np.random.uniform(low=0.1, high=0.2, size=(2))\n",
    "\n",
    "for i in range(n):\n",
    "    polys = np.random.rand(5*2).reshape(5, 2)\n",
    "    polys[:, 0] = polys[:, 0] * w * wh[0] + xy[0] * 512\n",
    "    polys[:, 1] = polys[:, 1] * h * wh[1] + xy[1] * 512\n",
    "    \n",
    "\n",
    "import cv2 \n",
    "\n",
    "for i in sortpts_clockwise(polys).reshape(1, 5, 2).astype(np.int32).tolist():\n",
    "    cv2.fillConvexPoly(mask, np.array(i), 1)\n",
    "    \n",
    "\n",
    "plt.imshow(mask)#, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sortpts_clockwise(polys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "polys = np.array([[[30,32], [36,46], [41,48], [50, 36]],\n",
    "                  [[10,32], [16,46], [30,48], [40, 36]],\n",
    "                  [[56,44], [58,70], [78,90], [75,34]]], np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polys.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polys.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
