{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install --upgrade torch torchvision\n",
    "#!/notebooks/py_36_env/bin/python train.py --mixing --loss r1 --sched lmdb_out\n",
    "#!pip3 install lmdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!apt-get install unzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!unzip good.zip -d ./mvtec_single_dataset/screw\n",
    "#!mkdir mvtec_single_out/screw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/notebooks/py_36_env/bin/python prepare_data.py --out mvtec_single_out/screw --n_worker 4 mvtec_single_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#coding: future_fstrings     # should work even without -*-\n",
    "#location = fromstr(f'POINT({longitude} {latitude})', srid=4326)\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "import sys\n",
    "sys.argv = [sys.argv[0], '--mixing', '--sched', '--loss', 'r1', 'mvtec_single_out/screw']# '--loss', 'r1'\n",
    "\n",
    "import argparse\n",
    "import random\n",
    "import math\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torch.autograd import Variable, grad\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, utils\n",
    "\n",
    "from dataset import MultiResolutionDataset\n",
    "from model import StyledGenerator, Discriminator\n",
    "\n",
    "\n",
    "def requires_grad(model, flag=True):\n",
    "    for p in model.parameters():\n",
    "        p.requires_grad = flag\n",
    "\n",
    "\n",
    "def accumulate(model1, model2, decay=0.999):\n",
    "    par1 = dict(model1.named_parameters())\n",
    "    par2 = dict(model2.named_parameters())\n",
    "\n",
    "    for k in par1.keys():\n",
    "        par1[k].data.mul_(decay).add_(1 - decay, par2[k].data)\n",
    "\n",
    "\n",
    "def sample_data(dataset, batch_size, image_size=4):\n",
    "    dataset.resolution = image_size\n",
    "    loader = DataLoader(dataset, shuffle=True, batch_size=batch_size, num_workers=1, drop_last=True)\n",
    "\n",
    "    return loader\n",
    "\n",
    "\n",
    "def adjust_lr(optimizer, lr):\n",
    "    for group in optimizer.param_groups:\n",
    "        mult = group.get('mult', 1)\n",
    "        group['lr'] = lr * mult\n",
    "\n",
    "\n",
    "def train(args, dataset, generator, discriminator):\n",
    "    step = int(math.log2(args.init_size)) - 2\n",
    "    resolution = 4 * 2 ** step\n",
    "    loader = sample_data(\n",
    "        dataset, args.batch.get(resolution, args.batch_default), resolution\n",
    "    )\n",
    "    data_loader = iter(loader)\n",
    "\n",
    "    adjust_lr(g_optimizer, args.lr.get(resolution, 0.001))\n",
    "    adjust_lr(d_optimizer, args.lr.get(resolution, 0.001))\n",
    "\n",
    "    pbar = tqdm(range(3_000_000)) #3_000_000\n",
    "\n",
    "    requires_grad(generator, False)\n",
    "    requires_grad(discriminator, True)\n",
    "\n",
    "    disc_loss_val = 0\n",
    "    gen_loss_val = 0\n",
    "    grad_loss_val = 0\n",
    "\n",
    "    alpha = 0\n",
    "    used_sample = 0\n",
    "\n",
    "    max_step = int(math.log2(args.max_size)) - 2\n",
    "    final_progress = False\n",
    "\n",
    "    for i in pbar:\n",
    "        discriminator.zero_grad()\n",
    "\n",
    "        alpha = min(1, 1 / args.phase * (used_sample + 1))\n",
    "\n",
    "        if (resolution == args.init_size and args.ckpt is None) or final_progress:\n",
    "            alpha = 1\n",
    "\n",
    "        if used_sample > args.phase * 2:\n",
    "            used_sample = 0\n",
    "            step += 1\n",
    "\n",
    "            if step > max_step:\n",
    "                step = max_step\n",
    "                final_progress = True\n",
    "                ckpt_step = step + 1\n",
    "\n",
    "            else:\n",
    "                alpha = 0\n",
    "                ckpt_step = step\n",
    "\n",
    "            resolution = 4 * 2 ** step\n",
    "            \n",
    "            del loader\n",
    "            del data_loader \n",
    "            \n",
    "            loader = sample_data(\n",
    "                dataset, args.batch.get(resolution, args.batch_default), resolution\n",
    "            )\n",
    "            data_loader = iter(loader)\n",
    "\n",
    "            torch.save(\n",
    "                {\n",
    "                    'generator': generator.module.state_dict(),\n",
    "                    'discriminator': discriminator.module.state_dict(),\n",
    "                    'g_optimizer': g_optimizer.state_dict(),\n",
    "                    'd_optimizer': d_optimizer.state_dict(),\n",
    "                    'g_running': g_running.state_dict(),\n",
    "                },\n",
    "                ('checkpoint/train_step-' + str(ckpt_step) + '.model'),\n",
    "            )\n",
    "\n",
    "            adjust_lr(g_optimizer, args.lr.get(resolution, 0.001))\n",
    "            adjust_lr(d_optimizer, args.lr.get(resolution, 0.001))\n",
    "\n",
    "        try:\n",
    "            real_image = next(data_loader)\n",
    "\n",
    "        except (OSError, StopIteration):\n",
    "            data_loader = iter(loader)\n",
    "            real_image = next(data_loader)\n",
    "\n",
    "        used_sample += real_image.shape[0]\n",
    "\n",
    "        b_size = real_image.size(0)\n",
    "        real_image = real_image.cuda()\n",
    "\n",
    "        if args.loss == 'wgan-gp':\n",
    "            real_predict = discriminator(real_image, step=step, alpha=alpha)\n",
    "            real_predict = real_predict.mean() - 0.001 * (real_predict ** 2).mean()\n",
    "            (-real_predict).backward()\n",
    "\n",
    "        elif args.loss == 'r1':\n",
    "            real_image.requires_grad = True\n",
    "            real_scores = discriminator(real_image, step=step, alpha=alpha)\n",
    "            real_predict = F.softplus(-real_scores).mean()\n",
    "            real_predict.backward(retain_graph=True)\n",
    "\n",
    "            grad_real = grad(\n",
    "                outputs=real_scores.sum(), inputs=real_image, create_graph=True\n",
    "            )[0]\n",
    "            grad_penalty = (\n",
    "                grad_real.view(grad_real.size(0), -1).norm(2, dim=1) ** 2\n",
    "            ).mean()\n",
    "            grad_penalty = 10 / 2 * grad_penalty\n",
    "            grad_penalty.backward()\n",
    "            if i%10 == 0:\n",
    "                grad_loss_val = grad_penalty.item()\n",
    "\n",
    "        if args.mixing and random.random() < 0.9:\n",
    "            gen_in11, gen_in12, gen_in21, gen_in22 = torch.randn(\n",
    "                4, b_size, code_size, device='cuda'\n",
    "            ).chunk(4, 0)\n",
    "            gen_in1 = [gen_in11.squeeze(0), gen_in12.squeeze(0)]\n",
    "            gen_in2 = [gen_in21.squeeze(0), gen_in22.squeeze(0)]\n",
    "\n",
    "        else:\n",
    "            gen_in1, gen_in2 = torch.randn(2, b_size, code_size, device='cuda').chunk(\n",
    "                2, 0\n",
    "            )\n",
    "            gen_in1 = gen_in1.squeeze(0)\n",
    "            gen_in2 = gen_in2.squeeze(0)\n",
    "\n",
    "        fake_image = generator(gen_in1, step=step, alpha=alpha)\n",
    "        fake_predict = discriminator(fake_image, step=step, alpha=alpha)\n",
    "\n",
    "        if args.loss == 'wgan-gp':\n",
    "            fake_predict = fake_predict.mean()\n",
    "            fake_predict.backward()\n",
    "\n",
    "            eps = torch.rand(b_size, 1, 1, 1).cuda()\n",
    "            x_hat = eps * real_image.data + (1 - eps) * fake_image.data\n",
    "            x_hat.requires_grad = True\n",
    "            hat_predict = discriminator(x_hat, step=step, alpha=alpha)\n",
    "            grad_x_hat = grad(\n",
    "                outputs=hat_predict.sum(), inputs=x_hat, create_graph=True\n",
    "            )[0]\n",
    "            grad_penalty = (\n",
    "                (grad_x_hat.view(grad_x_hat.size(0), -1).norm(2, dim=1) - 1) ** 2\n",
    "            ).mean()\n",
    "            grad_penalty = 10 * grad_penalty\n",
    "            grad_penalty.backward()\n",
    "            if i%10 == 0:\n",
    "                grad_loss_val = grad_penalty.item()\n",
    "                disc_loss_val = (-real_predict + fake_predict).item()\n",
    "\n",
    "        elif args.loss == 'r1':\n",
    "            fake_predict = F.softplus(fake_predict).mean()\n",
    "            fake_predict.backward()\n",
    "            if i%10 == 0:\n",
    "                disc_loss_val = (real_predict + fake_predict).item()\n",
    "\n",
    "        d_optimizer.step()\n",
    "\n",
    "        if (i + 1) % n_critic == 0:\n",
    "            generator.zero_grad()\n",
    "\n",
    "            requires_grad(generator, True)\n",
    "            requires_grad(discriminator, False)\n",
    "\n",
    "            fake_image = generator(gen_in2, step=step, alpha=alpha)\n",
    "\n",
    "            predict = discriminator(fake_image, step=step, alpha=alpha)\n",
    "\n",
    "            if args.loss == 'wgan-gp':\n",
    "                loss = -predict.mean()\n",
    "\n",
    "            elif args.loss == 'r1':\n",
    "                loss = F.softplus(-predict).mean()\n",
    "\n",
    "            if i%10 == 0:\n",
    "                gen_loss_val = loss.item()\n",
    "\n",
    "            loss.backward()\n",
    "            g_optimizer.step()\n",
    "            accumulate(g_running, generator.module)\n",
    "\n",
    "            requires_grad(generator, False)\n",
    "            requires_grad(discriminator, True)\n",
    "\n",
    "        if (i + 1) % 100 == 0:\n",
    "            images = []\n",
    "\n",
    "            gen_i, gen_j = args.gen_sample.get(resolution, (10, 5))\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for _ in range(gen_i):\n",
    "                    images.append(\n",
    "                        g_running(\n",
    "                            torch.randn(gen_j, code_size).cuda(), step=step, alpha=alpha\n",
    "                        ).data.detach().cpu()\n",
    "                    )\n",
    "\n",
    "            utils.save_image(\n",
    "                torch.cat(images, 0),\n",
    "                'sample/'+str(i + 1).zfill(6)+ '.png',\n",
    "                nrow=gen_i,\n",
    "                normalize=True,\n",
    "                range=(-1, 1),\n",
    "            )\n",
    "\n",
    "        if (i + 1) % 10000 == 0:\n",
    "            torch.save(\n",
    "                g_running.state_dict(), 'checkpoint/'+str(i + 1).zfill(6)+'.model'\n",
    "            )\n",
    "\n",
    "        state_msg = (\n",
    "            f'Size: {4 * 2 ** step}; G: {gen_loss_val:.3f}; D: {disc_loss_val:.3f};'\n",
    "            f' Grad: {grad_loss_val:.3f}; Alpha: {alpha:.5f}'\n",
    "        )\n",
    "\n",
    "        pbar.set_description(state_msg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n",
      "Size: 512; G: 2.832; D: 0.158; Grad: 0.146; Alpha: 0.30388:   0%|          | 4559/3000000 [2:35:40<1670:41:30,  2.01s/it] "
     ]
    }
   ],
   "source": [
    "code_size = 512\n",
    "base_batch_size = 2 #16\n",
    "n_critic = 1\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Progressive Growing of GANs')\n",
    "\n",
    "parser.add_argument('path', type=str, help='path of specified dataset')\n",
    "parser.add_argument(\n",
    "    '--phase',\n",
    "    type=int,\n",
    "    default=60_000,\n",
    "    help='number of samples used for each training phases',\n",
    ")\n",
    "parser.add_argument('--lr', default=0.001, type=float, help='learning rate')\n",
    "parser.add_argument('--sched', action='store_true', help='use lr scheduling')\n",
    "parser.add_argument('--init_size', default=512, type=int, help='initial image size') #8\n",
    "parser.add_argument('--max_size', default=512, type=int, help='max image size')\n",
    "parser.add_argument(\n",
    "    '--ckpt', default='checkpoint/screw_best.model', type=str, help='load from previous checkpoints'\n",
    ")\n",
    "parser.add_argument(\n",
    "    '--no_from_rgb_activate',\n",
    "    action='store_true',\n",
    "    help='use activate in from_rgb (original implementation)',\n",
    ")\n",
    "parser.add_argument(\n",
    "    '--mixing', action='store_true', help='use mixing regularization'\n",
    ")\n",
    "parser.add_argument(\n",
    "    '--loss',\n",
    "    type=str,\n",
    "    default='wgan-gp',\n",
    "    choices=['wgan-gp', 'r1'],\n",
    "    help='class of gan loss',\n",
    ")\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "generator = nn.DataParallel(StyledGenerator(code_size)).cuda()\n",
    "discriminator = nn.DataParallel(\n",
    "    Discriminator(from_rgb_activate=not args.no_from_rgb_activate)\n",
    ").cuda()\n",
    "g_running = StyledGenerator(code_size).cuda()\n",
    "g_running.train(False)\n",
    "\n",
    "g_optimizer = optim.Adam(\n",
    "    generator.module.generator.parameters(), lr=args.lr, betas=(0.0, 0.99)\n",
    ")\n",
    "g_optimizer.add_param_group(\n",
    "    {\n",
    "        'params': generator.module.style.parameters(),\n",
    "        'lr': args.lr * 0.01,\n",
    "        'mult': 0.01,\n",
    "    }\n",
    ")\n",
    "d_optimizer = optim.Adam(discriminator.parameters(), lr=args.lr, betas=(0.0, 0.99))\n",
    "\n",
    "accumulate(g_running, generator.module, 0)\n",
    "\n",
    "if args.ckpt is not None:\n",
    "    ckpt = torch.load(args.ckpt)\n",
    "\n",
    "    generator.module.load_state_dict(ckpt['generator'])\n",
    "    discriminator.module.load_state_dict(ckpt['discriminator'])\n",
    "    g_running.load_state_dict(ckpt['g_running'])\n",
    "    g_optimizer.load_state_dict(ckpt['g_optimizer'])\n",
    "    d_optimizer.load_state_dict(ckpt['d_optimizer'])\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5), inplace=True),\n",
    "    ]\n",
    ")\n",
    "\n",
    "dataset = MultiResolutionDataset(args.path, transform)\n",
    "\n",
    "if args.sched:\n",
    "    args.lr = {128: 0.0015, 256: 0.002, 512: 0.001, 1024: 0.001}\n",
    "    #args.batch = {4: 512, 8: 256, 16: 128, 32: 64, 64: 32, 128: 32, 256: 32}\n",
    "    args.batch = {4: 512, 8: 256, 16: 128, 32: 64, 64: 16, 128: 8, 256: 8, 512: 4}\n",
    "\n",
    "else:\n",
    "    args.lr = {}\n",
    "    args.batch = {}\n",
    "\n",
    "args.gen_sample = {512: (8, 4), 1024: (4, 2)}\n",
    "\n",
    "args.batch_default = base_batch_size\n",
    "\n",
    "train(args, dataset, generator, discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.batch.get(512, args.batch_default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "sibal = 0\n",
    "for obj in gc.get_objects():\n",
    "    try:\n",
    "        if torch.is_tensor(obj) or (hasattr(obj, 'data') and torch.is_tensor(obj.data)):\n",
    "            print(type(obj), obj.size())\n",
    "            sibal += 1\n",
    "    except:\n",
    "        pass\n",
    "print(sibal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "for obj in gc.get_objects():\n",
    "    try:\n",
    "        if torch.is_tensor(obj) or (hasattr(obj, 'data') and torch.is_tensor(obj.data)):\n",
    "            print(type(obj), obj.size())\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!nvcc --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_i, gen_j = args.gen_sample.get(16, (10, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resolution = 4\n",
    "\n",
    "gen_i, gen_j = args.gen_sample.get(16, (10, 5))\n",
    "alpha = 0.386135\n",
    "with torch.no_grad():\n",
    "    i = g_running(\n",
    "                torch.randn(gen_j, code_size).cuda(), step=2, alpha=alpha\n",
    "            ).data.cpu()\n",
    "        #)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "training_data = (np.transpose(i[0], (1,2,0)) - torch.min(i[0]) ) / ( torch.max(i[0]) - torch.min(i[0]) )\n",
    "plt.imshow( training_data )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int(math.log2(args.init_size)) - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_step = int(math.log2(args.max_size)) - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.max_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int(math.log2(args.max_size)) - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
