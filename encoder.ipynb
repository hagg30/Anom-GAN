{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_label = 'capsule'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "import sys\n",
    "sys.argv = [sys.argv[0], '--mixing', '--sched', 'mvtec_single_out/' +data_label]# '--loss', 'r1'\n",
    "\n",
    "import argparse\n",
    "import random\n",
    "import math\n",
    "\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torch.autograd import Variable, grad\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, utils\n",
    "\n",
    "from dataset import MultiResolutionDataset2\n",
    "from model import StyledGenerator, Discriminator, Encoder, ShortDiscriminator, StyledGenerator2\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.datasets import load_digits\n",
    "from scipy.spatial.distance import pdist\n",
    "from sklearn.manifold.t_sne import _joint_probabilities\n",
    "from scipy import linalg\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from scipy.spatial.distance import squareform\n",
    "from sklearn.manifold import TSNE\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import imgaug as ia\n",
    "import imgaug.augmenters as iaa\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 \n",
    "from scipy.spatial import distance\n",
    "\n",
    "def requires_grad(model, flag=True):\n",
    "    for p in model.parameters():\n",
    "        p.requires_grad = flag\n",
    "\n",
    "\n",
    "def accumulate(model1, model2, decay=0.999):\n",
    "    par1 = dict(model1.named_parameters())\n",
    "    par2 = dict(model2.named_parameters())\n",
    "\n",
    "    for k in par1.keys():\n",
    "        par1[k].data.mul_(decay).add_(1 - decay, par2[k].data)\n",
    "\n",
    "\n",
    "def sample_data(dataset, batch_size, image_size=4):\n",
    "    dataset.resolution = image_size\n",
    "    loader = DataLoader(dataset, shuffle=True, batch_size=batch_size, num_workers=1, drop_last=True)\n",
    "\n",
    "    return loader\n",
    "\n",
    "\n",
    "def adjust_lr(optimizer, lr):\n",
    "    for group in optimizer.param_groups:\n",
    "        mult = group.get('mult', 1)\n",
    "        group['lr'] = lr * mult\n",
    "        \n",
    "from PIL import Image\n",
    "image = Image.open('data/test/capsule/squeeze/001.png')\n",
    "\n",
    "resize_image = image.resize((512, 512))\n",
    "AAA = None\n",
    "BBB = None\n",
    "    \n",
    "    \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial import distance\n",
    "\n",
    "\n",
    "def sortpts_clockwise(A):\n",
    "    sortedAc2 = A[np.argsort(A[:,1]),:]\n",
    "    top2 = sortedAc2[0:2,:]\n",
    "    bottom2 = sortedAc2[2:,:]\n",
    "    sortedtop2c1 = top2[np.argsort(top2[:,0]),:]\n",
    "    top_left = sortedtop2c1[0,:]\n",
    "    sqdists = distance.cdist(top_left[None], bottom2, 'sqeuclidean')\n",
    "    rest2 = bottom2[np.argsort(np.max(sqdists,0))[::-1],:]\n",
    "    return np.concatenate((sortedtop2c1,rest2),axis =0)\n",
    "        \n",
    "    \n",
    "class ImgAugTransform:\n",
    "    def __init__(self):\n",
    "        #self.aug = iaa.Sequential([\n",
    "             #iaa.CoarseDropout(0.1, size_percent=0.5),\n",
    "             #iaa.CoarseDropout((0.02, 0.1), size_percent=(0.02, 0.05), per_channel=False),\n",
    "             #iaa.Salt(0.05, size_percent=(0.01, 0.1)) #AndPepper CoarseSalt\n",
    "            #iaa.BlendAlphaSimplexNoise(iaa.EdgeDetect(1.0))\n",
    "            #iaa.Cutout(fill_mode=\"gaussian\", fill_per_channel=True)\n",
    "            #iaa.Salt(0.05)\n",
    "        #])\n",
    "        self.aug = iaa.Sequential([\n",
    "            #iaa.CoarseDropout(0.1, size_percent=0.5),\n",
    "            #iaa.CoarseDropout((0.02, 0.1), size_percent=(0.02, 0.05), per_channel=False),\n",
    "            #iaa.Salt(0.05)#(0.05, size_percent=(0.01, 0.1)) #AndPepper CoarseSalt\n",
    "            iaa.ChangeColorTemperature((1100, 10000)),\n",
    "            iaa.KeepSizeByResize( iaa.Crop(percent=(0.0, 0.5), keep_size=False) ),\n",
    "            iaa.Flipud(0.5),\n",
    "            iaa.Fliplr(0.5),\n",
    "        ])\n",
    "        self.mask = np.zeros((512, 512, 1), dtype=np.int8)\n",
    "    \n",
    "    def distortion(self, img):\n",
    "        A = img.shape[0] / 3.0\n",
    "        w = 2.0 / img.shape[1]\n",
    "\n",
    "        shift = lambda x: A * np.sin(2.0*np.pi*x * w)\n",
    "\n",
    "        #for i in range(img.shape[0]):\n",
    "        #ret = np.roll(np.array(img[:,:,:]), int(shift(i)))\n",
    "        \n",
    "        if (np.random.randint(2) == 0):\n",
    "            for i in range(img.shape[0]):\n",
    "                img[i,:,0] = torch.tensor( np.roll(img[i,:,0], int(shift(i))) )\n",
    "                img[i,:,1] = torch.tensor( np.roll(img[i,:,1], int(shift(i))) )\n",
    "                img[i,:,2] = torch.tensor( np.roll(img[i,:,2], int(shift(i))) )\n",
    "        else:\n",
    "            for i in range(img.shape[1]):\n",
    "                img[:,i,0] = torch.tensor( np.roll(img[:,i,0], int(shift(i))) )\n",
    "                img[:,i,1] = torch.tensor( np.roll(img[:,i,1], int(shift(i))) )\n",
    "                img[:,i,2] = torch.tensor( np.roll(img[:,i,2], int(shift(i))) )\n",
    "            \n",
    "        return img\n",
    "\n",
    "    def __call__(self, img):\n",
    "        img = np.array(img)\n",
    "        tile_size = img.shape[0]\n",
    "        step = int(np.log2(tile_size / 4.0))\n",
    "        \n",
    "        n = int(np.random.rand(1) * 7 + 3)\n",
    "        xy = np.random.uniform(low=0.2, high=0.8, size=(2))\n",
    "        wh = np.random.uniform(low=0.2, high=0.8, size=(2))\n",
    "\n",
    "        self.mask[:] = 0\n",
    "        polys = np.random.rand(10*4).reshape(10, 4)\n",
    "        wh = np.random.uniform(low=0.2, high=0.8, size=(2))\n",
    "        n = 5\n",
    "        tile_size = 512\n",
    "        max_n = np.random.randint(10)\n",
    "        #num = np.random.randint(5)\n",
    "        for i in range(max_n+1):\n",
    "            cv2.line(self.mask,(int(polys[i, 0]*tile_size), int(polys[i, 1]*tile_size)),\n",
    "                        (int(polys[i, 2]*tile_size), int(polys[i, 3]*tile_size)),(1),1*1)\n",
    "        polys = np.random.rand(10*4).reshape(10, 4)\n",
    "        wh = np.random.uniform(low=0.2, high=0.8, size=(2))\n",
    "        for i in range(max_n+1):\n",
    "            cv2.line(self.mask,(int(polys[i, 0]*tile_size), int(polys[i, 1]*tile_size)),\n",
    "                        (int(polys[i, 2]*tile_size), int(polys[i, 3]*tile_size)),(1),2*2)\n",
    "        polys = np.random.rand(10*4).reshape(10, 4)\n",
    "        wh = np.random.uniform(low=0.2, high=0.8, size=(2))\n",
    "        for i in range(max_n+1):\n",
    "            cv2.line(self.mask,(int(polys[i, 0]*tile_size), int(polys[i, 1]*tile_size)),\n",
    "                        (int(polys[i, 2]*tile_size), int(polys[i, 3]*tile_size)),(1),3*3)\n",
    "        \n",
    "        #self.mask = 1-self.mask\n",
    "        \n",
    "        ret_mask = cv2.resize(self.mask.astype(np.uint8), dsize=(img.shape[0], img.shape[1]), interpolation=cv2.INTER_CUBIC)\n",
    "        ret_mask = ret_mask[:, :, None]\n",
    "        img_anom = img\n",
    "        #if (np.random.randint(2) == 0):\n",
    "        #    img_anom = (self.distortion( np.array(img_anom).astype(np.uint8) ).copy()).astype(np.float32)\n",
    "        #else:\n",
    "        #    pass\n",
    "        img_anom = (self.aug.augment_image( np.array(img_anom).astype(np.uint8) ).copy()).astype(np.float32)\n",
    "        #self.mask[:] = 1\n",
    "        ret = (img - ret_mask*img) + (ret_mask * img_anom)#img_anom#(img - self.mask*img) + (self.mask * img_anom)\n",
    "        \n",
    "        return np.concatenate((ret, ret_mask), axis=2)\n",
    "\n",
    "ia_transform = ImgAugTransform()\n",
    "\n",
    "code_size = 512\n",
    "base_batch_size = 2 #16\n",
    "n_critic = 1\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Progressive Growing of GANs')\n",
    "\n",
    "parser.add_argument('path', type=str, help='path of specified dataset')\n",
    "parser.add_argument(\n",
    "    '--phase',\n",
    "    type=int,\n",
    "    default=20_000, #600_000\n",
    "    help='number of samples used for each training phases',\n",
    ")\n",
    "parser.add_argument('--lr', default=0.001, type=float, help='learning rate')\n",
    "parser.add_argument('--sched', action='store_true', help='use lr scheduling')\n",
    "parser.add_argument('--init_size', default=512, type=int, help='initial image size') #2^9\n",
    "parser.add_argument('--max_size', default=512, type=int, help='max image size')\n",
    "parser.add_argument(\n",
    "    '--ckpt', default='checkpoint/'+data_label+'/train_step-7.model', type=str, help='load from previous checkpoints'\n",
    ")\n",
    "parser.add_argument(\n",
    "    '--no_from_rgb_activate',\n",
    "    action='store_true',\n",
    "    help='use activate in from_rgb (original implementation)',\n",
    ")\n",
    "parser.add_argument(\n",
    "    '--mixing', action='store_true', help='use mixing regularization'\n",
    ")\n",
    "parser.add_argument(\n",
    "    '--loss',\n",
    "    type=str,\n",
    "    default='wgan-gp',\n",
    "    choices=['wgan-gp', 'r1'],\n",
    "    help='class of gan loss',\n",
    ")\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "#encoder = nn.DataParallel(\n",
    "#    Encoder(from_rgb_activate=not args.no_from_rgb_activate)\n",
    "#).cuda()\n",
    "#generator = nn.DataParallel(StyledGenerator(code_size)).cuda()\n",
    "\n",
    "g2_running = StyledGenerator2(code_size).cuda()\n",
    "\n",
    "g_running = StyledGenerator(code_size).cuda()\n",
    "#g_running.train(False)\n",
    "\n",
    "e_running = Encoder(from_rgb_activate=not args.no_from_rgb_activate).cuda()\n",
    "#e_running.train(False)\n",
    "\n",
    "g2_optimizer = optim.Adam(\n",
    "    g2_running.generator.parameters(), lr=args.lr, betas=(0.0, 0.99)\n",
    ")\n",
    "g2_optimizer.add_param_group(\n",
    "    {\n",
    "        'params': g2_running.style.parameters(),\n",
    "        'lr': args.lr * 0.01,\n",
    "        'mult': 0.01,\n",
    "    }\n",
    ")\n",
    "\n",
    "g_optimizer = optim.Adam(\n",
    "    g_running.generator.parameters(), lr=args.lr, betas=(0.0, 0.99)\n",
    ")\n",
    "g_optimizer.add_param_group(\n",
    "    {\n",
    "        'params': g_running.style.parameters(),\n",
    "        'lr': args.lr * 0.01,\n",
    "        'mult': 0.01,\n",
    "    }\n",
    ")\n",
    "\n",
    "e_optimizer = optim.Adam(e_running.parameters(), lr=args.lr, betas=(0.0, 0.99))\n",
    "\n",
    "#accumulate(g_running, generator.module, 0)\n",
    "#accumulate(e_running, encoder.module, 0)\n",
    "\n",
    "assert args.ckpt is not None\n",
    "ckpt = torch.load(args.ckpt)\n",
    "\n",
    "#generator.module.load_state_dict(ckpt['generator'])\n",
    "#g_running.load_state_dict(ckpt['g_running'])\n",
    "#g_optimizer.load_state_dict(ckpt['g_optimizer'])\n",
    "\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        #transforms.RandomHorizontalFlip(),\n",
    "        ia_transform,\n",
    "        #transforms.ToTensor(),\n",
    "        #transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5), inplace=True),\n",
    "    ]\n",
    ")\n",
    "\n",
    "transform2 = transforms.Compose(\n",
    "    [\n",
    "        #transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5), inplace=True),\n",
    "    ]\n",
    ")\n",
    "\n",
    "dataset = MultiResolutionDataset2(args.path, transform, transform2)\n",
    "\n",
    "if args.sched:\n",
    "    args.lr = {128: 0.0015, 256: 0.002, 512: 0.003, 1024: 0.003}\n",
    "    args.batch = {4: 128, 8: 64, 16: 32, 32: 16, 64: 8, 128: 8, 256: 2, 512: 2} #8\n",
    "\n",
    "else:\n",
    "    args.lr = {}\n",
    "    args.batch = {}\n",
    "\n",
    "args.gen_sample = {512: (8, 4), 1024: (4, 2)}\n",
    "\n",
    "args.batch_default = base_batch_size * 2\n",
    "\n",
    "\n",
    "def toImage(tensor):\n",
    "    A = tensor.clone()\n",
    "    A -= A.min()\n",
    "    A /= A.max()\n",
    "    \n",
    "    return A\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt = torch.load('checkpoint/'+data_label+'/train_step-7.model')\n",
    "g_running.load_state_dict(ckpt['g_running'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[36  1 33 90  6 55 38 23 16 93]\n",
      "[36  1 33 90  6 55 38 23 16 93]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(None)\n",
    "st0 = np.random.get_state()\n",
    "# draw some random numbers\n",
    "print(np.random.randint(0, 100, 10))\n",
    "np.random.set_state(st0)\n",
    "print(np.random.randint(0, 100, 10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def get_holes(image, thresh):\n",
    "    gray = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "    im_bw = cv.threshold(gray, thresh, 255, cv.THRESH_BINARY)[1]\n",
    "    im_bw_inv = cv.bitwise_not(im_bw)\n",
    "\n",
    "    contour, _ = cv.findContours(im_bw_inv, cv.RETR_CCOMP, cv.CHAIN_APPROX_SIMPLE)\n",
    "    for cnt in contour:\n",
    "        cv.drawContours(im_bw_inv, [cnt], 0, 255, -1)\n",
    "\n",
    "    nt = cv.bitwise_not(im_bw)\n",
    "    im_bw_inv = cv.bitwise_or(im_bw_inv, nt)\n",
    "    return im_bw_inv\n",
    "\n",
    "\n",
    "def remove_background(image, thresh, scale_factor=.25, kernel_range=range(1, 15), border=None):\n",
    "    border = border or kernel_range[-1]\n",
    "\n",
    "    holes = get_holes(image, thresh)\n",
    "    small = cv.resize(holes, None, fx=scale_factor, fy=scale_factor)\n",
    "    bordered = cv.copyMakeBorder(small, border, border, border, border, cv.BORDER_CONSTANT)\n",
    "\n",
    "    for i in kernel_range:\n",
    "        kernel = cv.getStructuringElement(cv.MORPH_ELLIPSE, (2*i+1, 2*i+1))\n",
    "        bordered = cv.morphologyEx(bordered, cv.MORPH_CLOSE, kernel)\n",
    "\n",
    "    unbordered = bordered[border: -border, border: -border]\n",
    "    mask = cv.resize(unbordered, (image.shape[1], image.shape[0]))\n",
    "    fg = cv.bitwise_and(image, image, mask=mask)\n",
    "    return fg, mask\n",
    "\n",
    "def get_score(generator2, encoder, generator):\n",
    "    num_file = 0\n",
    "    r_list = []\n",
    "    for root, dirs, files in os.walk(\"./test/\"+data_label+\"/test/\"):\n",
    "        path = root.split(os.sep)\n",
    "        #print((len(path) - 1) * '---', os.path.basename(root))\n",
    "        if path[-1] == 'good' or path[-1] == '.ipynb_checkpoints':\n",
    "            continue\n",
    "        r_list_sub = []\n",
    "        for file in (sorted(files[:])):\n",
    "            if '.png' == file[-4:] and path[-1] != '':\n",
    "                #print()\n",
    "                # Open the image form working directory\n",
    "                anomaly = Image.open('./test/'+data_label+'/test/' + str(path[-1]) + '/' + file).convert('RGB')\n",
    "                gt = Image.open('./test/'+data_label+'/gt/' + str(path[-1]) + '/' + file[:-4] + '_mask.png')\n",
    "                gt = gt.resize((512, 512))\n",
    "                anomaly = anomaly.resize((512, 512))\n",
    "\n",
    "                gen_in1, gen_in2 = torch.randn(2, 1, code_size, device='cuda').chunk(\n",
    "                        2, 0\n",
    "                    )\n",
    "                gen_in1 = gen_in1.squeeze(0)\n",
    "\n",
    "                ground_truth = 1 - (torch.from_numpy(np.array(gt)[:, :]).permute(0, 1) / 255.0)\n",
    "                anomaly_image = torch.from_numpy(np.array(anomaly)[None, :, :, :]).permute(0, 3, 1, 2) / 255.0\n",
    "                anomaly_image = anomaly_image.cuda()\n",
    "\n",
    "                anomaly_image = anomaly_image\n",
    "                anomaly_image = anomaly_image * 2\n",
    "                anomaly_image = anomaly_image - 1.0\n",
    "\n",
    "                #out = encoder(anomaly_image, step=step, alpha=alpha)\n",
    "                (out, skiplist) = encoder(anomaly_image, step=step, alpha=alpha)\n",
    "                skiplist = skiplist[1:]\n",
    "                skiplist.insert(0, None)\n",
    "\n",
    "                out_orin, fake_image     = generator([gen_in1], styles=[out[:, :512]], step=step, alpha=alpha)\n",
    "                out_orin, (fake_image2, mask)     = generator2(skiplist, fake_image, anomaly_image, [gen_in1], styles=[out[:, 512:]], step=step, alpha=alpha)\n",
    "\n",
    "                gt_image = torch.from_numpy(np.array(gt)[None, :, :]) / 255.0\n",
    "                gt_image_im =torch.from_numpy(np.array(( toImage(torch.sum( gt_image.data[:, :, :], axis = 0) ) ) ))\n",
    "\n",
    "\n",
    "                fake_image_norm = (1 - mask) * fake_image + mask * anomaly_image\n",
    "\n",
    "\n",
    "                anomaly_image_norm = anomaly_image\n",
    "                anomaly_image_norm = (anomaly_image_norm - torch.min(anomaly_image_norm))\n",
    "                anomaly_image_norm = anomaly_image_norm / (torch.max(anomaly_image_norm) + 1e-6)\n",
    "\n",
    "                img_diff = mask\n",
    "                img_diff = torch.sum( torch.abs(img_diff), axis = 0)\n",
    "                img_diff = torch.from_numpy(np.array(( toImage(torch.sum( img_diff.data.cpu()[:, :, :], axis = 0) ) ) )).permute(0, 1)\n",
    "\n",
    "                fg = torch.from_numpy(np.array(( toImage( anomaly_image.data.cpu()[0, :, :, :] ) ) )).permute(1, 2, 0)\n",
    "                img = np.array(fg*255).astype(np.uint8)\n",
    "                nb_img, mask_fg = remove_background(img, 120)\n",
    "\n",
    "                kernel = np.ones((9,9),np.uint8)\n",
    "                img_diff = cv2.dilate(np.array(img_diff),kernel,iterations = 1)\n",
    "                ret = ((torch.tensor(img_diff) > 0.2) & (mask_fg > 0) )\n",
    "                gt = (gt_image_im > 0)\n",
    "\n",
    "                score = float(torch.sum ( ret & gt ).item()) / torch.sum ( ret | gt ).item()\n",
    "                \n",
    "                r_list_sub.append(score)\n",
    "            \n",
    "        r_list.append(r_list_sub)\n",
    "        \n",
    "    length = 0\n",
    "    sum_score = 0\n",
    "    for s_list in r_list:\n",
    "        length += len(s_list)\n",
    "        sum_score += sum(s_list)\n",
    "    \n",
    "    return sum_score / length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Size: 512; E: 1.329; G: 0.000;  Grad: 0.000; Alpha: 1.00000:   0%|          | 4/3000000 [00:01<393:28:30,  2.12it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-52ac5c18e365>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0mrecon_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m     \u001b[0me_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0mrequires_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m                 \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m                 \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m                 \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "generator2 = g2_running\n",
    "encoder = e_running\n",
    "generator = g_running\n",
    "\n",
    "losses = []\n",
    "scores = []\n",
    "scores.append(0)\n",
    "step = int(math.log2(args.init_size)) - 2\n",
    "resolution = 4 * 2 ** step\n",
    "\n",
    "\n",
    "resize_image = image.resize((512, 512))\n",
    "anomaly_image = torch.from_numpy(np.array(resize_image)[None, :, :, :]).permute(0, 3, 1, 2) / 255.0\n",
    "anomaly_image = anomaly_image.cuda()\n",
    "anomaly_image = anomaly_image\n",
    "anomaly_image = anomaly_image * 2\n",
    "anomaly_image = anomaly_image - 1.0\n",
    "\n",
    "loader = sample_data(\n",
    "    dataset, args.batch.get(resolution, args.batch_default), resolution\n",
    ")\n",
    "data_loader = iter(loader)\n",
    "\n",
    "adjust_lr(g_optimizer, args.lr.get(resolution, 0.001))\n",
    "\n",
    "pbar = tqdm(range(3_000_000)) #3_000_000\n",
    "\n",
    "requires_grad(generator, False)\n",
    "\n",
    "gen_loss_val = 0\n",
    "grad_loss_val = 0\n",
    "\n",
    "alpha = 1\n",
    "used_sample = 0\n",
    "\n",
    "max_step = int(math.log2(args.max_size)) - 2\n",
    "final_progress = False\n",
    "\n",
    "\n",
    "for i in pbar:\n",
    "    if used_sample > args.phase * 2:\n",
    "        used_sample = 0\n",
    "        step += 1\n",
    "\n",
    "        if step > max_step:\n",
    "            step = max_step\n",
    "            final_progress = True\n",
    "            ckpt_step = step + 1\n",
    "\n",
    "        else:\n",
    "            ckpt_step = step\n",
    "\n",
    "        resolution = 4 * 2 ** step\n",
    "\n",
    "        loader = sample_data(\n",
    "            dataset, args.batch.get(resolution, args.batch_default), resolution\n",
    "        )\n",
    "        data_loader = iter(loader)\n",
    "\n",
    "        torch.save(\n",
    "            {\n",
    "                'g_optimizer': g_optimizer.state_dict(),\n",
    "                'g_running': g_running.state_dict(),\n",
    "                'e_running': e_running.state_dict(),\n",
    "            },\n",
    "            ('checkpoint/'+data_label+'/encdec/train_step-' + str(ckpt_step) + '.model'),\n",
    "        )\n",
    "\n",
    "        adjust_lr(g_optimizer, args.lr.get(resolution, 0.001))\n",
    "        #gc.collect()\n",
    "    try:\n",
    "        real_image, anomaly_img, mask_gt = next(data_loader)\n",
    "\n",
    "    except (OSError, StopIteration):\n",
    "        data_loader = iter(loader)\n",
    "        real_image, anomaly_img, mask_gt = next(data_loader)\n",
    "\n",
    "    used_sample += real_image.shape[0]\n",
    "\n",
    "    b_size = real_image.size(0)\n",
    "    real_image = real_image.cuda()\n",
    "    anomaly_img = anomaly_img.cuda()\n",
    "    mask_gt = mask_gt.unsqueeze(1)\n",
    "    mask_gt = mask_gt.cuda()\n",
    "    \n",
    "   \n",
    "\n",
    "    # Encoder \n",
    "    encoder.zero_grad()\n",
    "\n",
    "    requires_grad(encoder, True)\n",
    "    requires_grad(generator2, True)\n",
    "    requires_grad(generator, False)\n",
    "\n",
    "    gen_in1, gen_in2 = torch.randn(2, b_size, code_size, device='cuda').chunk(\n",
    "            2, 0\n",
    "        )\n",
    "    gen_in1 = gen_in1.squeeze(0)\n",
    "    \n",
    "    \n",
    "    anomaly_img = anomaly_img\n",
    "    anomaly_img = anomaly_img / 255.0\n",
    "    anomaly_img = anomaly_img - 1.0\n",
    "    \n",
    "    (out, skiplist) = encoder(anomaly_img, step=step, alpha=alpha)\n",
    "    skiplist = skiplist[1:]\n",
    "    skiplist.insert(0, None)\n",
    "\n",
    "    out_orin, fake_image     = generator([gen_in1], styles=[out[:, :512]], step=step, alpha=alpha) #styles=[out],\n",
    "    out_orin2, (fake_image2, mask) = generator2(skiplist, fake_image, anomaly_img, [gen_in1], styles=[out[:, 512:]], step=step, alpha=alpha)\n",
    "\n",
    "    fake_image_norm = fake_image2\n",
    "    anomaly_image_norm = real_image\n",
    "\n",
    "    loss = nn.MSELoss(reduction = 'mean')\n",
    "    diff_norm = loss(fake_image_norm, anomaly_image_norm)\n",
    "    diff_norm2 = loss(fake_image, anomaly_image_norm)\n",
    "    diff_norm3 = loss(mask, mask_gt)\n",
    "    diff_norm4 = loss(fake_image, fake_image_norm)\n",
    "    recon_loss_pixel = torch.mean(diff_norm) + torch.mean(diff_norm2) + torch.mean(diff_norm3)+ torch.mean(diff_norm4)\n",
    "    \n",
    "    loss_norm = torch.norm(mask)\n",
    "    \n",
    "    recon_loss = recon_loss_pixel \n",
    "\n",
    "    if i%10 == 0:\n",
    "        encoder_loss_val = recon_loss.item()\n",
    "        losses.append(encoder_loss_val)\n",
    "    \n",
    "    recon_loss.backward()\n",
    "    e_optimizer.step()\n",
    "    \n",
    "    requires_grad(generator2, False)\n",
    "    requires_grad(encoder, False)\n",
    "    requires_grad(generator, False)\n",
    "    \n",
    "    # Encoder End\n",
    "\n",
    "    if (i + 1) % 1000 == 0:\n",
    "        images = []\n",
    "\n",
    "        gen_i, gen_j = args.gen_sample.get(resolution, (10, 5))\n",
    "        \n",
    "        \n",
    "        anom = anomaly_img \n",
    "        (out_tmp, list_tmp) = encoder(anom, step=step, alpha=alpha)\n",
    "\n",
    "        images.append(anomaly_img.data.detach().cpu())\n",
    "        images.append((anom*2-1).data[:1].detach().cpu())\n",
    "        \n",
    "        list_tmp = list_tmp[1:]\n",
    "        list_tmp.insert(0, None)\n",
    "\n",
    "        fk2 = g2_running(\n",
    "            list_tmp, fake_image[:], anom, [gen_in1], styles=[out[:, 512:]], step=step, alpha=alpha\n",
    "        )\n",
    "        fk2_mask = torch.cat( [fk2[1][1].data[:1].detach().cpu(), fk2[1][1].data[:1].detach().cpu(),\n",
    "                               fk2[1][1].data[:1].detach().cpu()], axis=1)\n",
    "\n",
    "        fk3_mask = torch.cat( [fk2[1][1].data[1:].detach().cpu(), fk2[1][1].data[1:].detach().cpu(),\n",
    "                               fk2[1][1].data[1:].detach().cpu()], axis=1)      \n",
    "\n",
    "        with torch.no_grad():\n",
    "            for _ in range(1):\n",
    "                images.append(\n",
    "                    g_running(\n",
    "                        [out[:, :512]], styles=[out[:, :512]], step=step, alpha=alpha\n",
    "                    )[1].data.detach().cpu() \n",
    "                )\n",
    "                images.append(\n",
    "                    g_running(\n",
    "                        [out_tmp[:, :512]], styles=[out_tmp[:, :512]], step=step, alpha=alpha\n",
    "                    )[1].data[:1].detach().cpu() \n",
    "                )\n",
    "                images.append(\n",
    "                    fk2[1][0].data[:1].detach().cpu()\n",
    "                )\n",
    "                images.append(\n",
    "                    fk2_mask\n",
    "                )\n",
    "                \n",
    "                images.append(\n",
    "                    fk2[1][0].data[1:].detach().cpu()\n",
    "                )\n",
    "                images.append(\n",
    "                    fk3_mask\n",
    "                )\n",
    "        utils.save_image(\n",
    "            torch.cat(images, 0),\n",
    "            'sample/'+data_label+'/encdec/'+str(i + 1).zfill(6)+ '.png',\n",
    "            nrow=gen_i,\n",
    "            normalize=True,\n",
    "            range=(-1, 1),\n",
    "        )\n",
    "        \n",
    "        latest_score = get_score(generator2, encoder, generator)\n",
    "        \n",
    "        if latest_score > max(scores):\n",
    "            print(latest_score)\n",
    "            print(str(i + 1).zfill(6))\n",
    "            torch.save(\n",
    "                g2_running.state_dict(), 'checkpoint/'+data_label+'/encdec/bestg2.model'\n",
    "            )\n",
    "            torch.save(\n",
    "                e_running.state_dict(), 'checkpoint/'+data_label+'/encdec/beste.model'\n",
    "            )\n",
    "        scores.append(latest_score)\n",
    "\n",
    "    if (i + 1) % 20000 == 0:\n",
    "        torch.save(\n",
    "            g2_running.state_dict(), 'checkpoint/'+data_label+'/enc'+str(i + 1).zfill(6)+'g2.model'\n",
    "        )\n",
    "        torch.save(\n",
    "            e_running.state_dict(), 'checkpoint/'+data_label+'/enc'+str(i + 1).zfill(6)+'e.model'\n",
    "        )\n",
    "        \n",
    "    state_msg = (\n",
    "        f'Size: {4 * 2 ** step}; E: {encoder_loss_val:.3f}; G: {gen_loss_val:.3f}; '\n",
    "        f' Grad: {grad_loss_val:.3f}; Alpha: {alpha:.5f}'\n",
    "    )\n",
    "\n",
    "    pbar.set_description(state_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('MT19937',\n",
       " array([2147483648, 1973952246, 2700483622, 3062020305, 2909344801,\n",
       "        1116939581, 1008371610, 1249036225,  861768517, 2505248493,\n",
       "        3593500672,  227497116, 2298433495, 3516138394, 1044592035,\n",
       "        2361457843, 1291448833, 3685614512,  953746249, 3087288407,\n",
       "        3122638999,  786488974, 4197158251, 3744250015, 3836680439,\n",
       "        3384097227, 1656112966, 1328243768, 3803903442, 1794590777,\n",
       "        3145332185, 1201569261,  535702486, 3007142371, 1021677493,\n",
       "        4052770243, 3079164736, 2840641662, 3374635812, 4017673419,\n",
       "        2440034551, 1342282559, 2906900979,  780450199, 1347469560,\n",
       "        3690854515, 2138950941, 2727648487, 2107678168, 2212443201,\n",
       "        3491437067, 3083886467,  198888914, 3706326276, 1036374021,\n",
       "         558837500, 1342537693, 4139764033, 2584649342, 2992058692,\n",
       "         840155387, 2488245761, 1946839338, 2429375166, 2799784793,\n",
       "        4165585943, 2609904223, 2235539820,   78207713, 2314463581,\n",
       "         512636430, 2253907428, 2314024181, 3105193387, 2081201980,\n",
       "        1059868735, 2566816982, 3191313721, 2618899705, 4185702159,\n",
       "        4156691514,  439974695,  970727756, 3641007958, 1909829213,\n",
       "        1639680213,  924128085,  541040012, 2071509536, 4264109911,\n",
       "        3473305078, 2013017839, 3669509840, 3213132874, 1461875842,\n",
       "        3719908810, 2660804512, 2500447959, 2902883670, 3049650070,\n",
       "        2280062510, 3119422400, 3291235116, 2067131014, 3175961557,\n",
       "        4251093340, 2929952531, 1465678415,  827880688, 1570070811,\n",
       "        2555797302, 1571899842, 3638844828, 3312987622, 1243768114,\n",
       "        3926496346, 2315002612, 4270781536, 3033667090,  671206834,\n",
       "        1914074830, 2314281231, 3835370987, 2952378090, 2636323531,\n",
       "         800230652, 1667205503, 1280988201, 3903230494,  578160424,\n",
       "         242022588,  543463991, 3398326726, 2657224652, 3848927465,\n",
       "        2760842556, 2336807248, 1783203831,  731382696, 3783648406,\n",
       "        3481939618, 1906685355, 3189677054, 2300122474, 1323095588,\n",
       "        2164953876, 3457954700, 3660564092,  843216586, 1798359390,\n",
       "        3881090580, 4028195754, 2635893572, 2736021866, 3472349447,\n",
       "        2600357357, 3949033993, 2518155990, 2323997221, 3422301583,\n",
       "         422295315,  748128329, 3333825510, 3431666904, 1219090017,\n",
       "        3787487982, 2415393783, 3050164862, 3899292658, 2874521195,\n",
       "        3099942517, 3848414833,  909126808, 3153047137,  974517877,\n",
       "        2481977756, 3148087772, 2117111726,  523539236, 2548794296,\n",
       "        1893429459, 4233134014, 2321010071, 3788298879, 2289164713,\n",
       "        1314611109, 3988200391, 3866413415,  517050937, 1779625564,\n",
       "        1042419970, 1723599055, 4270989610,  950851314, 4227031075,\n",
       "        3106597241, 1173913008, 2525539366,  522526117, 4275761513,\n",
       "        2256400741,  752499300, 2703621141, 2456062327,  281151210,\n",
       "        2830069153, 1443325159, 3162197512, 3486388790, 2584346900,\n",
       "        3408730557, 2500274004, 4285581048, 4142642565, 3485708675,\n",
       "        3025231330, 2527948277, 3239471720, 1720646270, 4274492372,\n",
       "        4201274370, 1509035068, 1086389600,  128990147, 2616985796,\n",
       "        2258398018,  316414092, 4019749323, 2347423778, 2704760089,\n",
       "         422363180, 2498898241,  225355254,  825351951,  284592966,\n",
       "        2596815835,  602045514, 1594001804, 3258721116, 3358328927,\n",
       "        4169500669, 3359584929, 3883402856, 3858452392, 1363063862,\n",
       "        4171889735,  498887036, 1429587078, 3977040852, 3772989981,\n",
       "         523887689, 4030543150, 2743771746, 2510407919, 3804194463,\n",
       "         216058003, 1620554799, 1169552107,  564992381, 3760653940,\n",
       "        3478290970, 4125984323, 3742181517, 1919653848, 2666193650,\n",
       "         838751808, 2461468807,  878806386, 2166745613, 2228542170,\n",
       "         871429136,  566716852, 1933238722, 3475499833, 1709232752,\n",
       "         904101296, 1942781252, 3111470363, 2979005136, 1228797582,\n",
       "        4140512915, 1349250069,  621622525, 1524619724, 1279944482,\n",
       "        2584818911, 2462357604, 2643136504, 4048513399,  496577351,\n",
       "        1096441354, 2404453122, 1573332239,  433417467, 3204051193,\n",
       "        3777294999, 3226398166, 3443153412, 1624834153, 2633298919,\n",
       "        3038486963, 4080164028, 2723007533,  274662956, 1834633506,\n",
       "        4081512664,  279271093, 3705379976, 1274810868, 4153723514,\n",
       "         264250880,  560088785, 2870094026, 2961423229, 1969128750,\n",
       "        1469516932, 1144967894,  476178991, 3211490891, 3499051772,\n",
       "        3795958777,  718973572, 1774036077, 2425744582, 4072435956,\n",
       "        3769732127,  960847301, 1438805617, 4045856830,  979675866,\n",
       "        1019864057, 1306004171,  206257251, 1292892673, 1629236732,\n",
       "        3362084374,  573543895, 1687538059, 1508363639, 1726199984,\n",
       "        1313684933,  575985466, 3979185517, 3981965540, 1881171320,\n",
       "        4192427165, 1206831390, 2508229779, 4018982884,  459463852,\n",
       "        1281197053, 1487319253, 2591332172, 1607276563, 3840923839,\n",
       "        3686187493, 2587727861,  486683436, 3630197600, 3529653201,\n",
       "         670852452, 2021603393, 3306737832, 1394169354, 2138805971,\n",
       "        4096670880, 2435113540,  409891869,  898591991, 1708585288,\n",
       "        3786832550, 2710796224,  299613907, 3409149405,  357030791,\n",
       "        3886438933,  732087162, 2660887143, 4194963322,  425289802,\n",
       "         685880073,  306109808, 1429848857, 3449503208, 4102601264,\n",
       "        1637265608, 1093350395,  669726136, 1685799731,  303675319,\n",
       "        4156014135,  988359514, 2011185656, 2845577250, 1604995994,\n",
       "        2653012786, 2270159463, 2294470860,  173271987, 1004457901,\n",
       "        1889176674, 1583784056, 1147874811, 2151543918, 4033124588,\n",
       "        2924281891,   85950559, 4273575178,  803132806, 1049800940,\n",
       "        1288265529, 1828897297, 3613843982,  139471006, 1696383420,\n",
       "         303705193, 2998485121, 4039073889, 2084183402, 3715919151,\n",
       "         338089710, 1489895395,  459258719,  527835333, 1616152524,\n",
       "        3015006859, 3603760253, 3592277262, 1294164875, 2495690063,\n",
       "        3319680446,  523820363, 1650555929, 3037866124, 1488822445,\n",
       "        1702332708, 3984095600,   76344162,   43352405,  615790343,\n",
       "        2525113178,   46587704,  424405819, 3421621474,  425658807,\n",
       "         108533302, 3646567034,  909799497, 1822482200, 3165726447,\n",
       "        1191854298, 3400557283, 2560533718, 3459156096, 3731153124,\n",
       "        2002981072, 2549701857, 2620423822, 3647373398, 1035783855,\n",
       "        2491100755, 2802669059, 4236251744, 3102077590, 3955710527,\n",
       "        3821757653,  994145745, 4287395295, 3372348553, 4199331106,\n",
       "        3848494883, 1461655212, 1421732837, 3906510758, 2740857774,\n",
       "        2534494722, 4235347482, 3712826499, 1097083076, 1590545086,\n",
       "         222325368,  688451798,  543905339, 2500449114, 2284351456,\n",
       "         499480043, 4065257294, 3729837027, 2667705241, 1240921032,\n",
       "        3793253800, 2571905119, 1071701064,  266628458, 3211932178,\n",
       "        3878092629,  407821110, 1950733019,  982345629, 1408618918,\n",
       "        1963162635, 3005260750, 4055777662, 2835235149,  675424922,\n",
       "        3868338284,  126083315, 3783556247,  332707388, 3583327451,\n",
       "        2235413789, 2175671773, 2113619267, 2225006528, 2285317351,\n",
       "        3095660247, 4117857337, 2223831842, 1489271620,  859016832,\n",
       "        3342735142, 2824444903, 3900472908, 2798727106, 1082539950,\n",
       "          40257640, 3205483759, 3974122643, 2516664569, 1961321721,\n",
       "        2232657539, 3393710612,  647463967, 3251685822, 1489209219,\n",
       "        2337676517, 2613546911, 3837791422,  870792727, 1775252163,\n",
       "        1638256333, 2339484095,  400531839,   94957531, 1192700719,\n",
       "        1929662938, 3185649329, 3045812696, 1265055663, 2298783786,\n",
       "        2479483337, 2726021576,  245403448,  535002333, 1747592346,\n",
       "        3561231191, 2693433378,  736956515, 1731689815,  776749119,\n",
       "        3353886608, 1485829905,  554865410, 4279822155, 3337328867,\n",
       "        2645546049,  495798349,  409020370,  514554227, 2870385896,\n",
       "        3547741958,  196982958, 1867564472,  125470004, 2653690636,\n",
       "         794352939, 3619158543,  310853337,  684417307, 2560806129,\n",
       "        3912367993, 2679432986,  523210671, 1733424354, 2840681545,\n",
       "        4171473949, 1244889347, 1767175751, 1123284699, 2889174843,\n",
       "        2535366654, 2022346489, 3081940042, 3724428512, 1703896351,\n",
       "        2548310455,  749976379, 4256431325, 2928943828, 1546826113,\n",
       "        4184211518, 3069994882, 3140170203, 4176480739, 1446797908,\n",
       "        2936470728,  465604704, 2202354486, 1915101982, 3634121538,\n",
       "        4236133422,  175142947, 2886639046, 2129454274,  600165573,\n",
       "         586081117, 1058937222,  883701906, 2588052466, 2140742282,\n",
       "        1915654022, 3786257699,  843586856,  194498532], dtype=uint32),\n",
       " 624,\n",
       " 0,\n",
       " 0.0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0.07681572528798353,\n",
       " 0.15823801174198843,\n",
       " 0.14375657892854732,\n",
       " 0.1649379840151192,\n",
       " 0.24000147749409725,\n",
       " 0.2674371448776942,\n",
       " 0.25342091404310474,\n",
       " 0.3026808756594139,\n",
       " 0.29365830074689714,\n",
       " 0.19971747094819498,\n",
       " 0.19560848506239964,\n",
       " 0.31294718106836894,\n",
       " 0.3727348359223772,\n",
       " 0.363653746723367,\n",
       " 0.3805039425279266,\n",
       " 0.4316559131551962,\n",
       " 0.4271487367949082,\n",
       " 0.4398161569591399,\n",
       " 0.3041939228740437,\n",
       " 0.41823271521052596,\n",
       " 0.4057650560917065,\n",
       " 0.3963421301513099,\n",
       " 0.29153030103173155,\n",
       " 0.3837023667021972,\n",
       " 0.3695862069284389,\n",
       " 0.4240676969617158,\n",
       " 0.3718329493472246,\n",
       " 0.3989592922881014,\n",
       " 0.41507439142530356,\n",
       " 0.38584033947351576,\n",
       " 0.36049771749190007,\n",
       " 0.42236058212034566,\n",
       " 0.441476272858257,\n",
       " 0.421281103107415,\n",
       " 0.44011783343213096,\n",
       " 0.41338076156588804,\n",
       " 0.4175040939338306,\n",
       " 0.38260983803332516,\n",
       " 0.3586686352806997,\n",
       " 0.3692592179127893,\n",
       " 0.41976986628526897,\n",
       " 0.4051606680001207,\n",
       " 0.38355359515252024,\n",
       " 0.3810865750730608,\n",
       " 0.389684930817785,\n",
       " 0.37531505921337766,\n",
       " 0.45065039424939174,\n",
       " 0.40811487258902324,\n",
       " 0.4579884315365957,\n",
       " 0.4147875181714408,\n",
       " 0.42858560893697023,\n",
       " 0.4427553301026003,\n",
       " 0.4529016323777049,\n",
       " 0.4245998221607026,\n",
       " 0.44241894955888206,\n",
       " 0.4544915379390268,\n",
       " 0.43754239895509023,\n",
       " 0.4286016530885154,\n",
       " 0.3767288917070244,\n",
       " 0.4586253110108075,\n",
       " 0.43423801038339127,\n",
       " 0.41869249556401544,\n",
       " 0.23669716985900444,\n",
       " 0.40961198132287474,\n",
       " 0.449258937689855,\n",
       " 0.4068343041446937,\n",
       " 0.44796323641515845,\n",
       " 0.4600679025170507,\n",
       " 0.399352589834526,\n",
       " 0.48550607831836395,\n",
       " 0.4518948114022306,\n",
       " 0.4574753228919046,\n",
       " 0.4041501098085551,\n",
       " 0.40492220636019327,\n",
       " 0.4224224705655656,\n",
       " 0.3782679702004583,\n",
       " 0.40432077488969265,\n",
       " 0.35523697030606016,\n",
       " 0.3736840948118768,\n",
       " 0.28509107429641706,\n",
       " 0.35574813026170954,\n",
       " 0.35833869943470015,\n",
       " 0.3721940400324696,\n",
       " 0.4275985140778131,\n",
       " 0.340665824389153,\n",
       " 0.3651372633263423,\n",
       " 0.30574889533602806,\n",
       " 0.34613480214150305,\n",
       " 0.2899355645726618,\n",
       " 0.40857214044067947,\n",
       " 0.35930776602961845,\n",
       " 0.3370615381955867,\n",
       " 0.3085606438895227,\n",
       " 0.344974407300099,\n",
       " 0.3389078005873508,\n",
       " 0.28128550634388194,\n",
       " 0.37046946365987615,\n",
       " 0.3378945542366311,\n",
       " 0.3977687429452242,\n",
       " 0.37137564002643403,\n",
       " 0.330777583714492,\n",
       " 0.3816102870630257,\n",
       " 0.32066512780773265,\n",
       " 0.3602385801428366,\n",
       " 0.3118676677388486,\n",
       " 0.30560688305353534,\n",
       " 0.3552500219694367,\n",
       " 0.28707280329454904,\n",
       " 0.3486387548085662,\n",
       " 0.3378739013070319,\n",
       " 0.2711083601226377,\n",
       " 0.26914559428708973,\n",
       " 0.3751745158526099,\n",
       " 0.2887666509720487,\n",
       " 0.355347081185528,\n",
       " 0.3172209408342665,\n",
       " 0.32574715422390016,\n",
       " 0.28225704666812135,\n",
       " 0.3339192979569173,\n",
       " 0.32104722439447275,\n",
       " 0.30771022548806604,\n",
       " 0.33024033987342927,\n",
       " 0.35833858927819323,\n",
       " 0.31007658095391855,\n",
       " 0.25497582392462637,\n",
       " 0.28320819818260384,\n",
       " 0.30064597725772213,\n",
       " 0.28580832059538996,\n",
       " 0.3198647449197131,\n",
       " 0.2990285603177576,\n",
       " 0.2866686358212411,\n",
       " 0.3081435242223618,\n",
       " 0.27549583840679104,\n",
       " 0.27106540506953153,\n",
       " 0.27249975799462284,\n",
       " 0.3166637161643568,\n",
       " 0.3057309422199371,\n",
       " 0.31294328221735207,\n",
       " 0.2889199838406798,\n",
       " 0.2753650767855865,\n",
       " 0.310911025850086,\n",
       " 0.2521836696830595,\n",
       " 0.27878890128365946,\n",
       " 0.2799349620850023,\n",
       " 0.28576940755143626,\n",
       " 0.2882085081013494,\n",
       " 0.26728159868202,\n",
       " 0.29232521985480425,\n",
       " 0.25363606745506173,\n",
       " 0.2283868565573222,\n",
       " 0.267358125018951,\n",
       " 0.27084728374995465,\n",
       " 0.2677520237355525,\n",
       " 0.18876590767773024,\n",
       " 0.2619234915585226,\n",
       " 0.27389776476450123,\n",
       " 0.2785939550893903,\n",
       " 0.27576135864917617,\n",
       " 0.2729203643683115,\n",
       " 0.2657684385357863,\n",
       " 0.2505309621195639,\n",
       " 0.09252011625199243,\n",
       " 0.2618506631328013,\n",
       " 0.2409485981250953,\n",
       " 0.2583400165100121,\n",
       " 0.24052417344769894,\n",
       " 0.2705769623603195,\n",
       " 0.2419432370785478,\n",
       " 0.2782603985634764,\n",
       " 0.2574415692487548,\n",
       " 0.21202359394765416,\n",
       " 0.26145742767316,\n",
       " 0.28171104280397846,\n",
       " 0.21530966328513612,\n",
       " 0.2685076993000334,\n",
       " 0.23055041600839843,\n",
       " 0.2488533526460811,\n",
       " 0.23678016556637782,\n",
       " 0.23938560184881108,\n",
       " 0.21251234980102204,\n",
       " 0.24532196638196657,\n",
       " 0.259638694697279,\n",
       " 0.2415987992200738,\n",
       " 0.2630475926340076,\n",
       " 0.24884231926822512,\n",
       " 0.2362621807327384,\n",
       " 0.2318993328594262,\n",
       " 0.2171721050458754,\n",
       " 0.22738913946005418,\n",
       " 0.22508315819457084,\n",
       " 0.2471693398494668,\n",
       " 0.21605534296410167,\n",
       " 0.27915125089400405,\n",
       " 0.22108254063119953,\n",
       " 0.25445661616438775,\n",
       " 0.21474324620448434,\n",
       " 0.23301317263516616,\n",
       " 0.18230274003282557,\n",
       " 0.22284861921597104,\n",
       " 0.24262548138505236,\n",
       " 0.19420626401102659,\n",
       " 0.21405954737377972,\n",
       " 0.21387931684556974,\n",
       " 0.21897319146113772,\n",
       " 0.24716100988614775,\n",
       " 0.20197814626963478,\n",
       " 0.17324377144538436,\n",
       " 0.1719379216780688,\n",
       " 0.20103951646627252,\n",
       " 0.23274351256031603,\n",
       " 0.190245372677811,\n",
       " 0.20837463828611483,\n",
       " 0.19881562015854637,\n",
       " 0.18127410551480883,\n",
       " 0.18117615773490658,\n",
       " 0.202249088768102,\n",
       " 0.24067966435081475,\n",
       " 0.2081755895624925,\n",
       " 0.18722771333712415,\n",
       " 0.2517433931704957,\n",
       " 0.18377706296196458,\n",
       " 0.2221013712960664]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
