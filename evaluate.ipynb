{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.manifold.t_sne module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.manifold. Anything that cannot be imported from sklearn.manifold is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-451924c73279>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[0;31m#generator = nn.DataParallel(StyledGenerator(code_size)).cuda()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m \u001b[0mg2_running\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStyledGenerator2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[0mg_running\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStyledGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    305\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         \"\"\"\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    223\u001b[0m                 \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m                     \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    305\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         \"\"\"\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: out of memory"
     ]
    }
   ],
   "source": [
    "#coding: future_fstrings     # should work even without -*-\n",
    "#location = fromstr(f'POINT({longitude} {latitude})', srid=4326)\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "import sys\n",
    "sys.argv = [sys.argv[0], '--mixing', '--sched', 'mvtec_single_out/capsule']# '--loss', 'r1'\n",
    "\n",
    "import argparse\n",
    "import random\n",
    "import math\n",
    "\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torch.autograd import Variable, grad\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, utils\n",
    "\n",
    "from dataset import MultiResolutionDataset2\n",
    "from model import StyledGenerator, Discriminator, Encoder, ShortDiscriminator, StyledGenerator2\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.datasets import load_digits\n",
    "from scipy.spatial.distance import pdist\n",
    "from sklearn.manifold.t_sne import _joint_probabilities\n",
    "from scipy import linalg\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from scipy.spatial.distance import squareform\n",
    "from sklearn.manifold import TSNE\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import imgaug as ia\n",
    "import imgaug.augmenters as iaa\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 \n",
    "from scipy.spatial import distance\n",
    "\n",
    "def requires_grad(model, flag=True):\n",
    "    for p in model.parameters():\n",
    "        p.requires_grad = flag\n",
    "\n",
    "\n",
    "def accumulate(model1, model2, decay=0.999):\n",
    "    par1 = dict(model1.named_parameters())\n",
    "    par2 = dict(model2.named_parameters())\n",
    "\n",
    "    for k in par1.keys():\n",
    "        par1[k].data.mul_(decay).add_(1 - decay, par2[k].data)\n",
    "\n",
    "\n",
    "def sample_data(dataset, batch_size, image_size=4):\n",
    "    dataset.resolution = image_size\n",
    "    loader = DataLoader(dataset, shuffle=True, batch_size=batch_size, num_workers=1, drop_last=True)\n",
    "\n",
    "    return loader\n",
    "\n",
    "\n",
    "def adjust_lr(optimizer, lr):\n",
    "    for group in optimizer.param_groups:\n",
    "        mult = group.get('mult', 1)\n",
    "        group['lr'] = lr * mult\n",
    "        \n",
    "from PIL import Image\n",
    "# Open the image form working directory\n",
    "#image = Image.open('crack/004.png')\n",
    "image = Image.open('1.png')\n",
    "#image = #Image.open('crack/004.png')\n",
    "image = Image.open('test/capsule/test/squeeze/001.png')\n",
    "\n",
    "resize_image = image.resize((512, 512))\n",
    "AAA = None\n",
    "BBB = None\n",
    "    \n",
    "    \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial import distance\n",
    "\n",
    "\n",
    "def sortpts_clockwise(A):\n",
    "    sortedAc2 = A[np.argsort(A[:,1]),:]\n",
    "    top2 = sortedAc2[0:2,:]\n",
    "    bottom2 = sortedAc2[2:,:]\n",
    "    sortedtop2c1 = top2[np.argsort(top2[:,0]),:]\n",
    "    top_left = sortedtop2c1[0,:]\n",
    "    sqdists = distance.cdist(top_left[None], bottom2, 'sqeuclidean')\n",
    "    rest2 = bottom2[np.argsort(np.max(sqdists,0))[::-1],:]\n",
    "    return np.concatenate((sortedtop2c1,rest2),axis =0)\n",
    "\n",
    "        \n",
    "    \n",
    "class ImgAugTransform:\n",
    "    def __init__(self):\n",
    "        self.aug = iaa.Sequential([\n",
    "            #iaa.CoarseDropout(0.1, size_percent=0.5),\n",
    "            #iaa.CoarseDropout((0.02, 0.1), size_percent=(0.02, 0.05), per_channel=False),\n",
    "            #iaa.Salt(0.05)#(0.05, size_percent=(0.01, 0.1)) #AndPepper CoarseSalt\n",
    "            iaa.ChangeColorTemperature((1100, 10000)),\n",
    "            iaa.KeepSizeByResize( iaa.Crop(percent=(0.0, 0.5), keep_size=False) ),\n",
    "            #iaa.SaltAndPepper(0.01),\n",
    "            iaa.Flipud(0.5),\n",
    "            iaa.Fliplr(0.5),\n",
    "            #iaa.ScaleX((0.5, 1.5)),\n",
    "            #iaa.ScaleY((0.5, 1.5)),\n",
    "            #iaa.TranslateX(px=(-256, 256)),\n",
    "            #iaa.TranslateX(px=(-256, 256)),\n",
    "            \n",
    "            \n",
    "            #iaa.BlendAlphaSimplexNoise(iaa.EdgeDetect(1.0))\n",
    "            #iaa.Cutout(fill_mode=\"gaussian\", fill_per_channel=True)\n",
    "            #iaa.Salt(0.05)\n",
    "        ])\n",
    "        #self.masks = [\n",
    "        #    np.zeros((4, 4, 1), dtype=np.int8),\n",
    "        #    np.zeros((8, 8, 1), dtype=np.int8),\n",
    "        #    np.zeros((16, 16, 1), dtype=np.int8),\n",
    "        #    np.zeros((32, 32, 1), dtype=np.int8),\n",
    "        #    np.zeros((64, 64, 1), dtype=np.int8),\n",
    "        #    np.zeros((128, 128, 1), dtype=np.int8),\n",
    "        #    np.zeros((256, 256, 1), dtype=np.int8),\n",
    "        #    np.zeros((512, 512, 1), dtype=np.int8),\n",
    "        #             ]\n",
    "        self.mask = np.zeros((512, 512, 1), dtype=np.int8)\n",
    "    \n",
    "    def distortion(self, img):\n",
    "        A = img.shape[0] / 3.0\n",
    "        w = 2.0 / img.shape[1]\n",
    "\n",
    "        shift = lambda x: A * np.sin(2.0*np.pi*x * w)\n",
    "\n",
    "        #for i in range(img.shape[0]):\n",
    "        #ret = np.roll(np.array(img[:,:,:]), int(shift(i)))\n",
    "        \n",
    "        if (np.random.randint(2) == 0):\n",
    "            for i in range(img.shape[0]):\n",
    "                img[i,:,0] = torch.tensor( np.roll(img[i,:,0], int(shift(i))) )\n",
    "                img[i,:,1] = torch.tensor( np.roll(img[i,:,1], int(shift(i))) )\n",
    "                img[i,:,2] = torch.tensor( np.roll(img[i,:,2], int(shift(i))) )\n",
    "        else:\n",
    "            for i in range(img.shape[1]):\n",
    "                img[:,i,0] = torch.tensor( np.roll(img[:,i,0], int(shift(i))) )\n",
    "                img[:,i,1] = torch.tensor( np.roll(img[:,i,1], int(shift(i))) )\n",
    "                img[:,i,2] = torch.tensor( np.roll(img[:,i,2], int(shift(i))) )\n",
    "            \n",
    "        return img\n",
    "\n",
    "    def __call__(self, img):\n",
    "        img = np.array(img)\n",
    "        tile_size = img.shape[0]\n",
    "        step = int(np.log2(tile_size / 4.0))\n",
    "        self.mask[:] = 0\n",
    "        #self.mask = self.masks[step][:, :, :]\n",
    "        n = int(np.random.rand(1) * 7 + 3)\n",
    "        xy = np.random.uniform(low=0.2, high=0.8, size=(2))\n",
    "        #wh = (np.random.normal(0.2, 0.1, size=(2)))\n",
    "        wh = np.random.uniform(low=0.2, high=0.8, size=(2))\n",
    "        \n",
    "#        for i in range(n):\n",
    "#            polys = np.random.rand(5*2).reshape(5, 2)\n",
    "#            polys[:, 0] = polys[:, 0] * tile_size * wh[0] + xy[0] * tile_size\n",
    "#            polys[:, 1] = polys[:, 1] * tile_size * wh[1] + xy[1] * tile_size\n",
    "#        for i in sortpts_clockwise(polys).reshape(1, 5, 2).astype(np.int32).tolist():\n",
    "#            cv2.fillConvexPoly(self.mask, np.array(i), 1)\n",
    "\n",
    "        polys = np.random.rand(10*4).reshape(10, 4)\n",
    "        wh = np.random.uniform(low=0.2, high=0.8, size=(2))\n",
    "        n = 5\n",
    "        tile_size = 512\n",
    "        num = np.random.randint(10) + 1\n",
    "        for i in range(11-num):\n",
    "            cv2.line(self.mask,(int(polys[i, 0]*tile_size), int(polys[i, 1]*tile_size)),\n",
    "                        (int(polys[i, 2]*tile_size), int(polys[i, 3]*tile_size)),(1),1*1)\n",
    "        polys = np.random.rand(10*4).reshape(10, 4)\n",
    "        wh = np.random.uniform(low=0.2, high=0.8, size=(2))\n",
    "        for i in range(11-num):\n",
    "            cv2.line(self.mask,(int(polys[i, 0]*tile_size), int(polys[i, 1]*tile_size)),\n",
    "                        (int(polys[i, 2]*tile_size), int(polys[i, 3]*tile_size)),(1),2*2)\n",
    "        polys = np.random.rand(10*4).reshape(10, 4)\n",
    "        wh = np.random.uniform(low=0.2, high=0.8, size=(2))\n",
    "        for i in range(11-num):\n",
    "            cv2.line(self.mask,(int(polys[i, 0]*tile_size), int(polys[i, 1]*tile_size)),\n",
    "                        (int(polys[i, 2]*tile_size), int(polys[i, 3]*tile_size)),(1),3*3)\n",
    "        wh = np.random.uniform(low=0.2, high=0.8, size=(2))\n",
    "        for i in range(11-num):\n",
    "            cv2.line(self.mask,(int(polys[i, 0]*tile_size), int(polys[i, 1]*tile_size)),\n",
    "                        (int(polys[i, 2]*tile_size), int(polys[i, 3]*tile_size)),(1),4*4)\n",
    "        for i in range(11-num):\n",
    "            cv2.line(self.mask,(int(polys[i, 0]*tile_size), int(polys[i, 1]*tile_size)),\n",
    "                        (int(polys[i, 2]*tile_size), int(polys[i, 3]*tile_size)),(1),5*5)\n",
    "        \n",
    "        #self.mask = 1-self.mask\n",
    "        \n",
    "        ret_mask = cv2.resize(self.mask.astype(np.uint8), dsize=(img.shape[0], img.shape[1]), interpolation=cv2.INTER_CUBIC)\n",
    "        ret_mask = ret_mask[:, :, None]\n",
    "        img_anom = img\n",
    "        #if (np.random.randint(2) == 0):\n",
    "        #    img_anom = (self.distortion( np.array(img_anom).astype(np.uint8) ).copy()).astype(np.float32)\n",
    "        #else:\n",
    "        #    pass\n",
    "        img_anom = (self.aug.augment_image( np.array(img_anom).astype(np.uint8) ).copy()).astype(np.float32)\n",
    "        #self.mask[:] = 1\n",
    "        ret = (img - ret_mask*img) + (ret_mask * img_anom)#img_anom#(img - self.mask*img) + (self.mask * img_anom)\n",
    "        \n",
    "        return np.concatenate((ret, ret_mask), axis=2)\n",
    "\n",
    "ia_transform = ImgAugTransform()\n",
    "\n",
    "code_size = 512\n",
    "base_batch_size = 2 #16\n",
    "n_critic = 1\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Progressive Growing of GANs')\n",
    "\n",
    "parser.add_argument('path', type=str, help='path of specified dataset')\n",
    "parser.add_argument(\n",
    "    '--phase',\n",
    "    type=int,\n",
    "    default=20_000, #600_000\n",
    "    help='number of samples used for each training phases',\n",
    ")\n",
    "parser.add_argument('--lr', default=0.001, type=float, help='learning rate')\n",
    "parser.add_argument('--sched', action='store_true', help='use lr scheduling')\n",
    "parser.add_argument('--init_size', default=512, type=int, help='initial image size') #2^9\n",
    "parser.add_argument('--max_size', default=512, type=int, help='max image size')\n",
    "parser.add_argument(\n",
    "    '--ckpt', default='checkpoint/capsule/train_step-8.model', type=str, help='load from previous checkpoints'\n",
    ")\n",
    "parser.add_argument(\n",
    "    '--no_from_rgb_activate',\n",
    "    action='store_true',\n",
    "    help='use activate in from_rgb (original implementation)',\n",
    ")\n",
    "parser.add_argument(\n",
    "    '--mixing', action='store_true', help='use mixing regularization'\n",
    ")\n",
    "parser.add_argument(\n",
    "    '--loss',\n",
    "    type=str,\n",
    "    default='wgan-gp',\n",
    "    choices=['wgan-gp', 'r1'],\n",
    "    help='class of gan loss',\n",
    ")\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "#encoder = nn.DataParallel(\n",
    "#    Encoder(from_rgb_activate=not args.no_from_rgb_activate)\n",
    "#).cuda()\n",
    "#generator = nn.DataParallel(StyledGenerator(code_size)).cuda()\n",
    "\n",
    "g2_running = StyledGenerator2(code_size).cuda()\n",
    "\n",
    "g_running = StyledGenerator(code_size).cuda()\n",
    "#g_running.train(False)\n",
    "\n",
    "e_running = Encoder(from_rgb_activate=not args.no_from_rgb_activate).cuda()\n",
    "#e_running.train(False)\n",
    "\n",
    "g2_optimizer = optim.Adam(\n",
    "    g2_running.generator.parameters(), lr=args.lr, betas=(0.0, 0.99)\n",
    ")\n",
    "g2_optimizer.add_param_group(\n",
    "    {\n",
    "        'params': g2_running.style.parameters(),\n",
    "        'lr': args.lr * 0.01,\n",
    "        'mult': 0.01,\n",
    "    }\n",
    ")\n",
    "\n",
    "g_optimizer = optim.Adam(\n",
    "    g_running.generator.parameters(), lr=args.lr, betas=(0.0, 0.99)\n",
    ")\n",
    "g_optimizer.add_param_group(\n",
    "    {\n",
    "        'params': g_running.style.parameters(),\n",
    "        'lr': args.lr * 0.01,\n",
    "        'mult': 0.01,\n",
    "    }\n",
    ")\n",
    "\n",
    "e_optimizer = optim.Adam(e_running.parameters(), lr=args.lr, betas=(0.0, 0.99))\n",
    "\n",
    "#accumulate(g_running, generator.module, 0)\n",
    "#accumulate(e_running, encoder.module, 0)\n",
    "\n",
    "assert args.ckpt is not None\n",
    "ckpt = torch.load(args.ckpt)\n",
    "\n",
    "#generator.module.load_state_dict(ckpt['generator'])\n",
    "g_running.load_state_dict(ckpt['g_running'])\n",
    "g_optimizer.load_state_dict(ckpt['g_optimizer'])\n",
    "\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        #transforms.RandomHorizontalFlip(),\n",
    "        ia_transform,\n",
    "        #transforms.ToTensor(),\n",
    "        #transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5), inplace=True),\n",
    "    ]\n",
    ")\n",
    "\n",
    "transform2 = transforms.Compose(\n",
    "    [\n",
    "        #transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5), inplace=True),\n",
    "    ]\n",
    ")\n",
    "\n",
    "dataset = MultiResolutionDataset2(args.path, transform, transform2)\n",
    "\n",
    "if args.sched:\n",
    "    args.lr = {128: 0.0015, 256: 0.002, 512: 0.003, 1024: 0.003}\n",
    "    args.batch = {4: 128, 8: 64, 16: 32, 32: 16, 64: 8, 128: 8, 256: 2, 512: 2} #8\n",
    "\n",
    "else:\n",
    "    args.lr = {}\n",
    "    args.batch = {}\n",
    "\n",
    "args.gen_sample = {512: (8, 4), 1024: (4, 2)}\n",
    "\n",
    "args.batch_default = base_batch_size * 2\n",
    "\n",
    "\n",
    "def toImage(tensor):\n",
    "    A = tensor.clone()\n",
    "    A -= A.min()\n",
    "    A /= A.max()\n",
    "    \n",
    "    return A\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_num = '120000'\n",
    "ckpt = torch.load('checkpoint/capsule/encdec/prog'+step_num+'e.model')\n",
    "e_running.load_state_dict(ckpt)\n",
    "ckpt = torch.load('checkpoint/capsule/encdec/prog'+step_num+'.model')\n",
    "g_running.load_state_dict(ckpt)\n",
    "ckpt = torch.load('checkpoint/capsule/encdec/prog'+step_num+'g2.model')\n",
    "g2_running.load_state_dict(ckpt)\n",
    "\n",
    "#ckpt = torch.load('checkpoint/capsule/encdec/020000e.model')\n",
    "#e_running.load_state_dict(ckpt)\n",
    "#ckpt = torch.load('checkpoint/capsule/encdec/020000.model')\n",
    "#g_running.load_state_dict(ckpt)\n",
    "#ckpt = torch.load('checkpoint/capsule/encdec/020000g2.model')\n",
    "#g2_running.load_state_dict(ckpt)\n",
    "\n",
    "generator2 = g2_running\n",
    "encoder = e_running\n",
    "generator = g_running\n",
    "\n",
    "\n",
    "resize_image = image.resize((256, 256))\n",
    "anomaly_image = torch.from_numpy(np.array(resize_image)[None, :, :, :]).permute(0, 3, 1, 2) / 255.0\n",
    "anomaly_image = anomaly_image.cuda()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "resolution = 512\n",
    "encoder = e_running\n",
    "generator = g_running\n",
    "step = 7\n",
    "alpha = 1\n",
    "\n",
    "gen_in1, gen_in2 = torch.randn(2, 1, code_size, device='cuda').chunk(\n",
    "                    2, 0\n",
    "                )\n",
    "gen_in1 = gen_in1.squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ckpt =  torch.load('checkpoint/capsule/090000.model')\n",
    "#g_running.load_state_dict(ckpt)\n",
    "#ckpt =  torch.load('checkpoint/capsule/090000enc.model')\n",
    "#e_running.load_state_dict(ckpt)\n",
    "\n",
    "#ckpt = torch.load('checkpoint/capsule/encdec/213464.model')\n",
    "#g_running.load_state_dict(ckpt)\n",
    "#ckpt = torch.load('checkpoint/capsule/encdec/encoder213464.model')\n",
    "#e_running.load_state_dict(ckpt)\n",
    "\n",
    "import cv2 as cv\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def get_holes(image, thresh):\n",
    "    gray = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "    im_bw = cv.threshold(gray, thresh, 255, cv.THRESH_BINARY)[1]\n",
    "    im_bw_inv = cv.bitwise_not(im_bw)\n",
    "\n",
    "    contour, _ = cv.findContours(im_bw_inv, cv.RETR_CCOMP, cv.CHAIN_APPROX_SIMPLE)\n",
    "    for cnt in contour:\n",
    "        cv.drawContours(im_bw_inv, [cnt], 0, 255, -1)\n",
    "\n",
    "    nt = cv.bitwise_not(im_bw)\n",
    "    im_bw_inv = cv.bitwise_or(im_bw_inv, nt)\n",
    "    return im_bw_inv\n",
    "\n",
    "\n",
    "def remove_background(image, thresh, scale_factor=.25, kernel_range=range(1, 15), border=None):\n",
    "    border = border or kernel_range[-1]\n",
    "\n",
    "    holes = get_holes(image, thresh)\n",
    "    small = cv.resize(holes, None, fx=scale_factor, fy=scale_factor)\n",
    "    bordered = cv.copyMakeBorder(small, border, border, border, border, cv.BORDER_CONSTANT)\n",
    "\n",
    "    for i in kernel_range:\n",
    "        kernel = cv.getStructuringElement(cv.MORPH_ELLIPSE, (2*i+1, 2*i+1))\n",
    "        bordered = cv.morphologyEx(bordered, cv.MORPH_CLOSE, kernel)\n",
    "\n",
    "    unbordered = bordered[border: -border, border: -border]\n",
    "    mask = cv.resize(unbordered, (image.shape[1], image.shape[0]))\n",
    "    fg = cv.bitwise_and(image, image, mask=mask)\n",
    "    return fg, mask\n",
    "\n",
    "num_file = 0\n",
    "r_list = []\n",
    "# traverse root directory, and list directories as dirs and files as files\n",
    "for root, dirs, files in os.walk(\"./test/capsule/test/\"):\n",
    "    path = root.split(os.sep)\n",
    "    #print(path)\n",
    "    print((len(path) - 1) * '---', os.path.basename(root))\n",
    "    if path[-1] == 'good':\n",
    "        continue\n",
    "    r_list_sub = []\n",
    "    for file in tqdm(sorted(files[:])):\n",
    "        if '.png' == file[-4:] and path[-1] != '':\n",
    "            #print()\n",
    "            # Open the image form working directory\n",
    "            anomaly = Image.open('./test/capsule/test/' + str(path[-1]) + '/' + file)\n",
    "            gt = Image.open('./test/capsule/gt/' + str(path[-1]) + '/' + file[:-4] + '_mask.png')\n",
    "            gt = gt.resize((512, 512))\n",
    "            anomaly = anomaly.resize((512, 512))\n",
    "            #resize_image = image\n",
    "            #anomaly_image = torch.from_numpy(np.array(resize_image)[None, :, :, :]).permute(0, 3, 1, 2) / 255.0\n",
    "            #anomaly_image = anomaly_image.cuda()\n",
    "            #plt.imshow( gt )\n",
    "            \n",
    "            #plt.imshow( toImage(resize_image.data.detach().cpu()[0]).permute(1, 2, 0)  )\n",
    "            \n",
    "            gen_in1, gen_in2 = torch.randn(2, 1, code_size, device='cuda').chunk(\n",
    "                    2, 0\n",
    "                )\n",
    "            gen_in1 = gen_in1.squeeze(0)\n",
    "\n",
    "            ground_truth = 1 - (torch.from_numpy(np.array(gt)[:, :]).permute(0, 1) / 255.0)\n",
    "            anomaly_image = torch.from_numpy(np.array(anomaly)[None, :, :, :]).permute(0, 3, 1, 2) / 255.0\n",
    "            anomaly_image = anomaly_image.cuda()\n",
    "            \n",
    "            anomaly_image = anomaly_image\n",
    "            anomaly_image = anomaly_image * 2\n",
    "            anomaly_image = anomaly_image - 1.0\n",
    "\n",
    "            #out = encoder(anomaly_image, step=step, alpha=alpha)\n",
    "            (out, skiplist) = encoder(anomaly_image, step=step, alpha=alpha)\n",
    "            skiplist = skiplist[1:]\n",
    "            skiplist.insert(0, None)\n",
    "\n",
    "            out_orin, fake_image     = generator([gen_in1], styles=[out[:, :512]], step=step, alpha=alpha)\n",
    "            out_orin, (fake_image2, mask)     = generator2(skiplist, fake_image, anomaly_image, [gen_in1], styles=[out[:, 512:]], step=step, alpha=alpha)\n",
    "            \n",
    "            #fake_image = fake_image[0] / 255.0\n",
    "            \n",
    "            gt_image = torch.from_numpy(np.array(gt)[None, :, :]) / 255.0\n",
    "            #gt_image = gt_image.cuda()\n",
    "            gt_image_im =torch.from_numpy(np.array(( toImage(torch.sum( gt_image.data[:, :, :], axis = 0) ) ) ))\n",
    "            \n",
    "            \n",
    "            fake_image_norm = (1 - mask) * fake_image + mask * anomaly_image\n",
    "\n",
    "\n",
    "            anomaly_image_norm = anomaly_image\n",
    "            anomaly_image_norm = (anomaly_image_norm - torch.min(anomaly_image_norm))\n",
    "            anomaly_image_norm = anomaly_image_norm / (torch.max(anomaly_image_norm) + 1e-6)\n",
    "\n",
    "            \n",
    "            img_diff = mask\n",
    "            #img_diff = fake_image_norm - anomaly_image_norm#mask#\n",
    "            img_diff = torch.sum( torch.abs(img_diff), axis = 0)\n",
    "            img_diff = torch.from_numpy(np.array(( toImage(torch.sum( img_diff.data.cpu()[:, :, :], axis = 0) ) ) )).permute(0, 1)\n",
    "            #plt.imshow( img_diff  )\n",
    "            \n",
    "            #img_diff = mask\n",
    "            fg = torch.from_numpy(np.array(( toImage( anomaly_image.data.cpu()[0, :, :, :] ) ) )).permute(1, 2, 0)\n",
    "            img = np.array(fg*255).astype(np.uint8)\n",
    "            nb_img, mask_fg = remove_background(img, 120)\n",
    "            \n",
    "            #diff = diff * ground_truth.expand_as(diff)\n",
    "            kernel = np.ones((9,9),np.uint8)\n",
    "            img_diff = cv2.dilate(np.array(img_diff),kernel,iterations = 1)\n",
    "            ret = ((torch.tensor(img_diff) > 0.2) & (mask_fg > 0) )\n",
    "            gt = (gt_image_im > 0)\n",
    "            \n",
    "            score = float(torch.sum ( ret & gt ).item()) / torch.sum ( ret | gt ).item()\n",
    "            \n",
    "            #plt.imshow( diff )\n",
    "            r_list_sub.append(score)\n",
    "            \n",
    "    r_list.append(r_list_sub)\n",
    "            #r_list.append((torch.sum(diff) / torch.sum(ground_truth) ).item())\n",
    "            #num_file += 1\n",
    "            #plt.imsave('./test/'+'result/'+str(num_file)+'.png', diff)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = 0\n",
    "sum_score = 0\n",
    "for s_list in r_list:\n",
    "    length += len(s_list)\n",
    "    sum_score += sum(s_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_score / length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_l = [\"crack\", \"squeeze\", \"faulty_imprint\", \"poke\", \"scratch\"]\n",
    "\n",
    "k = 0\n",
    "for i in range(len(r_list)):\n",
    "    if len(r_list[i]) > 0:\n",
    "        print(str_l[k])\n",
    "        print(sum(r_list[i]) / len(r_list[i]))\n",
    "        k += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_l = [\"crack\", \"squeeze\", \"faulty_imprint\", \"poke\", \"scratch\"]\n",
    "\n",
    "k = 0\n",
    "for i in range(len(r_list)):\n",
    "    if len(r_list[i]) > 0:\n",
    "        print(str_l[k])\n",
    "        print(sum(r_list[i]) / len(r_list[i]))\n",
    "        k += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
