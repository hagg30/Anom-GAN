{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_CATEGORY = 'capsule'\n",
    "\n",
    "import os\n",
    "\n",
    "checkpoint_dir = 'checkpoint/'+DATA_CATEGORY+'/'\n",
    "sample_dir     = 'sample/'+DATA_CATEGORY+'/'\n",
    "\n",
    "# If folder doesn't exist, then create it.\n",
    "if not os.path.isdir(checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir)\n",
    "if not os.path.isdir(sample_dir):\n",
    "    os.makedirs(sample_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#coding: future_fstrings     # should work even without -*-\n",
    "#location = fromstr(f'POINT({longitude} {latitude})', srid=4326)\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "import sys\n",
    "sys.argv = [sys.argv[0], '--sched', 'mvtec_single_out/'+DATA_CATEGORY]# '--loss', 'r1', '--mixing'\n",
    "\n",
    "import argparse\n",
    "import random\n",
    "import math\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torch.autograd import Variable, grad\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, utils\n",
    "\n",
    "from dataset import MultiResolutionDataset\n",
    "from model import StyledGenerator, Discriminator, Encoder\n",
    "\n",
    "\n",
    "def requires_grad(model, flag=True):\n",
    "    for p in model.parameters():\n",
    "        p.requires_grad = flag\n",
    "\n",
    "\n",
    "def accumulate(model1, model2, decay=0.999):\n",
    "    par1 = dict(model1.named_parameters())\n",
    "    par2 = dict(model2.named_parameters())\n",
    "\n",
    "    for k in par1.keys():\n",
    "        par1[k].data.mul_(decay).add_(1 - decay, par2[k].data)\n",
    "\n",
    "\n",
    "def sample_data(dataset, batch_size, image_size=4):\n",
    "    dataset.resolution = image_size\n",
    "    loader = DataLoader(dataset, shuffle=True, batch_size=batch_size, num_workers=1, drop_last=True)\n",
    "\n",
    "    return loader\n",
    "\n",
    "\n",
    "def adjust_lr(optimizer, lr):\n",
    "    for group in optimizer.param_groups:\n",
    "        mult = group.get('mult', 1)\n",
    "        group['lr'] = lr * mult\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pytorch/torch/csrc/utils/python_arg_parser.cpp:756: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha)\n"
     ]
    }
   ],
   "source": [
    "code_size = 512\n",
    "base_batch_size = 1 #16\n",
    "n_critic = 1\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Progressive Growing of GANs')\n",
    "\n",
    "parser.add_argument('path', type=str, help='path of specified dataset')\n",
    "parser.add_argument(\n",
    "    '--phase',\n",
    "    type=int,\n",
    "    default= 30000, #600_000 // 4,\n",
    "    help='number of samples used for each training phases',\n",
    ")\n",
    "parser.add_argument('--lr', default=0.001, type=float, help='learning rate')\n",
    "parser.add_argument('--sched', action='store_true', help='use lr scheduling')\n",
    "parser.add_argument('--init_size', default=8, type=int, help='initial image size') #8\n",
    "parser.add_argument('--max_size', default=512, type=int, help='max image size')\n",
    "parser.add_argument(\n",
    "    '--ckpt', default=None, type=str, help='load from previous checkpoints'\n",
    ")\n",
    "parser.add_argument(\n",
    "    '--no_from_rgb_activate',\n",
    "    action='store_true',\n",
    "    help='use activate in from_rgb (original implementation)',\n",
    ")\n",
    "parser.add_argument(\n",
    "    '--mixing', action='store_true', help='use mixing regularization'\n",
    ")\n",
    "parser.add_argument(\n",
    "    '--loss',\n",
    "    type=str,\n",
    "    default='wgan-gp',\n",
    "    choices=['wgan-gp', 'r1'],\n",
    "    help='class of gan loss',\n",
    ")\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "encoder = nn.DataParallel(\n",
    "    Encoder(from_rgb_activate=not args.no_from_rgb_activate)\n",
    ").cuda()\n",
    "generator = nn.DataParallel(StyledGenerator(code_size)).cuda()\n",
    "discriminator = nn.DataParallel(\n",
    "    Discriminator(from_rgb_activate=not args.no_from_rgb_activate)\n",
    ").cuda()\n",
    "g_running = StyledGenerator(code_size).cuda()\n",
    "g_running.train(False)\n",
    "\n",
    "e_running = Encoder(from_rgb_activate=not args.no_from_rgb_activate).cuda()\n",
    "e_running.train(False)\n",
    "\n",
    "g_optimizer = optim.Adam(\n",
    "    generator.module.generator.parameters(), lr=args.lr, betas=(0.0, 0.99)\n",
    ")\n",
    "g_optimizer.add_param_group(\n",
    "    {\n",
    "        'params': generator.module.style.parameters(),\n",
    "        'lr': args.lr * 0.01,\n",
    "        'mult': 0.01,\n",
    "    }\n",
    ")\n",
    "d_optimizer = optim.Adam(discriminator.parameters(), lr=args.lr, betas=(0.0, 0.99))\n",
    "#beta1=0.9, beta2=0.99, epsilon=1e-8)\n",
    "e_optimizer = optim.Adam(encoder.parameters(), lr=args.lr, betas=(0.0, 0.99))\n",
    "\n",
    "accumulate(g_running, generator.module, 0)\n",
    "accumulate(e_running, encoder.module, 0)\n",
    "\n",
    "#assert args.ckpt is not None\n",
    "if args.ckpt is not None:\n",
    "    ckpt = torch.load(args.ckpt)\n",
    "\n",
    "    generator.module.load_state_dict(ckpt['generator'])\n",
    "    discriminator.module.load_state_dict(ckpt['discriminator'])\n",
    "    g_running.load_state_dict(ckpt['g_running'])\n",
    "    g_optimizer.load_state_dict(ckpt['g_optimizer'])\n",
    "    d_optimizer.load_state_dict(ckpt['d_optimizer'])\n",
    "\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        #transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5), inplace=True),\n",
    "    ]\n",
    ")\n",
    "\n",
    "dataset = MultiResolutionDataset(args.path, transform)\n",
    "\n",
    "if args.sched:\n",
    "    args.lr = {128: 0.0015, 256: 0.002, 512: 0.002, 1024: 0.002}\n",
    "    #args.batch = {4: 512, 8: 256, 16: 128, 32: 64, 64: 32, 128: 32, 256: 32}\n",
    "    args.batch = {4: base_batch_size*64, 8: base_batch_size*32, 16: base_batch_size*32, 32: base_batch_size*16,\n",
    "                  64: base_batch_size*4, 128: base_batch_size*2, 256: base_batch_size, 512: base_batch_size}\n",
    "\n",
    "else:\n",
    "    args.lr = {}\n",
    "    args.batch = {}\n",
    "\n",
    "args.gen_sample = {512: (8, 4), 1024: (4, 2)}\n",
    "\n",
    "args.batch_default = base_batch_size\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_g = []\n",
    "loss_e = []\n",
    "loss_d = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Size: 16; G: 11.020; D: -8.452; Grad: 1.316; Alpha: 1.00000:   0%|          | 3416/3000000 [09:26<137:57:16,  6.03it/s] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-1eb048d1fb7c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0mb_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreal_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m     \u001b[0mreal_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreal_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'wgan-gp'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#train(args, dataset, generator, discriminator, 0)\n",
    "\n",
    "\n",
    "#def train(args, dataset, generator, discriminator, initial_num):\n",
    "step = int(math.log2(args.init_size)) - 2\n",
    "resolution = 4 * 2 ** step\n",
    "loader = sample_data(\n",
    "    dataset, args.batch.get(resolution, args.batch_default), resolution\n",
    ")\n",
    "data_loader = iter(loader)\n",
    "\n",
    "adjust_lr(g_optimizer, args.lr.get(resolution, 0.001))\n",
    "adjust_lr(d_optimizer, args.lr.get(resolution, 0.001))\n",
    "\n",
    "pbar = tqdm(range(3_000_000)) #3_000_000\n",
    "\n",
    "requires_grad(generator, False)\n",
    "requires_grad(discriminator, True)\n",
    "\n",
    "disc_loss_val = 0\n",
    "gen_loss_val = 0\n",
    "grad_loss_val = 0\n",
    "\n",
    "alpha = 0\n",
    "used_sample = 0\n",
    "\n",
    "max_step = int(math.log2(args.max_size)) - 2\n",
    "final_progress = False\n",
    "\n",
    "for i in pbar:\n",
    "    discriminator.zero_grad()\n",
    "\n",
    "    alpha = min(1, 1 / args.phase * (used_sample + 1))\n",
    "\n",
    "    if (resolution == args.init_size and args.ckpt is None) or final_progress:\n",
    "        alpha = 1\n",
    "\n",
    "    if used_sample > args.phase * 2:\n",
    "        used_sample = 0\n",
    "        step += 1\n",
    "\n",
    "        if step > max_step:\n",
    "            step = max_step\n",
    "            final_progress = True\n",
    "            ckpt_step = step + 1\n",
    "\n",
    "        else:\n",
    "            alpha = 0\n",
    "            ckpt_step = step\n",
    "\n",
    "        resolution = 4 * 2 ** step\n",
    "\n",
    "        del loader\n",
    "        del data_loader \n",
    "\n",
    "        loader = sample_data(\n",
    "            dataset, args.batch.get(resolution, args.batch_default), resolution\n",
    "        )\n",
    "        data_loader = iter(loader)\n",
    "\n",
    "        torch.save(\n",
    "            {\n",
    "                'encoder': encoder.module.state_dict(),\n",
    "                'generator': generator.module.state_dict(),\n",
    "                'discriminator': discriminator.module.state_dict(),\n",
    "                'g_optimizer': g_optimizer.state_dict(),\n",
    "                'd_optimizer': d_optimizer.state_dict(),\n",
    "                'g_running': g_running.state_dict(),\n",
    "                'e_running': e_running.state_dict(),\n",
    "            },\n",
    "            ('checkpoint/capsule/train_step-' + str(ckpt_step) + '.model'),\n",
    "        )\n",
    "\n",
    "        adjust_lr(g_optimizer, args.lr.get(resolution, 0.001))\n",
    "        adjust_lr(d_optimizer, args.lr.get(resolution, 0.001))\n",
    "\n",
    "    try:\n",
    "        real_image = next(data_loader)\n",
    "\n",
    "    except (OSError, StopIteration):\n",
    "        data_loader = iter(loader)\n",
    "        real_image = next(data_loader)\n",
    "\n",
    "    used_sample += real_image.shape[0]\n",
    "\n",
    "    b_size = real_image.size(0)\n",
    "    real_image = real_image.cuda()\n",
    "\n",
    "    if args.loss == 'wgan-gp':\n",
    "        real_predict = discriminator(real_image, step=step, alpha=alpha)\n",
    "        real_predict = real_predict.mean() - 0.001 * (real_predict ** 2).mean()\n",
    "        (-real_predict).backward()\n",
    "\n",
    "    elif args.loss == 'r1':\n",
    "        real_image.requires_grad = True\n",
    "        real_scores = discriminator(real_image, step=step, alpha=alpha)\n",
    "        real_predict = F.softplus(-real_scores).mean()\n",
    "        real_predict.backward(retain_graph=True)\n",
    "\n",
    "        grad_real = grad(\n",
    "            outputs=real_scores.sum(), inputs=real_image, create_graph=True\n",
    "        )[0]\n",
    "        grad_penalty = (\n",
    "            grad_real.view(grad_real.size(0), -1).norm(2, dim=1) ** 2\n",
    "        ).mean()\n",
    "        grad_penalty = 10 / 2 * grad_penalty\n",
    "        grad_penalty.backward()\n",
    "        if i%10 == 0:\n",
    "            grad_loss_val = grad_penalty.item()\n",
    "\n",
    "    if args.mixing and random.random() < 0.9:\n",
    "        gen_in11, gen_in12, gen_in21, gen_in22 = torch.randn(\n",
    "            4, b_size, code_size, device='cuda'\n",
    "        ).chunk(4, 0)\n",
    "        gen_in1 = [gen_in11.squeeze(0), gen_in12.squeeze(0)]\n",
    "        gen_in2 = [gen_in21.squeeze(0), gen_in22.squeeze(0)]\n",
    "\n",
    "    else:\n",
    "        gen_in1, gen_in2 = torch.randn(2, b_size, code_size, device='cuda').chunk(\n",
    "            2, 0\n",
    "        )\n",
    "        gen_in1 = gen_in1.squeeze(0)\n",
    "        gen_in2 = gen_in2.squeeze(0)\n",
    "\n",
    "    #gen_in1 = encoder(real_image, step=step, alpha=alpha)\n",
    "\n",
    "    _, fake_image = generator([gen_in1], step=step, alpha=alpha)\n",
    "    fake_predict = discriminator(fake_image, step=step, alpha=alpha)\n",
    "\n",
    "    if args.loss == 'wgan-gp':\n",
    "        fake_predict = fake_predict.mean()\n",
    "        fake_predict.backward()\n",
    "\n",
    "        eps = torch.rand(b_size, 1, 1, 1).cuda()\n",
    "        x_hat = eps * real_image.data + (1 - eps) * fake_image.data\n",
    "        x_hat.requires_grad = True\n",
    "        hat_predict = discriminator(x_hat, step=step, alpha=alpha)\n",
    "        grad_x_hat = grad(\n",
    "            outputs=hat_predict.sum(), inputs=x_hat, create_graph=True\n",
    "        )[0]\n",
    "        grad_penalty = (\n",
    "            (grad_x_hat.view(grad_x_hat.size(0), -1).norm(2, dim=1) - 1) ** 2\n",
    "        ).mean()\n",
    "        grad_penalty = 10 * grad_penalty\n",
    "        grad_penalty.backward()\n",
    "        if i%10 == 0:\n",
    "            grad_loss_val = grad_penalty.item()\n",
    "            disc_loss_val = (-real_predict + fake_predict).item()\n",
    "            loss_d.append(disc_loss_val)\n",
    "\n",
    "    elif args.loss == 'r1':\n",
    "        fake_predict = F.softplus(fake_predict).mean()\n",
    "        fake_predict.backward()\n",
    "        if i%10 == 0:\n",
    "            disc_loss_val = (real_predict + fake_predict).item()\n",
    "            loss_d.append(disc_loss_val)\n",
    "\n",
    "    d_optimizer.step()\n",
    "\n",
    "    if (i + 1) % n_critic == 0:\n",
    "        generator.zero_grad()\n",
    "\n",
    "        requires_grad(generator, True)\n",
    "        requires_grad(discriminator, False)\n",
    "\n",
    "        #gen_in2 = encoder(real_image, step=step, alpha=alpha)\n",
    "        _, fake_image = generator([gen_in2], step=step, alpha=alpha)\n",
    "        predict = discriminator(fake_image, step=step, alpha=alpha)\n",
    "\n",
    "        if args.loss == 'wgan-gp':\n",
    "            loss = -predict.mean()\n",
    "        elif args.loss == 'r1':\n",
    "            loss = F.softplus(-predict).mean()\n",
    "        if i%10 == 0:\n",
    "            gen_loss_val = loss.item()\n",
    "            loss_g.append(gen_loss_val)\n",
    "        loss.backward()\n",
    "        g_optimizer.step()\n",
    "        accumulate(g_running, generator.module)\n",
    "\n",
    "        requires_grad(generator, False)\n",
    "        requires_grad(discriminator, True)\n",
    "\n",
    "    if (i + 1) % 100 == 0:\n",
    "        images = []\n",
    "\n",
    "        gen_i, gen_j = args.gen_sample.get(resolution, (10, 5))\n",
    "\n",
    "        images.append(real_image.data.detach().cpu())\n",
    "        images.append(g_running(\n",
    "                        [gen_in2], step=step, alpha=alpha\n",
    "                    )[1].data.detach().cpu())\n",
    "                      \n",
    "        with torch.no_grad():\n",
    "            for _ in range(gen_i):\n",
    "                images.append(\n",
    "                    g_running(\n",
    "                        [torch.randn(gen_j, code_size).cuda()], step=step, alpha=alpha\n",
    "                    )[1].data.detach().cpu()\n",
    "                )\n",
    "\n",
    "        utils.save_image(\n",
    "            torch.cat(images, 0),\n",
    "            'sample/capsule/'+str(i + 1).zfill(6)+ '.png',\n",
    "            nrow=gen_i,\n",
    "            normalize=True,\n",
    "            range=(-1, 1),\n",
    "        )\n",
    "\n",
    "    if (i + 1) % 10000 == 0:\n",
    "        torch.save(\n",
    "            g_running.state_dict(), 'checkpoint/capsule/'+str(i + 1).zfill(6)+'.model'\n",
    "        )\n",
    "\n",
    "    state_msg = (\n",
    "        f'Size: {4 * 2 ** step}; G: {gen_loss_val:.3f}; D: {disc_loss_val:.3f};'\n",
    "        f' Grad: {grad_loss_val:.3f}; Alpha: {alpha:.5f}'\n",
    "    )\n",
    "\n",
    "    pbar.set_description(state_msg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
